# 目录（改进版）

## 主要改进说明

### 1. **第二章结构调整**
- 原顺序：频域分析 → LLM → 门控注意力 → 评价指标
- **改进**：LLM基础 → 频域分析 → 门控注意力 → 评价指标
- **理由**：先讲基础理论（LLM），再讲应用技术（频域分析），最后讲改进点（门控注意力），逻辑更清晰

### 2. **标题学术化**
- "统一改进基座" → "统一改进框架"
- "（侧重 MSE 优化）" → 改为在引言中说明，标题更简洁
- 问句标题改为陈述句

### 3. **章节内容细化**
- 第二章增加"时间序列预测基础"作为总领
- 第三章细化适配器设计的子节
- 第七章增加"研究贡献"和"研究局限性"

### 4. **实验章节统一**
- 在第三章增加"基线实验"验证统一改进的有效性
- 第四、五章聚焦各自方法的创新点

---

## 改进后的完整目录

第一章 绪论
• 1.1 研究背景与意义
• 1.2 国内外研究现状
  • 1.2.1 统计学及浅层机器学习方法
  • 1.2.2 深度循环与卷积神经网络方法
  • 1.2.3 基于 Transformer 与注意力机制的方法
  • 1.2.4 大语言模型（LLM）在时序预测中的应用现状
• 1.3 本文研究目标与主要内容
• 1.4 论文组织结构

第二章 相关理论基础与关键技术
• 2.1 时间序列预测基础
  • 2.1.1 时间序列预测问题定义
  • 2.1.2 评价指标：MSE 与 MAE 的数学特性与适用场景
• 2.2 大语言模型基础理论
  • 2.2.1 Transformer 架构与预训练机制
  • 2.2.2 Qwen3-1.4B 模型架构分析
  • 2.2.3 冻结大模型的参数高效微调策略
• 2.3 时间序列频域分析理论
  • 2.3.1 傅里叶变换及其在时序分析中的局限性
  • 2.3.2 小波包分解的时频局部化原理
  • 2.3.3 频域神经网络的全局频谱建模机制
• 2.4 门控注意力机制原理
  • 2.4.1 传统注意力机制的局限性
  • 2.4.2 门控注意力的数学原理与优势
• 2.5 数据集与实验环境
  • 2.5.1 数据集描述与预处理
  • 2.5.2 实验环境与超参数设置

第三章 基于 Qwen3 与门控注意力的统一改进框架
• 3.1 整体架构设计
  • 3.1.1 T3Time 基线模型分析
  • 3.1.2 统一改进框架的整体设计思路
• 3.2 冻结大模型的适配器设计
  • 3.2.1 跨模态特征投影与维度对齐
  • 3.2.2 时序位置编码与语义嵌入设计
  • 3.2.3 适配器参数量与训练效率分析
• 3.3 门控注意力池化模块
  • 3.3.1 门控注意力池化的数学建模
  • 3.3.2 与传统注意力池化的对比分析
• 3.4 基线实验与统一改进有效性验证
  • 3.4.1 实验设置
  • 3.4.2 Qwen3-1.4B 与 GPT-2 的对比实验
  • 3.4.3 门控注意力机制的有效性验证
• 3.5 本章小结

第四章 基于小波包分解增强的时序预测模型
• 4.1 引言：非平稳信号下的局部时频分析需求
• 4.2 模型架构设计
  • 4.2.1 小波包多尺度分解策略
  • 4.2.2 频域子带特征与 LLM 嵌入空间的映射机制
  • 4.2.3 多尺度特征融合与预测头设计
• 4.3 实验设置与结果分析
  • 4.3.1 实验设置与对比基线
  • 4.3.2 MSE 指标表现及显著性分析
  • 4.3.3 极端波动场景下的预测可视化分析
  • 4.3.4 消融实验：小波包分解层数的影响
• 4.4 本章小结

第五章 基于频域前馈网络增强的时序预测模型
• 5.1 引言：全局频谱特征建模的优势
• 5.2 模型架构设计
  • 5.2.1 频域前馈网络结构设计
  • 5.2.2 复数域特征提取与门控权重融合机制
  • 5.2.3 频域-时域特征交互设计
• 5.3 实验设置与结果分析
  • 5.3.1 实验设置与对比基线
  • 5.3.2 MAE 指标表现及稳健性分析
  • 5.3.3 长期预测趋势平滑度分析
  • 5.3.4 消融实验：频域前馈网络深度的影响
• 5.4 本章小结

第六章 两种频域增强方法的对比分析与机理探讨
• 6.1 综合性能对比分析
  • 6.1.1 MSE 与 MAE 指标的对比结果
  • 6.1.2 不同数据集上的表现差异
• 6.2 误差特性机理分析
  • 6.2.1 小波包分解对大误差抑制的机理分析
  • 6.2.2 频域前馈网络对平均误差优化的机理分析
  • 6.2.3 MSE 与 MAE 分化的理论解释
• 6.3 计算复杂度与收敛性分析
  • 6.3.1 参数量与计算开销对比
  • 6.3.2 训练收敛速度与稳定性分析
• 6.4 不同应用场景下的模型选择策略
  • 6.4.1 基于误差敏感度的场景分类
  • 6.4.2 模型选择决策树
• 6.5 本章小结

第七章 总结与展望
• 7.1 研究工作总结
  • 7.1.1 主要研究内容回顾
  • 7.1.2 主要创新点与贡献
• 7.2 研究局限性分析
• 7.3 未来研究方向
  • 7.3.1 模型架构的进一步优化
  • 7.3.2 多任务学习与迁移学习扩展
  • 7.3.3 实际应用场景的工程化探索

参考文献

致谢

附录
• 附录 A：详细实验配置参数
• 附录 B：完整实验结果表格
• 附录 C：关键代码实现片段
