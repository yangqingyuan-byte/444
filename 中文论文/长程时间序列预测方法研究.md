# 北京交通大学

# 博士学位论文

# 长程时间序列预测方法研究

# Research on Long-range Time Series Forecasting

作者：贾宇欣

导师：林友芳

北京交通大学

2025年06月

# 北京交通大学

# 博士学位论文

# 长程时间序列预测方法研究

# Research on Long-range Time Series Forecasting

作者姓名：贾宇欣 学号:21112031

导师姓名：林友芳 职称：教授

学位类别：工学 学位级别：博士

学科专业: 计算机科学与技术 研究方向: 机器学习

北京交通大学

2025年06月


答辩委员会名单


<table><tr><td>答辩委员会</td><td>姓名</td><td>工作单位</td><td>职称</td></tr><tr><td>主席</td><td>贾彩燕</td><td>北京交通大学</td><td>教授</td></tr><tr><td>委员</td><td>王宁</td><td>北京交通大学</td><td>教授</td></tr><tr><td>委员</td><td>万怀宇</td><td>北京交通大学</td><td>教授</td></tr><tr><td>委员</td><td>高良才</td><td>北京大学</td><td>研究员</td></tr><tr><td>委员</td><td>张莹</td><td>华北电力大学</td><td>教授</td></tr><tr><td>秘书</td><td>郭晟楠</td><td>北京交通大学</td><td>副教授</td></tr></table>

# 摘要

时间序列是按照时间顺序排列的观测数据集合，用于刻画某一变量随时间的变化趋势。时间序列预测通过分析历史数据，构建模型，以预测未来一段时间内该变量的变化状态。精准的时间序列预测不仅能优化资源分配，为决策提供科学依据，如提升电网调度效率、缓解城市交通拥堵、支持灾害预警和促进农业生产，还在推动相关领域智能化发展方面具有重要的实际意义。时间序列预测方法可以根据预测的时间步跨度的长短进行分类，包括短程预测和长程预测。与短程预测相比，长程时间序列预测致力于预测更长的时间跨度，通常涉及数百甚至数千个时间步，以便能够为决策者提供更全面的未来趋势信息，从而支持长期规划和资源分配。然而，由于需要从历史数据中捕获更长的时间依赖关系，长程预测任务的建模难度会显著高于短程预测，对模型的表达能力也提出了更高的要求。

尽管基于深度学习的方法在时间序列预测领域取得了显著进展，但在处理长程预测任务时，如何实现高预测精度和高运行效率的平衡这一目标仍面临诸多挑战。首先，时间序列中蕴含的复杂时间模式（如趋势性模式、周期性模式、长期模式、短期模式、局部模式和全局模式）难以全面有效提取。其次，信息传递路径过长会导致信息损失，影响模型的预测精度。此外，多变量时间序列中存在的异质性（即不同变量间的显著差异）可能导致模式识别能力下降。最后，信息提取过程中一致性与差异性之间的矛盾，使得模型在时间和变量两个维度上同时兼顾并建模它们变得尤为困难。这些问题严重限制了现有方法在长程时间序列预测任务中的表现。针对上述挑战，本文提出了一系列创新性解决方案，旨在提升长程时间序列预测的精度和效率。

(1) 针对时间序列数据中蕴含的多种复杂时间模式难以有效提取方面的挑战，提出了水波型信息传递的长程时间序列预测方法（WITRAN），旨在从长期和短期的尺度上同时捕获周期性与趋势性模式和全局与局部模式。在方法中，设计了双粒度门控选择单元（HVGSU），水平方向从短期尺度上捕获趋势性模式，垂直方向从长期尺度上捕获周期性模式，随后通过信息的选择与融合操作建模上述模式的相关性。同时，为进一步提高模型的运算效率，提出了循环加速网络（RAN），实现了  $\mathcal{O}(\sqrt{T})$  的复杂度。在覆盖多个领域的五个真实场景下的基准数据集上的实验结果表明，WITRAN 在长程时间序列预测任务上的性能和效率方面均表现出色。

(2)针对长程时间序列预测任务中信息传递路径过长导致的信息损失方面的挑战,提出了并行门控机制的长程时间序列预测方法。其核心是并行门控网络(PGN),通过将信息传递路径缩短至  $\mathcal{O}(1)$ , 显著提升了对长程依赖关系的捕获能力,同时

保持了  $\mathcal{O}(T)$  的理论复杂度。在实际应用中，由于 PGN 可以并行计算，实际运行效率得到了大幅提升。为保证复杂时间模式信息的全面捕获，基于 PGN，提出了时间并行门控网络（TPGN）。TPGN 通过两个独立的分支分别从长期和短期两个尺度上，捕获局部周期性模式与全局趋势性模式，实现了复杂时间模式信息的全面捕获。TPGN 的计算复杂度为  $\mathcal{O}(\sqrt{T})$  ，具有高效的时间建模能力。在覆盖多个领域的五个真实场景下的基准数据集上的实验结果表明，TPGN 在长程时间序列预测任务上的预测性能和计算效率方面的表现均更为出色。

(3) 针对多变量间异质性导致模式混淆给建模带来的挑战，提出了变量完全独立（SCI）的建模方式。SCI 通过在关键层为每个变量分配独立参数，有效消除了变量异质性带来的影响，同时保持了  $\mathcal{O}(N)$  的理论复杂度。与此同时，为充分地捕获复杂时间模式，并尽可能缩短信息传递路径以降低信息损失，提出了一种简单的基于线性变换的双分支（DB）时间建模架构。并通过系统性地整合 SCI 范式与 DB 架构，提出了一种专门针对异质性多变量时间序列的长程预测模型（SCI Linear）。通过在覆盖多个领域的五个真实场景基准数据集上进行验证，SCI Linear 在多变量长程时间序列预测任务中，展现出出色的通道间异质性处理能力，能显著提高预测精度。

(4) 针对时间与变量双维度信息提取的一致性与差异性之间相互矛盾的挑战, 提出了一种万年历式信息提取方法, 并结合 SCI 和变量独立 (CI) 在变量维度信息提取上的一致性与差异性优势, 构建了万年历式信息提取网络 (CalendarNet)。CalendarNet 在时间维度建模上, 通过将时间序列重构为类似万年历的二维排布结构, 并结合窗口滑动机制, 能够有效地从长期尺度提取局部周期性模式。随后, 在短期尺度上, 有效对局部表示进一步建模趋势性变化, 同时保持相同数据量级的全局感受野。此外, CalendarNet 能够灵活采用 SCI 或 CI 建模方式, 更好地兼顾变量维度信息提取的一致性与差异性。通过在覆盖多个领域的五个真实场景下的基准数据集上进行实验, 结果表明, CalendarNet 在预测性能和运行效率上均展现出卓越的表现, 并具有更强的通用性。

综上所述，本文提出了一系列创新性方法，有效解决了长程时间序列预测中的关键挑战，显著提升了预测精度和运行效率。本文的研究成果为相关领域的研究和应用提供了新的思路和技术支持，具有重要的理论意义和实际应用价值。

关键词：长程时间序列预测；复杂时间模式；高预测精度与高运行效率；水波型信息传递；并行门控网络；变量完全独立建模；万年历式信息提取

# ABSTRACT

A time series is a collection of observed data arranged in chronological order, used to characterize the trend of a variable over time. Time series forecasting involves analyzing historical time series data to build models that predict the future values of a variable. Accurate time series forecasting not only optimizes resource allocation and supports decision-making, such as improving power grid dispatching efficiency, alleviating urban congestion, and assisting in disaster warnings and agricultural production, but also plays a crucial role in advancing intelligent development across related fields. Time series forecasting methods can be categorized based on the forecast time span, including short-range and long-range forecasting. Compared to short-range forecasting, long-range time series forecasting aims to predict over a much longer time span, often involving hundreds or even thousands of time steps. This allows decision-makers to gain a more comprehensive understanding of future trends, supporting long-term planning and resource allocation. However, since long-range forecasting requires capturing extended temporal dependencies from historical data, its modeling complexity is significantly higher than that of short-range forecasting, placing greater demands on the expressive power of the model.

Although deep learning-based methods have made significant progress in the field of time series forecasting, achieving a balance between high forecasting accuracy and computational efficiency in long-range forecasting remains a major challenge. First, the complex temporal patterns embedded in time series data (such as trend patterns, periodic patterns, long-term patterns, short-term patterns, local patterns, and global patterns) are difficult to extract comprehensively and effectively. Second, excessively long information transmission paths can lead to information loss, which affects the model's forecasting accuracy. Additionally, the heterogeneity present in multivariate time series (i.e., significant differences between different variables) may reduce the model's pattern recognition ability. Finally, the conflict between consistency and diversity in the information extraction process makes it particularly difficult for models to simultaneously capture and model both temporal and variable dimensions. These issues severely limit the performance of existing methods in long-range time series forecasting tasks. To address these challenges, this paper proposes a series of innovative solutions aimed at enhancing the accuracy and efficiency of long-range time series forecasting.

(1) To address the challenge of effectively extracting the complex temporal pat

terns inherent in time series data, this paper proposes a long-range time series forecasting method called WITRAN, based on Water-wave Information Transmission (WIT). The method aims to simultaneously capture both periodic and trend patterns, as well as global and local patterns, across both long-term and short-term scales. Additionally, a Horizontal-Vertical Gated Selective Unit (HVGSU) is designed. Horizontally, it captures trend patterns at the short-term scale, while vertically, it captures periodic patterns at the long-term scale. The correlations between these patterns are then modeled through information selection and fusion operations. Furthermore, to enhance the model's computational efficiency, a Recurrent Acceleration Network (RAN) is proposed, achieving a complexity of  $\mathcal{O}(\sqrt{T})$ . Experimental results on benchmark datasets from five real-world scenarios spanning multiple domains demonstrate that WITRAN excels in both performance and efficiency for long-range time series forecasting tasks.

(2) To address the challenge of information loss caused by excessively long information transmission paths in long-range time series forecasting tasks, a forecasting method incorporating a parallel gated mechanism is proposed. The core of this method is the Parallel Gated Network (PGN), which shortens the information transmission path to  $\mathcal{O}(1)$ , significantly improving the model's ability to capture long-range dependencies while maintaining a theoretical complexity of  $\mathcal{O}(T)$ . In practical applications, since PGN can be computed in parallel, its actual runtime efficiency is greatly enhanced. To ensure the comprehensive capture of complex temporal patterns, a Temporal Parallel Gated Network (TPGN) is proposed, built upon PGN. TPGN utilizes two independent branches to capture both local periodic patterns and global trend patterns at both long-term and short-term scales, enabling a full capture of complex temporal pattern information. TPGN has a computational complexity of  $\mathcal{O}(\sqrt{T})$ , offering efficient temporal modeling capabilities. Experimental results on benchmark datasets from five real-world scenarios across multiple domains demonstrate that TPGN outperforms other methods in both predictive performance and computational efficiency for long-range time series forecasting tasks.

(3) To address the challenge of pattern confusion caused by heterogeneity between variables in multivariate time series modeling, a Separate Channel Independent (SCI) modeling paradigm is proposed. SCI assigns independent parameters to each variable at key layers, effectively eliminating the impact of variable heterogeneity while maintaining a theoretical complexity of  $\mathcal{O}(N)$ . To fully capture complex temporal patterns and minimize information loss by shortening information transmission paths, a simple Dual-Branch (DB) temporal modeling architecture based on linear transformations is proposed.

By systematically integrating the SCI paradigm with the DB architecture, a long-range forecasting model specifically designed for heterogeneous multivariate time series, SCILinear, is introduced. Through validation on benchmark datasets from five real-world scenarios covering multiple domains, SCILinear demonstrates exceptional capability in handling variable-wise heterogeneity in multivariate long-range time series forecasting tasks, significantly improving prediction accuracy.

(4) To address the challenge of the contradiction between consistency and diversity in the extraction of both temporal and variable dimensional information, a Calendar-inspired information extraction method is proposed. By combining the advantages of SCI and Channel Independent (CI) in capturing consistency and diversity in variable dimension information extraction, CalendarNet is constructed. In the temporal dimension modeling, CalendarNet reconstructs the time series into a two-dimensional structure similar to a calendar and uses a sliding window mechanism, effectively extracting local periodic patterns from the long-term scale. Subsequently, on the short-term scale, it models trend changes in local representations while maintaining the same data scale for the global receptive field. Additionally, CalendarNet can flexibly adopt either SCI or CI modeling approaches, better balancing the consistency and diversity in variable dimension information extraction. Experimental results on benchmark datasets from five real-world scenarios, involving multiple domains, demonstrate that CalendarNet excels in both forecasting performance and computational efficiency, highlighting its superior versatility.

In summary, this paper proposes a series of innovative methods that effectively address the key challenges in long-range time series forecasting, significantly improving forecasting accuracy and computational efficiency. The research outcomes provide new ideas and technical support for research and applications in related fields, with important theoretical and practical value.

KEYWORDS: Long-range time series forecasting; Complex temporal patterns; High forecasting accuracy and high computational efficiency; Water-wave information transmission; Parallel gated network; Separate channel independent modeling; Calendar-inspired information extraction

# 目录

# 1绪论 1

1.1 研究背景与意义

1.2 研究面临的挑战与难点 ..... 2

1.3 国内外研究现状 5

1.3.1 基于传统统计学的时间序列预测方法 ..... 5

1.3.2 基于传统机器学习的时间序列预测方法 6

1.3.3 基于深度神经网络的时间序列预测方法

1.4本文的主要创新与贡献 9

1.5 本文的组织架构 ..... 11

# 2 时间序列预测相关定义及其基础方法与理论分析 13

2.1 时间序列预测问题的相关定义 13

2.2 基于线性变换的预测方法与理论分析 13

2.2.1 单层线性模型及其理论分析 ..... 13

2.2.2 多层线性模型及其理论分析 ..... 15

2.2.3 相关理论复杂度分析 ..... 15

2.3 基于循环神经网络的预测方法及理论分析 16

2.3.1 循环神经网络基本框架及其信息提取过程分析 16

2.3.2 循环神经网络主要变体及其信息提取过程分析 17

2.3.3 相关理论复杂度分析 ..... 18

2.4基于卷积神经网络的预测方法及理论分析 19

2.4.1卷积神经网络基本框架及其信息提取过程分析 19

2.4.2卷积神经网络主要变体及其信息提取过程分析 20

2.4.3 相关理论复杂度分析 ..... 23

2.5 基于注意力机制的预测方法及理论分析 ..... 24

2.5.1 注意力机制的基本框架及其信息提取过程分析 ..... 24

2.5.2 Transformer 理论复杂度分析 ..... 27

2.5.3 基于注意力机制的主要变体方法及相关理论分析 ..... 28

2.6 基于图神经网络的预测方法及其理论分析 31

2.6.1 图神经网络及其主要变体信息提取过程分析 31

2.6.2 相关理论复杂度分析 32

2.7 数据集与评价指标 33

2.7.1 数据集 33

2.7.2 评价指标 34

# 2.8 本章小结 34

3 水波型信息传递的长程时间序列预测方法 35

3.1 引言 35

3.2水波型信息传递与循环加速网络 39

3.2.1 输入模块 41

3.2.2 双粒度门控选择单元 ..... 42

3.2.3 循环加速网络 44

3.2.4 预测模块 44

3.2.5 理论复杂度分析 ..... 45

3.3 实验评估 45

3.3.1 基线方法 ..... 45

3.3.2 实验设置 46

3.3.3 预测性能分析 ..... 46

3.3.4运行效率分析 47

3.3.5 模型分析及讨论 ..... 51

3.4 本章小结 60

4 并行门控机制的长程时间序列预测方法 ..... 61

4.1 引言 61

4.2 并行门控网络 63

4.2.1 网络结构 64

4.2.2 理论复杂度分析 64

4.3 基于并行门控网络的长程时间序列预测方法 65

4.3.1 输入模块 66

4.3.2 长期信息提取分支 67

4.3.3 短期信息提取分支 67

4.3.4 预测模块 68

4.3.5 理论复杂度分析 68

4.4 实验评估 68

4.4.1 基线方法 68

4.4.2 实验设置 69

4.4.3 预测性能分析 69

4.4.4 运行效率分析 ..... 71

4.4.5 模型分析及讨论 ..... 72

4.5 本章小结 ..... 79

5 变量完全独立建模的多变量长程时间序列预测方法 ..... 81

5.1 引言 ..... 81

5.2 基于变量完全独立建模的线性预测方法 ..... 84

5.2.1 输入模块 ..... 84

5.2.2 变量完全独立的建模方式 ..... 85

5.2.3 变量完全独立的双分支时间建模框架 ..... 86

5.2.4 预测模块 ..... 87

5.2.5 变量完全独立建模方式的等价优化 ..... 87

5.2.6 理论复杂度分析 ..... 87

5.3 实验评估 ..... 88

5.3.1 基线方法 ..... 88

5.3.2 实验设置 88

5.3.3 预测性能分析 ..... 89

5.3.4 运行效率分析 91

5.3.5 模型分析及讨论 ..... 92

5.4 本章小结 ..... 98

6万年历式信息提取的多变量长程时间序列预测方法 99

6.1 引言 99

6.2 万年历式信息提取网络 ..... 104

6.2.1 输入模块 ..... 104

6.2.2 周期性提取模块 ..... 105

6.2.3 趋势性提取模块 ..... 106

6.2.4 等价优化的周期性和趋势性提取模块 ..... 107

6.2.5 信息融合模块 ..... 108

6.2.6 预测模块 ..... 109

6.2.7 理论复杂度分析 ..... 109

6.3 实验评估 ..... 109

6.3.1 基线方法 ..... 110

6.3.2 实验设置 110

6.3.3 预测性能分析 110

6.3.4 运行效率分析 ..... 112

6.3.5 模型分析及讨论 ..... 113

6.4 本章小结 ..... 120

7 总结与展望 ..... 121

7.1 论文工作总结 ..... 121

7.2 未来工作展望 ..... 122

参考文献 125

# 1 绪论

时间序列（Time Series）是按时间先后顺序排列的一组观测数据，用于刻画变量随时间的演变态势[1]。在现实世界中，时间序列数据能够被广泛采集于能源管理、交通运输、气象分析等多个关键领域。对这些时间序列数据进行深入分析并实现精准预测，对于优化资源配置、提升决策效率以及推动相关领域的智能化发展具有重要意义。

在能源领域[2]，准确预测电网节点的电力需求有助于提前制定发电计划，优化电力调度，从而降低资源浪费和运营成本。在交通领域[3]，精准预测路段交通流量可为交通管理部门提供决策支持，引导车辆分流，缓解交通拥堵，提升道路通行效率。在气象领域[4]，通过对风速、湿度、温度等气象要素的分析与预测，气象部门可提供更精确的天气预报，为公众生活、农业生产及灾害预防提供科学依据。由此可见，时间序列预测具有广泛的实际价值[5]。

与短程时间序列预测（Short-range Time Series Forecasting）相比，长程时间序列预测（Long-range Time Series Forecasting）需要预测的时间跨度显著增加，通常涉及上百甚至上千个时间步，如图1-1所示。虽然长程预测任务需要从历史序列中捕获更长的时间依赖关系，建模难度显著高于短程预测，但它能够提供未来更长时间范围内的变化趋势，为决策者预留更充足的应对时间，因此具有更高的应用和研究价值。长程预测任务的核心目标是通过历史时间序列数据，准确推断未来较长时间范围内的数值变化，从而为相关领域的长期规划与决策提供科学依据[6]。

![](images/03ee033838c99c6e1fea645960397277eacb63529469f89b4b5404d2e05f83d2.jpg)



图1-1 长程时间序列预测示意图



Fig 1-1 Long-range time series forecasting.


# 1.1 研究背景与意义

近年来，随着信息技术的快速发展，时间序列预测面临着数据规模激增和应用需求升级的双重挑战。以智能交通领域为例[7-9]，复杂的路网结构和实时变化的交通状况对预测方法提出了更高的要求，需要同时满足预测精度和实时性的双重标准。传统的时间序列预测方法[10-14]通常依赖于特定的理论假设，而现实中的时间序列数据往往具有动态性和复杂性，这严重限制了其在实际应用中的预测性能。

随着人工智能和机器学习技术的快速发展，基于深度神经网络（Deep Neural Network, DNN）的方法为时间序列预测提供了新的解决方案[15-17]。线性层通过简单的映射关系实现了历史数据与未来预测值之间的直接关联；循环神经网络（Recurrent Neural Network, RNN）凭借其循环结构，能够有效捕获时间序列的动态特性[18,19]；卷积神经网络（Convolutional Neural Network, CNN）利用卷积核的局部感受野和权值共享机制，能够有效提取局部特征[20,21]；基于注意力机制的Transformer模型[22]在处理时间序列数据时，能够有效捕获远距离时间步之间的依赖关系[23,24]。

然而，这些基础性深度学习方法也各自存在局限性，特别是在面对长程时间序列预测任务时。线性模型的表达能力有限，难以处理复杂的非线性关系；RNN在处理长序列时容易出现梯度消失或爆炸问题[25]，难以有效捕获远距离依赖关系；CNN虽然擅长提取局部特征，但由于卷积核感受野的限制，通常需要多层结构才能捕获全局信息，从而增加了模型的复杂度和训练难度[26]；而Transformer虽然能够捕捉远距离依赖，但其点乘注意力机制难以捕获时间序列中的语义信息，并且对计算资源的需求较高[27]。

鉴于这些局限性，研究适用于长程时间序列的预测方法，需要围绕两个核心目标展开：

核心目标一：提升预测精度。时间序列数据中蕴含着复杂的时间依赖模式和丰富的语义信息，例如周期性重复模式、总体发展趋势、局部变化波动等。这些特征在时间维度上呈现出复杂的耦合关系，贯穿于整个观测序列。因此，充分利用历史时间序列，分析并提取出这些潜在的特征，是提升预测精度的关键。

核心目标二：提高运行效率。在长程时间序列预测任务中，数据量的增加本身就会带来资源开销方面的压力。考虑到模型的实际部署与训练需求，如何在优先确保预测准确性的同时尽可能降低模型开销，也是研究的重要核心目标。

尽管根据没有免费午餐定理（No Free Lunch Theorem），同时提升预测精度与计算效率存在固有的理论限制，但在面对多领域的实际应用需求时，实现二者的有效平衡非常重要。为此，本研究将针对长程时间序列预测的核心目标，提出一系列适用于多个应用领域的通用预测方法，旨在提升预测精度和实用性，为相关领域的决策支持提供更可靠的技术保障。

# 1.2 研究面临的挑战与难点

如1.1节所述，由于固有理论的限制，同时提高预测精度和计算效率本身就是研究面临的核心挑战。然而，本文将模型运行效率的优化纳入整体设计目标，因

此本节将重点分析提升预测精度所面临的挑战与难点。

长程时间序列预测任务可根据变量维度分为单变量预测和多变量预测两种类型，这两者在任务性质上存在显著差异。尽管从理论上看，多变量时间序列预测可视为多个单变量预测任务的叠加，但在实际应用中，为每个变量单独设计预测模型会显著增加建模复杂性和计算资源的消耗，从而极大地影响预测方法的效率和可扩展性。因此，针对多变量的长程预测任务，研究的重点在于构建一个统一的预测框架，对多个变量进行综合建模。

需要强调的是，无论时间序列的研究对象是单个变量还是多个变量，有效提取和利用时间模式信息都是关键所在。由此，研究面临两方面具体的挑战与难点：

# 挑战与难点一：如何充分捕获复杂的时间模式信息。

时间序列数据通常蕴含多种复杂的时间模式信息。从时间波动的角度分析，可将其分为趋势性模式和周期性模式；从语义尺度的角度分析，可将其分为长期模式和短期模式；从信息粒度的角度分析，则可将其分为局部模式和全局模式。

(1) 趋势性模式和周期性模式：趋势性反映了时间序列在一段时间内的变化模式，是预测未来数据的重要初始条件。准确捕获趋势性可确保预测结果与当前数据状态一致。例如，在交通流量预测中，城市交通的持续增长趋势受城市规划和人口规模增长等因素的影响。周期性是指数据在特定时间间隔内的重复模式。例如，交通流量在工作日的早晚高峰时段通常表现出相似的波动特性。有效利用周期性信息能够显著提升长程预测的稳定性。

(2) 长期模式和短期模式: 长期 (Long-term) 和短期 (Short-term) 反映的是数据的语义尺度特性, 与长程和短程依据数据点数量进行界定的方式不同, “长期和短期”与“长程和短程”在定义上存在本质区别。例如, 对于按小时粒度采集的一周交通流量数据（共168个数据点），每天内包含24个采样点，这种基于小时尺度的模式即为短期模式。相较之下，同一小时在跨天时间尺度的变化趋势，尽管数据点的数量更少（为7个），但它所反映的却是长期模式。

(3) 局部模式和全局模式：局部模式反映了短时间内的动态变化，如高峰和非高峰时段的交通流量差异；全局模式则包含整体上下文信息，有助于理解长期趋势和周期性变化。整合全局信息能够降低对局部噪声的敏感性，从而增强模型的鲁棒性。

上述信息对于提升预测精准度至关重要，但由于它们具有不同特性且可能相互影响，因此，全面捕获这些信息成为构建时间序列预测方法的核心挑战。

# 挑战与难点二：如何减少信息在传递过程中的损失。

在长程（Long-range）时间序列预测中，准确捕获时间步之间的依赖关系对于深入分析时间序列的复杂模式至关重要，这一过程高度依赖于信息的有效传递。特

别是，长程时间步间的信息高效传递能够帮助模型从长期尺度更精准地识别数据中的潜在规律，从而提升预测精度。例如，在交通流量预测任务中，周一的早高峰往往与上周五的早高峰关系更为紧密，而非与前一天（周日）的模式更相关。

然而，根据信息瓶颈理论，智能系统在处理信息过程中只能存储有限的信息，导致信息传递路径越长，信息损失越显著[28]。为了解决这一问题，优化信息传递路径至关重要。通过缩短信息传递路径，可以有效减少信息损失，更好地捕捉时间序列中的长程依赖关系，同时降低模型训练难度。因此，如何优化信息传递路径以最小化时间步间信息传递带来的损失，成为构建高性能预测模型的另一个重要挑战。

综上所述，在时间信息的提取和捕获方面，充分捕获复杂的时间模式信息（挑战与难点一）和减少信息传递过程中的损失（挑战与难点二）在信息层面上相辅相成，共同为提升预测精度奠定了关键基础。

然而，当时间序列的研究对象为多个变量时，不同变量可能表现出截然不同的时间模式。这种在同一时段内变量间关系的显著差异，通常被称为异质性。这进一步引出了第三个挑战与难点：

# 挑战与难点三：如何有效处理多变量间的异质性。

若未对变量间的异质性进行有效处理，可能会引发两方面问题，从而直接影响预测方法的性能：（1）变化特性混淆：相反趋势变量的信息直接融合会导致各自的变化特性混淆，进而降低模式识别的准确性；（2）幅值特征丢失：相同变化趋势的变量间可能存在幅度差异，直接叠加会使其局部特性被全局幅度掩盖，导致关键信息丢失。因此，如何设计差异化处理机制以应对多变量间的异质性，成为解决多变量预测任务的核心挑战。

多变量间的异质性来源于时间序列数据的固有特性。然而，在某些情况下，异质性可能并不显著，甚至共性特征可能起到更重要的作用。此时，模型需要确保捕获变量间的一致性信息。另外，在时间维度上也需要兼顾信息提取的一致性与差异性。因此，进一步引出了第四个挑战与难点：

# 挑战与难点四：如何在时间与变量双维度上兼顾信息提取的一致性与差异性。

变量维度信息的一致性与差异性取决于数据的固有特性，可通过现有方法或其改进方案加以有效处理。相比之下，时间维度信息提取的一致性与差异性则需要依赖于模型的特殊设计来加以实现。

在时间维度上，信息提取的一致性要求每个预测点所使用的特征基于相同长度的历史序列数据生成，具有相同的数据量级和统一的生成方式。这种一致性能够避免因信息量差异导致的预测偏差，从而提高预测结果的准确性和可靠性。差异性则强调保留不同时间步的独特变化态势，使模型能够更全面地捕获时间序列

的复杂模式，从而提升预测精度。

尽管一致性与差异性对于提升预测精度均至关重要，但它们在某种程度上是相互矛盾的：一致性强调统一的信息提取方式，而差异性则强调个性化的信息提取方式。因此，如何在两者之间找到平衡点，是研究面临的一个复杂而关键的挑战。更进一步，在时间与变量两个维度上兼顾信息提取的一致性与差异性，则是一个更大的挑战与难点。

# 1.3 国内外研究现状

时间序列预测方法主要可以总结为三大类：传统统计学方法、传统机器学习方法以及基于深度神经网络的方法。本节将分别从这三个类别出发，对国内外研究现状进行总结与分析。

# 1.3.1 基于传统统计学的时间序列预测方法

传统的时间序列分析方法主要基于统计学理论，其核心思想是通过统计建模提取数据中的趋势性、周期性和波动性等关键特征。由于其简单性、可解释性以及在实际应用中的高效性，这些方法在经济、金融等领域得到了广泛应用。常用的模型主要包括以下几类：

(1) 自回归差分移动平均模型 (ARIMA)[11]：由 Box 和 Jenkins 提出，ARIMA (AutoRegressive Integrated Moving Average) 模型结合了自回归 (AR)、差分 (I) 和移动平均 (MA) 三个部分，适用于平稳时间序列的预测，能够有效捕获线性趋势和波动性变化。其扩展形式 SARIMA[29] 进一步引入了季节性分量，适用于具有周期性特征的时间序列。

(2) 指数平滑法[12]：该方法通过对历史数据进行加权平均来预测未来值，适用于捕捉时间序列的平滑趋势。其变体Holt-Winters模型[29]进一步引入了趋势性和周期性分量，从而能够有效处理具有显著季节性变化的时间序列。

(3) Prophet 模型[13]：由 Facebook 开发，Prophet 模型结合了趋势分解、周期性建模以及节假日效应，能够自适应处理缺失值和异常值，适用于商业预测和宏观经济分析。凭借其灵活性和鲁棒性，该方法在处理复杂时间序列数据时表现优异，尤其适用于不规则波动或多变趋势的场景。

尽管传统统计方法在特定场景下表现良好，但现实世界的时间序列数据往往具有复杂的变化模式，使得这些方法在处理此类数据时，性能受到显著限制。具体而言，传统统计方法的局限性主要体现在以下几个方面：

(1) 线性假设的局限性: 此类方法通常假设时间序列呈线性关系, 难以有效捕获复杂的非线性模式, 这限制了其在非线性数据场景中的适用性。

(2) 平稳性假设的不足: 许多经典模型 (如 ARIMA) 要求时间序列满足平稳性条件, 即数据的统计特性 (如均值和方差) 在时间上保持稳定。然而, 实际数据往往是非平稳的, 需要进行差分、对数变换等预处理操作, 这不仅增加了建模的复杂性, 还可能导致信息损失。

(3) 高维数据处理能力的欠缺: 在面对多变量时间序列或高维数据时, 传统方法的适用性较弱, 难以有效适应复杂的数据变化, 限制了其在大规模预测任务中的应用。

# 1.3.2 基于传统机器学习的时间序列预测方法

随着计算能力的提升和数据科学的快速发展，传统机器学习方法在时间序列预测领域得到了广泛应用。这些方法能够有效处理非线性关系和高维数据，且通常不依赖于严格的平稳性假设。然而，它们在捕获长程时间依赖关系和动态演化模式方面仍存在一定局限性。

(1) 支持向量机 (SVM)[30]: SVM (Support Vector Machine) 通过核技巧[31]能够有效处理非线性映射, 在电力负荷预测和风速预测等任务中表现出色。然而, SVM在处理大规模时间序列数据时面临较高的计算复杂度, 且其训练过程未充分考虑时间序列的顺序性和依赖关系, 因此在长程预测任务中效果受限。

(2) 梯度提升决策树 (GBDT)[32]: 以 XGBoost[33] 和 LightGBM[34] 为代表的 GBDT (Gradient Boosting Decision Tree) 方法, 采用加法模型和梯度下降优化策略,在金融时间序列预测等任务中取得了较好的效果。尽管这些方法在短程预测任务中表现优异, 但在捕获远距离时间步之间的依赖关系和动态模式变化时仍存在一定不足。此外, GBDT 对特征工程的依赖较大, 通常需要手动调整特征, 这可能影响其在不同应用场景中的泛化能力。

(3) 随机森林 (Random Forest)[35]：随机森林基于集成学习框架，通过并行训练多个决策树，能够有效处理多变量时间序列数据。在交通流量预测、空气质量预测等任务中，表现出了较好的性能[36,37]。然而，随机森林同样存在时间依赖关系建模方面的局限性。此外，尽管随机森林能够处理非线性关系，但在高维数据环境下可能面临过拟合问题，从而影响预测的准确性和稳定性。

总结来说，传统机器学习方法在建模复杂时间依赖关系和处理高维数据方面存在局限，这为深度学习方法的引入和发展创造了重要契机。

# 1.3.3 基于深度神经网络的时间序列预测方法

近年来，深度学习技术[38]在时间序列分析领域取得了显著进展。与传统方法不同，深度神经网络能够自适应地学习多层次的时间依赖关系，而无需依赖手动设计的特征工程。通过端到端的学习方式，深度学习模型能够自动提取并建模复杂的时间模式，从而显著提高预测精度。然而，这些模型也面临着大规模数据需求和高计算资源消耗等挑战。当前的研究重点主要集中在如何应对这些问题，以提升模型在实际应用中的效率与可扩展性。

总体而言，基于深度神经网络的时间序列预测方法可从建模对象的角度划分为两类：一类是针对时间维度进行建模的方法，另一类是针对变量维度进行建模的方法。

# (1) 时间 (Temporal) 维度的建模方法

针对时间维度的建模方法大致可分为四种范式：基于线性变换的方法、基于循环神经网络（Recurrent Neural Network, RNN）的方法、基于卷积神经网络（Convolutional Neural Network, CNN）的方法以及基于注意力机制的方法。

基于线性变换的方法因其结构简单、计算复杂度低且信息传递路径较短，在时间序列预测中得到了广泛关注。这类模型的简洁性不仅使其易于实现和训练，也促进了其在该领域的广泛应用和快速发展。DLinear[39]和NLinear[39]通过引入序列分解和时间维度归一化策略，在保留线性变换实现从历史输入到未来预测直接映射特点的同时，进行了有效改进，从而增强了模型对时间序列的适应能力。然而，直接映射的方式仍使得复杂的时间模式难以被捕获。TimeMixer[40]设计了双模块架构，采用多尺度建模来提取时间序列特征。尽管该方法在捕捉周期性模式方面表现优异，但多尺度计算不可避免地增加了计算开销和训练难度。FITS[41]创新性地将时间序列预测转化为频域插值问题，通过低通滤波器（LPF）模块和线性层实现预测。然而，这种频域转换使得FITS主要聚焦于时间序列的全局特性，限制了其对局部动态变化模式的建模。

基于 RNN 的方法[42] 严重依赖顺序执行的循环结构，这使得它们在捕捉长期依赖关系时面临挑战，并且容易出现梯度消失或爆炸的问题[25]。与此同时，由于其顺序性计算，尽管 RNN 的理论复杂度与序列长度  $T$  呈线性关系（见 2.3 节），但其实际运行速度可能甚至比 Transformer[22] 的  $\mathcal{O}(T^2)$  理论复杂度（见 2.5 节）还要慢。虽然出现了一些变体[43-45]尝试通过引入专门的门控机制来提升性能，但相比 RNN 结构固有的局限性，这些在信息选择和融合方面的改进无疑是杯水车薪。为了克服这些问题，一些方法开始尝试优化传统 RNN 的循环结构。DilatedRNN[46] 引入了一种多尺度扩张机制，在每个时间步聚合信息。尽管它能够通过选择最大跳跃

步长的分支来缩短信息传递路径，但该路径仍与序列长度  $T$  呈线性关系，依然相对较长。SlicedRNN[47]通过将序列划分为多个切片以实现并行计算，解决了RNN效率低下的问题。然而，在信息传递路径方面，SlicedRNN仍然面临与DilatedRNN类似的局限性，仍然难以高效地提取信息。

基于CNN的方法[48-50]具有  $\mathcal{O}(T)$  的理论复杂度，并且由于其优越的并行计算能力，实际计算效率通常优于RNN。然而，CNN在时间序列建模中通常沿时间步直接构建一维卷积核，这使得它难以有效捕捉周期性特征。针对这一问题，TimesNet[51]提出了二维建模方法，通过多尺度分支，多次将输入序列转置为两个维度，结合Inception[52]结构来提取信息，从而有效捕获周期性模式。

然而，CNN方法会受到卷积核局部感受野的限制，需要堆叠多个卷积层才能捕获全局信息。卷积层的数量  $G$  与序列长度  $T$  呈超线性增长，从而使得基于CNN的方法的信息传递路径为  $\mathcal{O}(G)$  。这不仅增加了计算开销，还提高了模型训练的难度。为了解决这一问题，MICN[26]和ModernTCN[53]通过扩大卷积核的感受野来缩短信息传递路径，从而高效提取全局信息。但相比之下，它们在提取周期性特征方面不如TimesNet[51]有效。

基于注意力机制的方法在时间序列预测领域仍然占据主导地位。基于点积注意力机制的方法，如Transformer[22]、Informer[2]和FEDformer[54]，其优势在于具有 $\mathcal{O}(1)$ 的信息传递路径。然而，已有研究[51]明确指出，这些方法在捕获时间步的语义信息方面存在一定局限性。另一方面，采用非点积注意力机制的方法同样面临着其他限制。Autoformer[55]通过序列分解在一定程度上能够捕获时间序列的周期性，但这一过程可能导致信息损失，同时其理论复杂度高达 $\mathcal{O}(T\log T)$ 。Pyraformer[56]通过金字塔结构的特殊设计，能够有效提取序列的周期性特征。然而，由于其需要使用CNN来初始化金字塔结构的节点，因此仍然会受到卷积核感受野的限制。此外，结合其 $\mathcal{O}(T)$ 理论复杂度的注意力计算，总体复杂度依然较高。PatchTST[27]通过先使用Patch化操作提取局部特征，再利用注意力机制进行局部特征间的信息聚合，从而将理论复杂度进一步降低至 $\mathcal{O}((T/S)^2)$ ，其中 $S$ 表示步长。然而，该方法仍无法直接捕获时间序列的周期特性。

# (2) 变量 (Variable) 维度的建模方法

变量建模在提升多变量时间序列预测精度方面发挥着关键作用。总体而言，这些方法可以总结为：基于变量融合建模（又称通道依赖建模）（Channel Dependent, CD）的方法、基于变量独立建模（又称通道独立建模）（Channel Independent, CI）的方法、基于图神经网络（Graph Neural Networks, GNN）的方法以及基于注意力机制的方法。

基于变量融合建模的方法通过融合多个变量的信息来学习变量间的全局依赖

关系，早期的研究[22,54-56]大多采用这种方式。然而，由于多变量之间的异质性[2]，这种方式可能会导致变量间的信息相互约束，进而使得它们相互成为噪声，影响预测结果。

基于变量独立建模的方法假设变量间相互独立，并使用相同的参数对每个变量进行单独计算。典型的代表性方法包括DLinear[39]、PatchTST[27]和FITS[41]。这类方法在有效消除变量间相互约束方面表现良好，特别适用于处理具有异质性变量的数据集。值得注意的是，已有研究[57]指出，在一些数据集中，不同变量之间存在显著的分布差异，这使得变量独立建模的方法在这些场景中更具优势。

基于图神经网络的方法通过将变量视为节点，并构建合适的图结构来表示变量间的依赖关系，从而聚合变量间的信息。CrossGNN[58]和FourierGNN[59]是此类方法的代表性工作。然而，在处理变量数为  $N$  的时间序列时，仅建模变量间的相关性所需的理论复杂度就高达  $\mathcal{O}(N^2)$  （见2.6节）。因此，在处理大规模数据集时，可能会出现设备内存不足（Out of Memory, OOM）或运行速度低下等问题，从而限制了其实际应用能力。

基于注意力机制的方法在变量建模中也得到了广泛应用，因为它能够自适应地计算变量间的相关性，并有效地聚合信息，具有良好的可解释性和灵活性。Crossformer[60]和Transformer[61]是这类方法的代表。前者在时间和变量两个维度上均使用注意力机制进行计算；而后者则在时间维度上采用Patch方法进行特征聚合，然后利用注意力机制计算变量间的相关性。尽管这些方法取得了一定的成效，但仍面临前文提到的注意力机制的局限性和较高的计算复杂度问题。

# 1.4 本文的主要创新与贡献

本文致力于长程时间序列预测方法的研究，旨在实现预测精度与预测效率的双重提升。针对时间序列数据中复杂时间模式的提取难题、信息传递路径过长引发的信息损失、多变量间异质性导致的模式混淆，以及信息提取的一致性与差异性之间的矛盾等挑战，本文提出了一系列创新性的解决方案。本文的主要研究内容、解决方案及其对应的章节如图1-2所示。具体而言，本文的研究内容及其创新与贡献可总结为以下几个方面：

(1) 针对时间序列数据中蕴含的多种复杂时间模式难以有效提取方面的挑战,本文提出了一种水波型信息传递的长程时间序列预测方法——水波型信息传递和循环加速网络 (WITRAN), 旨在从长期和短期的尺度上同时捕获周期性与趋势性模式和全局与局部模式。具体而言, 在水波信息传递 (WIT) 框架中设计了双粒度门控选择单元 (HVGSU), 水平方向从短期尺度上捕获趋势性模式, 垂直方向从长

期尺度上捕获周期性模式，并通过信息的选择与融合操作捕获上述模式间的相关性。同时，HVGSU的循环结构能够逐步捕获序列局部到全局的模式信息，从而显著提升预测精度。为了进一步提高模型的运算效率，本文还提出了循环加速框架(RAN)，实现了  $\wp (\sqrt{T})$  的复杂度，以提升运行效率。在覆盖多个领域的五个真实场景下的基准数据集上的实验结果表明，WITRAN在长程时间序列预测任务上的性能和效率方面均表现出色。

(2) 针对长程时间序列预测任务中信息传递路径过长导致的信息损失方面的挑战, 本文提出了一种并行门控机制的长程时间序列预测方法。其核心由并行门控网络 (PGN) 构成, PGN 通过将信息传递路径缩短至  $\mathcal{O}(1)$ , 显著提升了对长期依赖关系的捕获能力, 同时保持了  $\mathcal{O}(T)$  的理论复杂度。在实际应用中, 由于 PGN 可以并行计算, 实际运行效率得到了大幅提升。基于 PGN, 本文还提出了时间并行门控网络 (TPGN), 以实现复杂时间模式信息的全面捕获。TPGN 通过两个独立的分支分别从长期和短期两个尺度上, 捕获局部周期性模式与全局趋势性模式, 其复杂度为  $\mathcal{O}(\sqrt{T})$ , 具有高效的时间建模能力。在覆盖多个领域的五个真实场景下的基准数据集上的实验结果表明, TPGN 在长程时间序列预测任务上的预测性能和计算效率方面的表现均更为出色。

(3) 针对多变量间异质性导致模式混淆给建模带来的挑战, 本文提出了变量完全独立建模 (Separate Channel Independent, SCI) 范式。该方法通过为每个变量分配独立参数, 从而有效消除了变量异质性带来的影响, 同时保持了  $O(N)$  的理论复杂度。与此同时, 为充分地捕获复杂时间模式, 并尽可能缩短信息传递路径以降低信息损失, 本文还提出了一种简单的基于线性变换的双分支 (Dual-Branch, DB) 时间建模架构。并通过系统性地整合 SCI 范式与 DB 架构, 提出了一种专门针对异质性多变量时间序列的长程预测模型——SCI Linear。在多变量长程时间序列预测任务中的实验结果表明, 该方法在覆盖多个领域的真实场景基准数据集上, 能够出色地处理变量间的异质性, 进一步显著提升预测精度。

(4) 针对时间与变量双维度信息提取的一致性与差异性之间相互矛盾的挑战,本文提出了一种万年历式信息提取方法, 并结合 SCI 和 CI 在变量维度信息提取上的一致性与差异性优势, 构建了万年历式信息提取网络 (CalendarNet)。该方法通过将时间序列重构为类似万年历的二维排布结构, 并结合窗口滑动机制, 能够有效地从长期尺度提取局部周期性模式。随后, 在短期尺度上, 有效对局部表示进一步建模趋势性变化, 同时保持相同数据量级的全局感受野。通过一系列机制的协同作用, CalendarNet 在兼顾时间维度信息提取的一致性与差异性的同时, 深入挖掘了复杂的时间模式。同时, CalendarNet 根据数据集的特性, 适配性地通过 SCI 或 CI 建模方式, 以兼顾变量维度信息提取的一致性与差异性。通过在五个真实场

景下的基准数据集上的实验表明，CalendarNet在预测性能和运行效率上均展现出卓越的性能，并更具通用性。

![](images/c55793de892c35536ba9516db9c3ab81f4eb5edc871bd055cfebde5952845d78.jpg)



图1-2 研究内容框架



Fig 1-2 The overall research framework.


# 1.5 本文的组织架构

本文以长程时间序列预测任务为应用场景，围绕第1.2节描述的研究挑战和难点展开研究，全文的章节组织安排如下：

第1章为绪论。首先，阐述了时间序列及时间序列预测任务的基本概念，并深入探讨了长程时间序列预测的研究背景与意义。随后，系统梳理和分析了国内外在长程时间序列预测领域的研究现状，指出了当前研究面临的主要挑战与不足。最后，概述了本文的主要研究内容及贡献，并详细说明了全文的组织架构安排。

第2章为相关定义与理论基础。本章首先对长程时间序列进行了形式化定义，明确了研究对象的数学表达。接着，本文详细介绍了研究所依托的背景知识与相关理论技术，从信息提取过程、复杂度等方面对线性模型、循环神经网络、卷积神经网络、注意力机制、图神经网络以及这些基础方法的主要变体进行了深入分析，为后续研究奠定了坚实的理论基础。最后，介绍了本文研究所使用的数据集和评价指标，为实验部分的展开提供了必要的基础。

第3章提出了一种水波型信息传递的长程时间序列预测方法。该方法设计了双方向的信息传递机制，能有效从长期和短期尺度上捕获周期性与趋势性模式、局

部与全局模式，从而显著提升预测精度。同时，基于提出的通用加速框架，进一步优化了模型的运行效率。通过在五个真实场景的基准数据集上的实验，验证了该方法的有效性和高效性。

第4章提出了一种并行门控机制的长程时间序列预测方法。本章首先提出了并行门控网络，其作为一种全新范式，能够有效缩短信息传递路径，以减少信息损失，提升了预测精度。另一方面，其通过可并行计算的设计，优化了运行效率。为解决充分捕获复杂时间模式的挑战，本章基于并行门控网络，进一步设计了适用于长程时间序列预测任务的时间建模方法。实验在五个真实场景的基准数据集上展开，验证了该方法在性能和效率方面的显著优势。

第5章提出了变量完全独立建模的范式，通过为每个变量分配独立参数，并在关键层进行使用，确保前向计算和反向传播过程中参数的完全独立性，有效解决了多变量间异质性带来的影响。同时，在本章中还提出了一种基于变量完全独立建模的多变量长程时间序列预测方法，以同时解决充分捕获复杂时间模式和减小信息传递过程中损失的双重挑战。实验在五个真实场景的公开数据集上展开，验证了该方法在多变量长程时间序列预测任务上处理变量间异质性方面的性能和效率上的显著优势。

第6章提出了一种基于万年历式信息提取的多变量长程时间序列预测方法。该方法从万年历的循环结构中汲取灵感，通过将一维时间序列转换为二维布局并结合滑动窗口机制和门控机制，在充分捕获复杂时间模式和减少信息传递损失的同时，兼顾了时间维度信息提取的一致性与差异性。同时，通过适配性地引入第5章中提出的变量完全独立建模方式和先前已有的变量独立建模方式，进一步优化了变量维度信息提取的一致性与差异性，从而提高了预测的准确性和稳定性。在五个真实场景的基准数据集上的实验，验证了该方法在有效性、高效性和通用性方面的卓越表现。

第7章为总结和展望。本章系统地总结了全文的研究内容与核心贡献，并对未来研究的优化方向进行了展望。

# 2 时间序列预测相关定义及其基础方法与理论分析

本章聚焦于本文研究的核心应用场景——时间序列预测任务展开介绍。首先，阐述该问题的基本定义，并对各类代表性基础方法进行理论分析，包括基于线性变换、循环神经网络、卷积神经网络、注意力机制和图神经网络的相关方法。最后，本章将详细描述与本研究相关的数据集和评价指标。

# 2.1 时间序列预测问题的相关定义

给定一个历史时间序列  $\mathbf{X} = \{\pmb{x}_1, \pmb{x}_2, \dots, \pmb{x}_T\} \in \mathbb{R}^{T \times N}$ ，其中  $\pmb{x}_t \in \mathbb{R}^N$  表示第  $t$  个时间步的观测值， $T$  表示历史时间步的数量， $N$  表示每个观测值的变量维度。时间序列预测任务的目标是利用这些历史数据对未来的时间序列  $\mathbf{Y} = \{\pmb{y}_1, \pmb{y}_2, \dots, \pmb{y}_F\} \in \mathbb{R}^{F \times M}$  进行预测，预测的输出序列为  $\hat{\mathbf{Y}} = \{\hat{\pmb{y}}_1, \hat{\pmb{y}}_2, \dots, \hat{\pmb{y}}_F\} \in \mathbb{R}^{F \times M}$ ，其中  $\pmb{y}_t \in \mathbb{R}^M$  表示第  $t$  个时间步的真实值， $\hat{\pmb{y}}_t \in \mathbb{R}^M$  表示第  $t$  个时间步的预测值， $F$  表示预测的步长， $M$  表示预测序列的变量维度。

通常情况下，历史时间序列的变量数  $N$  与预测序列的变量数  $M$  是相等的。若  $N = M = 1$  ，则为单变量时间序列预测任务；若  $N = M \neq 1$  ，则为多变量时间序列预测任务。本研究主要围绕这两种任务的长程实际应用场景展开研究，因此在后文中，将统一使用  $N$  表示时间序列的变量维度。

此外，时间序列通常具有对应的时间戳。历史时间序列的时间戳可以表示为  $\mathbf{TF}_{\mathrm{hist}} \in \mathbb{R}^{T \times D}$ ，而未来时间序列的时间戳则可以表示为  $\mathbf{TF}_{\mathrm{pred}} \in \mathbb{R}^{F \times D}$ ，其中  $D$  代表时间戳的维度。

# 2.2 基于线性变换的预测方法与理论分析

本节主要分析基于单层线性模型和多层线性模型的时间序列预测方法，重点讨论这些模型在实际应用中的优势与局限性。与此同时，结合相关公式，进一步推导并分析它们的理论复杂度，为后续的分析奠定基础。

# 2.2.1 单层线性模型及其理论分析

单层线性模型[62]通过简单的线性变换实现输入到输出的直接映射，具有结构简单、易于实现的特点。该模型可在输出层选择性地引入非线性激活函数，以增强其表达能力。

在时间序列预测领域，Zeng等人[39]重新审视了单层线性模型的潜力，提出了相关优化方法，使其能够更好地适应时间序列预测任务。具体而言，该研究基于单层线性映射提出了以下三种模型：

- Linear (基础线性模型): 利用单线性层, 将历史时间序列的每个时间步直接映射至对应的预测时间步, 实现高效且直观的预测。

- NLinear（归一化线性模型）：在 Linear 的基础上引入了时间维度归一化策略。具体而言，该方法首先对历史时间序列的每个时间步减去序列的最后一个值，以去除整体偏移量，然后通过线性层进行映射，最后将预测结果加回该最后值，从而有效保留原始数据的整体趋势。

- DLinear（分解线性模型）：通过序列分解策略进一步提升 Linear 的预测能力。该方法首先将时间序列拆分为趋势项和周期项两个部分，然后分别通过线性层进行建模，最后将两部分的预测结果合并，以捕获时间序列的长期趋势和周期性变化。

上述三种方法的提出颠覆了深度模型必然优于线性模型的传统认知，并证明在特定场景下，优化后的线性模型不仅能与复杂神经网络模型（如Transformer[22]、Informer[2]、Autoformer[55]等）表现相当，甚至在某些情况下能实现性能的超越。在上述方法的基础上，衍生出了一系列通过对时间序列数据进行处理后与Linear相结合实现预测的方法。例如，FITS[41]将时间序列数据映射到频域，并使用Linear进行预测；而SparseTSF[63]则结合稀疏性选择与Linear组合来进行高效预测。

具体来说，Linear的形式化表达如公式（2-1）所示：

$$
\hat {\mathbf {Y}} = \mathbf {W} \cdot \mathbf {X} + b, \tag {2-1}
$$

其中， $\mathbf{W} \in \mathbb{R}^{F \times T}$  为权重矩阵， $b \in \mathbb{R}^F$  为偏置向量。·表示矩阵乘法运算。

从公式（2-1）中可以看出，输入的每个时间点到输出的传递路径为  $O(1)$ ，这使得模型能够高效地从历史时间序列中提取信息。但由于 Linear 模型将历史数据直接映射到未来预测，难以捕获复杂的时间模式，因此通常依赖于数据的预处理操作。尽管这类方法能在一定程度上缓解问题，但仍然存在一些局限，限制了其应用能力。例如，NLinear 和 Linear 采用点对点预测方法，难以捕获序列的语义信息[27,51]，并且无法有效识别周期性模式；DLinear 的分解方式可能导致信息的丢失；FITS 方法通过将时域数据转为频域，主要聚焦于时间序列全局的周期性变化，但可能忽略了局部波动；而 SparseTSF 则在周期性信息提取方面表现比较有限。

# 2.2.2 多层线性模型及其理论分析

多层线性模型通过级联多个线性变换层来实现深层特征提取，其中最具代表性的是多层感知机（Multilayer Perceptron, MLP）[38,62,64,65]。MLP 通过在相邻的线性层之间引入非线性激活函数，使得模型能够有效捕获数据中的非线性依赖关系。

早期已有不少代表性研究[66,67]将MLP引入时间序列领域。然而，随着Transformer[22]等复杂神经网络的兴起，MLP逐渐被其他方法取代，直到DLinear[39]的提出，使得MLP才再次获得了关注。TimeMixer[40]是这类方法的代表性工作之一，其借助了TimesNet[51]的思想，引入了多个尺度以捕获时间序列中的周期性，并利用MLP逐层提取特征，从而帮助模型更好地理解序列中的复杂时间模式。然而，TimeMixer中多尺度策略的引入，也带来了高昂的计算开销和低下的运行效率。

目前，最新的研究方法，如 SparseTSF[63]，通常将单层线性架构与双层架构作为模型的两种变体。在双层架构中，第一层将历史时间序列映射到特征空间，第二层则将这些特征转换为预测输出，其形式化表达如公式（2-2）所示：

$$
\mathbf {H} = \mathbf {W} _ {1} \cdot \mathbf {X} + b _ {1}, \tag {2-2a}
$$

$$
\hat {\mathbf {Y}} = \mathbf {W} _ {2} \cdot \mathbf {H} + b _ {2}, \tag {2-2b}
$$

其中， $\mathbf{W}_1 \in \mathbb{R}^{dm \times T}$  和  $\mathbf{W}_2 \in \mathbb{R}^{F \times dm}$  分别代表第一层和第二层的权重矩阵， $b_1 \in \mathbb{R}^{dm}$  和  $b_2 \in \mathbb{R}^F$  分别代表第一层和第二层的偏置向量。 $\mathbf{H} \in \mathbb{R}^{dm \times N}$  为第一层线性变换的输出结果，代表时间序列在特征空间中的表示。在本文中， $dm$  统一表示模型特征空间中隐藏单元的数量，即特征维数。

从公式（2-2）中可以看出，尽管多层线性模型的信息传递路径比单层线性模型更加复杂，但其仍然保持在常数级别  $\mathcal{O}(1)$  。这种结构有助于模型提取时间序列的语义信息，但在捕获周期性和局部特征等方面仍存在一定的局限性。

# 2.2.3 相关理论复杂度分析

基于线性变换的模型中，理论复杂度分析主要聚焦于权重矩阵与输入矩阵的矩阵乘法运算，以及偏置向量的加法运算上。

对于单层线性模型，从公式（2-1）可知，矩阵乘法的计算复杂度为  $F \times T \times N$ ，而偏置向量的加法操作需要在  $N$  维度上进行累加，复杂度为  $F \times N$ 。因此，单层线性模型的总体理论（时间和空间）复杂度为  $\mathcal{O}(F \times T \times N)$ 。

进一步分析模型复杂度与时间序列长度  $T$  之间的关系时, 可假设历史时间序列长度  $\mathcal{O}(T)$  与预测时间序列长度  $\mathcal{O}(F)$  处于同一量级, 从而单层线性模型的理论

(时间和空间) 复杂度可近似表达为  $\mathcal{O}(T^{2} \times N)$  。

多层线性模型，以双层架构为例进行分析，从公式（2-2）中可知，两次矩阵乘法的计算复杂度分别为  $dm \times T \times N$  和  $F \times dm \times N$  ，而对应的加法操作复杂度分别为  $dm \times N$  和  $F \times N$  。综合计算，双层线性模型的理论（时间和空间）复杂度可表示为  $\mathcal{O}(T \times N \times dm)$  。

# 2.3 基于循环神经网络的预测方法及理论分析

本节主要分析循环神经网络（Recurrent Neural Network, RNN）及其主要变体提取时间序列信息的过程，并基于此讨论它们的优势与局限性。最后，结合相关公式，进一步分析这些模型的理论复杂度和实际运行效率。

# 2.3.1 循环神经网络基本框架及其信息提取过程分析

循环神经网络（RNN）是一类专为处理序列数据而设计的神经网络架构，其信息流图如图2-1所示。与基于线性变换的模型不同，RNN具有循环结构，能够在当前时间步的计算中保留先前的状态信息。因此，RNN在时间序列分析[68]、自然语言处理[69,70]以及其他需要上下文记忆的任务中展现出更大的优势。此外，由RNN衍生出了一系列变体，使其能够更有效地处理复杂的序列任务。

![](images/c7e75eb6cea27b8873bb377168943f8f08f3735a46567be507c803f30a4e2e7e.jpg)



图2-1 RNN提取信息过程示意图



Fig. 2-1 Diagram of the information extraction process of RNN.


在图2-1中，黄颜色圆圈表示历史序列中的各个时间步，蓝色圆圈则代表历史序列中的最后一个时间步。红色箭头用于指示序列数据的时间流向，展示了时间步之间的先后顺序。在模型表示部分，每个圆圈对应RNN在不同时间步提取的特征表示，颜色的深浅反映了信息捕获的程度——颜色浅表示模型提取到的信息较少，颜色越深则表明捕获的信息更丰富。绿色箭头表示从序列输入到模型表示的映射过程，蓝色箭头则展示了信息在模型内部的流动路径。而黑色虚线箭头用于标识相距最远的两个时间步之间的信息传递路径，从而揭示RNN在时间序列建模过程中的信息传递机制。为保持表达的一致性，本文后续的信息流图将遵循相同的标记方式进行展示。

通过上述分析可以看出，RNN的信息提取过程与序列的时间演化过程高度契合，使其在捕获时序依赖关系方面具有显著优势。依托循环结构，RNN能够逐步积累信息，从最初的局部特征捕获到更全面的全局表示。然而，这一优势也伴随着固有结构带来的限制——其信息传递路径的长度与时间序列的长度呈线性关系，为  $\mathcal{O}(T)$  。导致随着处理序列的增长，信息会逐渐衰减或被遗忘，使得对长程依赖的建模能力下降。此外，RNN还面临梯度爆炸、梯度消失[25]的问题，进一步限制了其在长程时间序列预测中的表现。

# 2.3.2 循环神经网络主要变体及其信息提取过程分析

RNN有两个主要变体：长短期记忆网络（Long Short-Term Memory, LSTM)[71]和门控循环单元（Gated Recurrent Unit, GRU)[72]，它们通过引入门控机制，在一定程度上缓解了传统RNN中梯度消失和梯度爆炸的问题。然而，需要强调的是，它们在处理单个时间步信息时，各有优劣，如图2-2所示。同一颜色的箭头表示这些计算过程之间无需等待信息，可以同时进行。不同颜色的箭头则表示计算过程存在依赖关系，后续的计算必须等待前一步完成才能继续进行。其计算顺序依次为：黑色  $\rightarrow$  红色  $\rightarrow$  深蓝色  $\rightarrow$  橙黄色  $\rightarrow$  粉色  $\rightarrow$  绿色  $\rightarrow$  浅蓝色  $\rightarrow$  灰色。

# (1) 长短期记忆网络——LSTM

LSTM 处理信息的过程如图2-2(a)所示，包含三个门控机制：输入门、遗忘门和输出门。门控机制的处理过程（如图2-2(a)中红色箭头所示）需要进行四次线性变换，并分别通过激活函数进行操作。同时，LSTM 通过隐藏状态和细胞状态两个矩阵递归地传递信息，从而捕获时间步之间的依赖关系。当处理时间步  $t$  的时间序列输入时，LSTM 的第  $l$  层可以形式化表达为公式（2-3）所示：

$$
\boldsymbol {f} _ {t} ^ {(l)} = \sigma \left(\mathbf {W} _ {f} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {f} ^ {(l)}\right), \tag {2-3a}
$$

$$
\boldsymbol {i} _ {t} ^ {(l)} = \sigma \left(\mathbf {W} _ {i} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {i} ^ {(l)}\right), \tag {2-3b}
$$

$$
\widetilde {\boldsymbol {C}} _ {t} ^ {(l)} = \tanh  \left(\mathbf {W} _ {c} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {c} ^ {(l)}\right), \tag {2-3c}
$$

$$
\boldsymbol {o} _ {t} ^ {(l)} = \sigma \left(\mathbf {W} _ {o} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {o} ^ {(l)}\right), \tag {2-3d}
$$

$$
\boldsymbol {C} _ {t} ^ {(l)} = \boldsymbol {f} _ {t} ^ {(l)} \odot \boldsymbol {C} _ {t} ^ {(l)} + \boldsymbol {i} _ {t} ^ {(l)} \odot \widetilde {\boldsymbol {C}} _ {t} ^ {(l)}, \tag {2-3e}
$$

$$
\boldsymbol {h} _ {t} ^ {(l)} = \boldsymbol {o} _ {t} ^ {(l)} \odot \tanh  \left(\boldsymbol {C} _ {t} ^ {(l)}\right), \tag {2-3f}
$$

其中  $h_{t-1}^{(l)}$  表示上一个时间步  $t-1$  输出的隐藏状态， $\boldsymbol{i}n_t^{(l)} \in \mathbb{R}^{di}$  表示当前时间步的输入向量，[·]表示拼接操作。在本文中，将用  $L$  统一表示模型层数的总数量。当模型层数  $l=1$  时， $\boldsymbol{i}n_t^{(l)} = \boldsymbol{x}_t \in \mathbb{R}^N$ ；而当模型层数  $l>1$  时， $\boldsymbol{i}n_t^{(l)} = \boldsymbol{h}_t^{(l-1)} \in \mathbb{R}^{dm}$ 。

$\mathbf{W}_{*}^{(l)} \in \mathbb{R}^{dm \times (dm + di)}$  表示权重矩阵， $b_{*}^{(l)} \in \mathbb{R}^{dm}$  表示偏置向量。 $\sigma(\cdot)$  和  $\tanh(\cdot)$  分别表示 sigmoid 和  $\tanh$  激活函数， $\odot$  表示元素的点积操作。 $\pmb{f}_{t}^{(l)}, \pmb{i}_{t}^{(l)}$  和  $\pmb{o}_{t}^{(l)}$  分别表示第  $l$  层输入门、遗忘门和输出门的输出结果， $\widetilde{\pmb{C}}_{t}^{(l)}$  表示计算得到的中间变量，它们的维度均为  $\mathbb{R}^{dm}$ 。 $\pmb{C}_{t}^{(l)}$  和  $\pmb{h}_{t}^{(l)}$  分别表示当前时间步  $t$  的输出单元状态和输出隐藏状态。

![](images/1fbc13dbc5f2535f4b54f91fac3946e38923ffccaca865bb8872937aa78a6bd3.jpg)



(a)LSTM的信息处理过程


![](images/bfb04e0b8164b5f85825bb1d90a19d7b69b4216a165cb30e8308b741ff7cbaa3.jpg)



(b) GRU 的信息处理过程



图2-2 LSTM与GRU的信息处理过程



Fig. 2-2 Information processing of LSTM and GRU.


# (2) 门控循环单元——GRU

GRU 处理信息的过程如图2-2(b)所示，由两个门控机制：重置门和更新门组成，通过隐藏状态递归地传递信息。其门控处理过程（如图2-2(b)中红色箭头和底部粉色箭头所示）需要进行三次线性变换，并通过激活函数实现。当处理时间序列输入时，GRU 的第  $l$  层可以形式化表达如公式（2-4）所示：

$$
\boldsymbol {r} _ {t} ^ {(l)} = \sigma \left(\mathbf {W} _ {r} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {r} ^ {(l)}\right), \tag {2-4a}
$$

$$
\boldsymbol {u} _ {t} ^ {(l)} = \sigma \left(\mathbf {W} _ {u} ^ {(l)} \cdot \left[ \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {u} ^ {(l)}\right), \tag {2-4b}
$$

$$
\widetilde {\boldsymbol {h}} _ {t} ^ {(l)} = \tanh  \left(\mathbf {W} _ {h} ^ {(l)} \cdot \left[ \boldsymbol {r} _ {t} ^ {(l)} \odot \boldsymbol {h} _ {t - 1} ^ {(l)}, \boldsymbol {i n} _ {t} ^ {(l)} \right] + \boldsymbol {b} _ {h} ^ {(l)}\right), \tag {2-4c}
$$

$$
\boldsymbol {h} _ {t} ^ {(l)} = \left(1 - \boldsymbol {u} _ {t} ^ {(l)}\right) \odot \boldsymbol {h} _ {t - 1} ^ {(l)} + \boldsymbol {u} _ {t} ^ {(l)} \odot \widetilde {\boldsymbol {h}} _ {t} ^ {(l)}, \tag {2-4d}
$$

其中  $\pmb{h}_{t-1}^{(l)}$  表示上一个时间步  $t-1$  输出的隐藏状态，  $\pmb{i}n_{t}^{(l)} \in \mathbb{R}^{di}$  表示当前时间步  $t$  的输入向量。当模型层数  $l = 1$  时，  $\pmb{i}n_{t}^{(l)} = \pmb{x}_{t} \in \mathbb{R}^{N}$ ；而当模型层数  $l > 1$  时，  $\pmb{i}n_{t}^{(l)} = \pmb{h}_{t}^{(l-1)} \in \mathbb{R}^{dm}$ 。  $\pmb{W}_{*}^{(l)} \in \mathbb{R}^{dm \times (dm + di)}$  表示权重矩阵，  $\pmb{b}_{*}^{(l)} \in \mathbb{R}^{dm}$  表示偏置向量。  $\sigma(\cdot)$  和  $\tanh(\cdot)$  分别表示 sigmoid 和 tanh 激活函数，  $\odot$  表示元素的点积操作。  $\pmb{r}_{t}^{(l)}$  和  $\pmb{u}_{t}^{(l)}$  分别表示第  $l$  层重置门和更新门的输出结果，  $\widetilde{\pmb{h}}_{t}^{(l)}$  表示计算得到的中间变量，它们的维度均为  $\mathbb{R}^{dm}$ 。  $\pmb{h}_{t}^{(l)}$  表示当前时间步  $t$  的输出隐藏状态。

# 2.3.3 相关理论复杂度分析

如公式（2-3）所示，LSTM由三个门控机制（输入门、遗忘门和输出门）组成，并包含四次矩阵乘法操作。每次参数矩阵与向量进行乘法的计算复杂度为  $dm \times$

$(dm + di)$ , 而点积和加法的计算复杂度均  $dm$  。由于矩阵乘法的计算量远高于点积和加法操作, 因此单个 LSTM 单元的总计算复杂度可简化为  $4 \times dm \times (dm + di)$  。

当LSTM处理完整的时间序列时，它需要在时间维度上顺序执行  $\mathcal{O}(T)$  次计算。此外，在具有  $L$  层的深度模型中，计算过程需要在层级维度上顺序执行  $L$  次。因此，LSTM的总计算复杂度可表示为：  $4\times T\times dm\times (dm + di)\times L_{\circ}$  由于  $dm + di > dm$  因此LSTM的理论（时间和空间）复杂度可以近似为  $\mathcal{O}(T\times dm^2\times L)$  。

对于 GRU（如公式（2-4）所示），由于其仅包含两个门控机制（重置门和更新门），涉及三次矩阵乘法运算，计算过程与 LSTM 类似。因此，GRU 的理论（时间和空间）复杂度也可总结为  $\mathcal{O}(T \times dm^2 \times L)$ 。

以此类推，类似于LSTM和GRU的依赖于循环结构捕获信息的RNN变体，理论（时间和空间）复杂度均可总结为  $\mathcal{O}(T\times dm^2\times L)$  。然而，需要强调的是，虽然LSTM和GRU的理论复杂度处于同一量级，但在实际应用中，LSTM由于具备更多的门控机制，并额外依赖细胞状态进行信息传递，其内存占用必然高于GRU。

在运行速度方面，由于门控机制的计算占据主要计算量，LSTM 的四个门控可并行计算，彼此独立，无需相互等待；而 GRU 的更新门依赖于重置门的计算结果，存在信息等待问题，限制了计算的并行性。因此，在实际运行过程中，LSTM 的计算效率通常优于 GRU。

# 2.4 基于卷积神经网络的预测方法及理论分析

本节主要分析卷积神经网络（Convolutional Neural Network, CNN）及其主要变体方法在处理时间序列时的信息提取过程，同时归纳总结了各方法的优缺点，并对它们的信息传递路径和理论复杂度进行对比分析。

# 2.4.1 卷积神经网络基本框架及其信息提取过程分析

卷积神经网络（CNN）[64,73] 由于其在处理网格结构数据方面的独特优势，被广泛应用于图像和计算机视觉领域[52,74-76]。CNN的主要结构由卷积层、池化层和全连接层组成，其中卷积操作是其核心。通过卷积核的局部感受野，CNN能够有效地提取局部特征，通过卷积层的堆叠，逐步学习到数据的多层次表示。当用CNN处理时间序列时，其信息提取过程如图2-3所示，其中红色框表示卷积核（示例中感受野大小为5）。

通过图2-3，可以明显看出，CNN由于卷积核感受野的局限性，需要依赖多个卷积层的堆叠才能捕获到序列的全局信息。其卷积层数与序列长度  $T$  呈超线性关系  $\mathcal{O}(G)$ ，而卷积层数即为其信息传递路径的长度。而由于全局信息对模型预测的

![](images/ef5cb1008bcafadae7a1c17953c8c6aa963d79ec407683bd86e131488748cbf7.jpg)



图2-3 CNN提取信息过程示意图



Fig. 2-3 Diagram of the information extraction process of CNN.


准确性至关重要，卷积核感受野的局限性无疑增加了模型训练的难度，同时也带来了更高的计算资源开销。其第  $l$  层卷积操作的形式化表达如公式（2-5）所示：

$$
\hat {\mathbf {X}} ^ {(l)} = \mathcal {W} * \hat {\mathbf {X}} ^ {(l - 1)}, \tag {2-5}
$$

其中， $\hat{\mathbf{X}}^{(l-1)} \in \mathbb{R}^{T \times di}$  表示输入序列， $\hat{\mathbf{X}}^{(l)} \in \mathbb{R}^{T \times dm}$  表示输出序列。当  $l = 1$  时， $\hat{\mathbf{X}}^{(l-1)} = \mathbf{X} \in \mathbb{R}^{T \times N}$ ；当  $l > 1$  时，第  $l$  层的输入即为第  $l - 1$  层的输出。\*代表卷积操作， $\mathcal{W} \in \mathbb{R}^{dm \times di \times K}$  表示卷积核， $K$  为卷积核的大小。

涉及到对  $\hat{\mathbf{X}}^{(l)}$  中第  $t$  个时间步的向量  $\hat{x}_t^{(l)}\in \mathbb{R}^{dm}$  的卷积具体计算过程，如公式（2-6）所示：

$$
\hat {x} _ {t} ^ {(l)} = \sum_ {k = 1} ^ {K} \mathbf {W} _ {k} \cdot \hat {x} _ {k} ^ {(l - 1)} \tag {2-6}
$$

其中， $\mathbf{W}_k \in \mathbb{R}^{dm \times di}$  代表卷积核中第  $k$  个位置的卷积权重矩阵， $\hat{x}_k^{(l-1)} \in \mathbb{R}^{di}$  表示与卷积参数向量  $\mathbf{W}_k$  对应相乘的输入向量，·表示矩阵乘法运算。 $\hat{x}_t^{(l)}$  表示第  $t$  个时间步的输出向量。

# 2.4.2 卷积神经网络主要变体及其信息提取过程分析

# (1) 时间卷积网络——TCN

时间卷积网络（Temporal Convolutional Network, TCN）[48]是卷积神经网络的一种重要变体，专为序列建模任务（如时间序列分析和自然语言处理）设计。其核心模块包括因果卷积和空洞卷积。因果卷积（Causal Convolution）模块确保每一卷积层的输出仅依赖于当前时间步及其之前的输入，这一特性更贴近时间序列的实际发生过程[77]。空洞卷积（Dilated Convolution）模块通过扩张系数扩大了局部感受

野，在不增加卷积核大小的情况下，使得模型能够更有效地捕获长程依赖关系[78]。TCN的信息提取过程如图2-4所示，卷积核示例的感受野大小为4。

![](images/f848cc3b857be0fd254810c96678db02149fc707aace61e63ec95a4b7049305c.jpg)



图2-4 TCN提取信息过程示意图



Fig. 2-4 Diagram of the information extraction process of TCN.


从图2-4中可以看出，由于卷积核感受野的扩大，TCN能够高效捕获序列的全局信息。特别是，与图2-3相比，TCN的卷积核比CNN更小，但其信息传递路径（等同于卷积层数）却大大减少，提升了信息传递的效率，展现出了更大的优势。

# (2) 基于二维卷积的时间序列预测方法——TimesNet

TimesNet[51] 首先通过傅里叶变换自适应地计算时间序列中的多个周期值，并根据这些周期值将时间序列转置到二维进行排布，以便模型能够直接提取周期性特征随后，利用 Inception[52] 模型从二维序列中直接提取信息，并将最终得到的表示用于后续的预测任务。其信息传递过程如图2-5所示。为了便于分析 TimesNet 的信息传递路径，图中仅展示了一个案例，说明卷积核操作的过程。

![](images/e8cdd66e12e77d52b9f72d5e16b66088f31c2e8c1dd4e59bbe7d2015eb8e008d.jpg)



图2-5 TimesNet提取信息过程示意图



Fig. 2-5 Diagram of the information extraction process of TimesNet.


从图2-5中可以看出，由于TimesNet是在二维上对时间序列进行卷积操作，因此在两个维度上的长度均与时间序列长度  $T$  呈平方根关系  $\mathcal{O}(\sqrt{T})$  。与此同时，所需堆叠的层数，即信息传递路径的长度，也对应为  $\mathcal{O}(\sqrt{G})$  ，这一点明显优于CNN。此外，在捕获周期性信息方面，TimesNet相较于CNN和TCN具有更大优势。

# (3) 增大卷积核的时间序列预测方法——MICN与ModernTCN

MICN[26] 和 ModernTCN[53] 是两种通过增大卷积核来扩大局部感受野，以减少卷积层堆叠深度的代表性时间序列分析方法。

MICN的核心原理是通过设置大卷积核并结合因果卷积策略，以高效捕获历史时间序列的全局信息，其信息提取过程如图2-6所示。首先，在输入序列中，对每个预测时间步的位置进行全零填充，以适应后续计算需求。随后，利用Patch化操作（图2-6中橙黄色框）对整个时间序列进行下采样，从而提取局部特征表示。接着，利用大卷积核覆盖整个历史时间序列的局部特征，并执行因果卷积运算，使每个预测时间步的特征能够充分整合历史序列的全局信息。最后，通过上采样操作，将提取到的全局特征映射至输出序列，生成最终的预测结果。

![](images/3045a09b7309c48a261e9f297bc7a79c63da8f171bb265dc554da5acc28c4e99.jpg)



图2-6 MICN提取信息过程示意图



Fig. 2-6 Diagram of the information extraction process of MICN.


从图2-6中可以观察到，MICN 的模型层数固定，尤其是卷积操作仅需一层即可，因此其信息传递路径为固定的常数级别，即  $\mathcal{O}(1)$ 。

ModernTCN的核心原理与MICN类似，其信息提取过程如图2-7所示。ModernTCN同样通过Patch化操作提取时间序列的局部特征，接着通过卷积层高效地提取序列的局部和全局信息。最终，在时间维度上进行信息的融合，形成全局特征表示。在处理多变量时间序列时，ModernTCN会结合各个变量的全局特征信息表示，沿通道维度进行再次融合，以便最终进行预测。

从图2-7中可以观察到，ModernTCN的模型层数也是固定的，卷积操作也仅需一层，因此其信息传递路径也可以总结为  $\mathcal{O}(1)$ 。

总的来说，虽然MICN与ModernTCN通过增大卷积核的方式有效地将信息传递路径降低到0(1)，但在捕获周期性信息方面，它们的表现仍不如TimesNet那样直接有效。

![](images/175ed03dd036ec74b12f82c81d65195acae52bbe2a1d000a38c370bad4e50819.jpg)



图2-7 ModernTCN提取信息过程示意图



Fig. 2-7 Diagram of the information extraction process of ModernTCN.


# 2.4.3 相关理论复杂度分析

如公式 (2-6) 所示, 在 CNN 对时间步  $t$  的每一层卷积操作中, 对卷积核中每一个位置  $k$  均需进行权重矩阵  $\mathbf{w}_k$  与输入向量  $\hat{x}_k^{(l-1)}$  的点乘操作, 因此其计算复杂度为  $dm \times di$  。由于卷积核的长度为  $K$ , 时间步的操作需要重复  $\mathcal{O}(T)$  次, 因此单层卷积操作的理论复杂度为  $\mathcal{O}(T \times dm \times di \times K)$  。此外, 由于卷积核的大小  $K$  通常小于时间序列的维度  $\mathcal{O}(T)$ , 因此在这种情况下, 需要通过多层结构才能捕获序列的长程依赖关系。具体来说, 模型需要堆叠  $L \geq \lfloor 2T / K \rfloor + 1$  层, 其中  $\lfloor \cdot \rfloor$  表示向下取整操作。在这种情况下, 层数  $L$  与序列长度  $T$  呈超线性关系, 即  $L = \mathcal{O}(T / K) = \mathcal{O}(G)$  。与此同时, 每一层的输入维度  $di$  与输出维度  $dm$  处在同一量级, 即  $\mathcal{O}(di) = \mathcal{O}(dm)$  。因此, CNN 的总理论（时间和空间）复杂度可以总结为  $\mathcal{O}(T \times dm^2 \times K \times L)$  。

TCN 作为 CNN 的主要变体，其计算过程与 CNN 类似，因此 TCN 的总体理论（时间和空间）复杂度也可以总结为  $\mathcal{O}(T \times dm^2 \times K \times L)$ 。然而，由于 TCN 中空洞卷积的感受野更大，能够更有效地捕获长程依赖关系，TCN 的实际层数  $L \geq \left\lfloor \log_a^{T / K} \right\rfloor + 1$  通常低于 CNN，从而使得 TCN 的复杂度也更低，其中  $a$  表示扩张系数。

MICN和ModernTCN的计算过程虽然与传统的CNN和TCN相似，但由于引入了Patch化操作，它们将时间序列的长度进一步降低至  $\mathcal{O}(T / S)$ ，其中  $S$  为Patch操作滑动的步长（Stride）。因此，它们的理论（时间和空间）复杂度可以表示为 $\mathcal{O}(T / S\times dm^2\times K\times L)$ 。其中，卷积核  $K$  通常设置较大，为  $\mathcal{O}(T / S)$  。由于仅需一层卷积操作即可捕获全局信息，此时  $L = 1$  。因此，相较于传统的CNN和TCN，它们的计算复杂度得到了有效降低。

TimesNet 通过将原始一维时间序列转置为二维进行建模，因此在两个维度上的序列长度均为  $\mathcal{O}(\sqrt{T})$  。在此基础上，采用 Inception 操作，假设卷积核大小为

$K$ , 其复杂度将是两个维度的序列长度与卷积核大小的乘积。同时, 由于需要多层结构才能捕获全局和局部信息, 因此其理论 (时间和空间) 复杂度也可以总结为  $\mathcal{O}(T \times d m^{2} \times K \times L)$ , 但层数  $L$  与原始 CNN 的层数  $\mathcal{O}(G)$  呈平方根关系  $\mathcal{O}(\sqrt{G})$  。

为了便于本文后续的讨论分析，小节依照上述的理论分析过程，对CNN及其主要变体进行总结对比，如表2-1所示。其中，理论复杂度遵循时间序列领域的主流方式[2,54-56]，主要关注与序列长度  $T$  的关系。


表 2-1 CNN 及其主要变体的对比总结



Table 2-1 Comparison of CNN and its main variants.


<table><tr><td>方法</td><td>周期性的直接捕获</td><td>信息传递路径</td><td>理论（时间和空间）</td><td>复杂度</td></tr><tr><td>CNN</td><td>X</td><td>O(G)</td><td></td><td>O(T)</td></tr><tr><td>TCN</td><td>X</td><td>O(log G)</td><td></td><td>O(T)</td></tr><tr><td>TimesNet</td><td>✓ (二维建模)</td><td>O(√G)</td><td></td><td>O(T)</td></tr><tr><td>MICN</td><td>✓ (序列分解)</td><td>O(1)</td><td></td><td>O(T/S)</td></tr><tr><td>ModernTCN</td><td>X</td><td>O(1)</td><td></td><td>O(T/S)</td></tr></table>

# 2.5 基于注意力机制的预测方法及理论分析

本节首先以Transformer作为注意力机制的代表性方法，深入分析其自注意力机制的信息提取过程及其优势与局限性。随后，通过公式化推导其编码器结构，为后续理论复杂度分析及不同变体的对比奠定基础。最后，探讨Transformer的主要变体，比较它们的特点，并进行系统性的对比分析。

# 2.5.1 注意力机制的基本框架及其信息提取过程分析

# (1) 自注意力机制基本框架

注意力机制[22,79,80]旨在模拟人类在处理信息时对关键信息的聚焦，通过自适应加权计算融合重要信息。常见的注意力机制包括加性注意力（Additive Attention)[79,80]和点积注意力（Dot-Product Attention)[22,80]。与加性注意力相比，点积注意力在计算效率上具有明显优势，能够更好地捕获输入之间的依赖关系，因此成为了当前主流的注意力机制。

Transformer是基于点积注意力机制的代表性架构，最初应用于自然语言处理任务，近年来在各个领域大获成功。其核心自注意力（Self-Attention）机制能够有效捕获输入序列中任意两个位置之间的关系，从而克服了传统方法在处理长程依赖时的局限性。图2-8展示了自注意力机制提取信息的过程。

![](images/b68627ee6e7725faf9be8516ec809d91801fded2059284194a337a13faa4f17e.jpg)



图2-8 自注意力机制提取信息过程示意图



Fig. 2-8 Diagram of the information extraction process of Self-Attention.


从图2-8中可以看出，Transformer的自注意力机制在计算过程中，会对输入序列中任意两个位置的信息进行相似性计算，从而使得任意两位置间的信息传递路径长度均为  $O(1)$  。然而，这种全局交互的计算方式也带来了极高的计算复杂度（见2.5.2节），在长程时间序列预测任务中容易造成计算和存储瓶颈。具体来说，自注意力机制的形式化表达如公式（2-7）所示：

$$
\operatorname {A t t e n t i o n} (\hat {\mathbf {Q}}, \hat {\mathbf {K}}, \hat {\mathbf {V}}) = \operatorname {s o f t m a x} \left(\frac {\hat {\mathbf {Q}} \cdot \hat {\mathbf {K}} ^ {\top}}{\sqrt {d m}}\right) \cdot \hat {\mathbf {V}}, \tag {2-7}
$$

其中， $\hat{\mathbf{Q}} \in \mathbb{R}^{Q \times dm}$  为查询（Query）矩阵，表示计算关注的目标对象； $\hat{\mathbf{K}} \in \mathbb{R}^{V \times dm}$  为键（Key）矩阵，表示用于与目标对象进行匹配计算的特征矩阵； $\hat{\mathbf{V}} \in \mathbb{R}^{V \times dm}$  为值（Value）矩阵，提供用于加权求和与计算输出的特征信息。查询矩阵  $\hat{\mathbf{Q}}$  的行数  $Q$  表示查询矩阵的长度，键矩阵  $\hat{\mathbf{K}}$  和值矩阵  $\hat{\mathbf{V}}$  的行数均为  $V$ ， $dm$  则表示它们的特征维数。 $\top$  表示转置操作，softmax(\cdot) 表示对  $\hat{\mathbf{Q}}$  和  $\hat{\mathbf{K}}$  计算得出的注意力权重矩阵进行 softmax 操作。Attention( $\hat{\mathbf{Q}}, \hat{\mathbf{K}}, \hat{\mathbf{V}}$ ) 的输出维度与  $\hat{\mathbf{Q}}$  一致，为  $\mathbb{R}^{Q \times dm}$ 。

为了进一步增强模型的表达能力，Transformer引入了多头注意力模块，通过并行化多个自注意力机制，在特征表示空间内实现多样化的学习。其形式化表达如公式（2-8）和（2-9）所示：

$$
\mathbf {H} _ {j} = \text {A t t e n t i o n} \left(\mathbf {Q} \cdot \mathbf {W} _ {j} ^ {\text {Q u e r y}}, \mathbf {K} \cdot \mathbf {W} _ {j} ^ {\text {K e y}}, \mathbf {V} \cdot \mathbf {W} _ {j} ^ {\text {V a l u e}}\right), \tag {2-8}
$$

$$
\operatorname {M u l t i H e a d} (\mathbf {Q}, \mathbf {K}, \mathbf {V}) = \left[ \mathbf {H} _ {1}, \mathbf {H} _ {2}, \dots , \mathbf {H} _ {h d} \right] \cdot \mathbf {W} ^ {\text {o u t}}, \tag {2-9}
$$

在公式（2-8）中， $\mathbf{W}_j^* \in \mathbb{R}^{dm \times dk}$  表示特征矩阵， $\mathbf{H}_j \in \mathbb{R}^{Q \times dk}$  表示第  $j$  个分头上的注意力计算输出矩阵。在公式（2-9）中，[·]表示拼接操作， $hd$  表示多头注意力的头数，其中  $hd \times dk = dm$  。通过先将  $hd$  个分头注意力机制的输出进行拼合，再通过权重矩阵  $\mathbf{W}^{\mathrm{out}} \in \mathbb{R}^{dm \times dm}$  进行线性变换，从而生成输出  $\mathbf{H} \in \mathbb{R}^{Q \times dm}$  。

# (2) Transformer 基本框架

虽然自注意力机制是Transformer计算序列中不同位置之间依赖关系的关键部分，但单靠这一机制并不足以完成序列的高效建模。因此，Transformer采用了编码器-解码器（Encoder-Decoder）结构，以提升信息处理能力。编码器负责提取输入序列的特征，而解码器则利用这些特征生成目标序列。这种设计使Transformer能够更加灵活地应对不同类型的任务，尤其是在序列到序列的任务（如机器翻译[81]、文本摘要[82]等[83]）中表现较好。

然而，在时间序列分析领域，特别是在长程时间序列预测任务中，传统的Transformer架构由于解码器的循环生成机制，容易受到误差累积的影响[56]。为了解决这一问题，Transformer的后续变体逐渐演变为只使用编码器来生成序列表示，然后通过线性层直接进行预测的方式。

在Transformer的编码器中，除了自注意力机制外，还包括输入的嵌入表示操作以及前馈神经网络（Feed-Forward Network, FFN）。嵌入层将原始输入序列映射到高维向量空间，使得模型能够有效地处理和学习序列中的特征；而FFN位于自注意力机制的尾端，负责对自注意力的输出进行逐点的非线性变换，以进一步增强模型的表达能力，捕获更丰富的特征信息。

嵌入表示操作的形式化表达如公式（2-10）所示：

$$
\mathbf {E} = \operatorname {E m b e d d i n g} _ {1} (\mathbf {X}) + \mathbf {P E} + \mathbf {T E}, \tag {2-10}
$$

其中，Embedding $_1(\cdot)$  代表对历史时间序列  $\mathbf{X}$  的嵌入计算过程； $\mathbf{PE} \in \mathbb{R}^{T \times dm}$  表示序列的位置嵌入，每个位置的嵌入由公式（2-11）计算得出，从而为模型提供了序列中每个时间步的相对位置信息； $\mathbf{TE} \in \mathbb{R}^{T \times dm}$  表示序列的时间嵌入，计算过程如公式（2-12）所示。 $\mathbf{E} \in \mathbb{R}^{T \times dm}$  表示历史时间序列的嵌入输出。

$$
\mathbf {P E} (t, 2 p) = \sin \left(\frac {t}{1 0 0 0 0 ^ {2 p / d m}}\right), \tag {2-11a}
$$

$$
\mathbf {P E} (t, 2 p + 1) = \cos \left(\frac {t}{1 0 0 0 0 ^ {2 p / d m}}\right), \tag {2-11b}
$$

其中， $t$  表示序列中的位置， $p$  是嵌入维度的索引。 $\sin(\cdot)$  和  $\cos(\cdot)$  分别表示正弦和余弦函数。

$$
\mathbf {T E} = \operatorname {E m b e d d i n g} _ {2} (\mathbf {T F}), \tag {2-12}
$$

其中， $\mathsf{Embedding}_2(\cdot)$  代表对序列对应时间戳 TF 的嵌入计算过程。通过时间嵌入，模型能够有效地捕获时间信息，从而提升预测精度。

FFN 模块主要由两个线性层的叠加构成，其形式化表达如公式（2-13）所示：

$$
\mathbf {H} _ {1} = \mathbf {H} \cdot \mathbf {W} _ {1} + b _ {1}, \tag {2-13a}
$$

$$
\mathbf {H} _ {2} = \mathbf {H} _ {1} \cdot \mathbf {W} _ {2} + \boldsymbol {b} _ {2}, \tag {2-13b}
$$

其中， $\mathbf{W}_1 \in \mathbb{R}^{dm \times df}$  和  $\mathbf{W}_2 \in \mathbb{R}^{df \times dm}$  分别表示第一层和第二层的权重矩阵， $b_1 \in \mathbb{R}^{df}$  和  $b_2 \in \mathbb{R}^{dm}$  分别为两层的偏置向量。 $\mathbf{H}_1 \in \mathbb{R}^{Q \times df}$  和  $\mathbf{H}_2 \in \mathbb{R}^{Q \times dm}$  分别表示两层的输出结果。通常情况下，第一层输出的特征维数  $df$  大于第二层输出的特征维数  $dm$ 。通过在两层之间引入非线性激活函数，模型能够捕获更复杂的特征和模式。

此外，Transformer中引入了残差连接[76]和层归一化操作[84]，这些机制能够有效加快模型的收敛速度，并增强模型的表达能力。Transformer第  $l$  层编码器  $\mathrm{Encoder}^{(l)}(\cdot)$  的形式化表达如公式（2-14）所示：

$$
\hat {\mathbf {H}} _ {1} ^ {(l)} = \operatorname {L a y e r N o r m} _ {1} ^ {(l)} \left(\mathbf {I n} ^ {(l)} + \operatorname {M u l t i H e a d} ^ {(l)} \left(\mathbf {I n} ^ {(l)}, \mathbf {I n} ^ {(l)}, \mathbf {I n} ^ {(l)}\right)\right), \tag {2-14a}
$$

$$
\hat {\mathbf {H}} ^ {(l)} = \operatorname {L a y e r N o r m} _ {2} ^ {(l)} \left(\hat {\mathbf {H}} _ {1} ^ {(l)} + \operatorname {F F N} ^ {(l)} \left(\hat {\mathbf {H}} _ {1} ^ {(l)}\right)\right), \tag {2-14b}
$$

其中，LayerNorm $_*$ $(l)(\cdot)$  表示层归一化操作。 $\mathbf{In}^{(l)} \in \mathbb{R}^{Q \times dm}$  表示第  $l$  层的输入序列。当  $l = 1$  时， $\mathbf{In}^{(l)} = \mathbf{E}$ ，输入为历史时间序列的原始嵌入表示；当  $l > 1$  时， $\mathbf{In}^{(l)} = \hat{\mathbf{H}}^{(l - 1)}$ ，输入为上一层模型的输出。

# 2.5.2 Transformer理论复杂度分析

本小节主要以Transformer中的第  $j$  个分头注意力机制为例进行理论复杂度分析。如公式（2-8）所示，对  $\mathbf{Q}$ 、 $\mathbf{K}$  和  $\mathbf{V}$  进行线性矩阵变换时，复杂度分别为  $Q \times dm \times dk$ 、 $V \times dm \times dk$  和  $V \times dm \times dk$ 。在注意力机制的运算中，如公式（2-7）所示，计算  $\hat{\mathbf{Q}} \cdot \hat{\mathbf{K}}^{\top}$  得到注意力权重矩阵的过程中，复杂度为  $Q \times dm \times V$ ；当该注意力权重矩阵与  $\hat{\mathbf{V}}$  进行矩阵运算时，复杂度同样为  $Q \times dm \times V$ 。

如公式（2-9）所示，由于  $dm = nh \times dk$ ，因此在多头注意力中，对 Q、K、V 进行线性变换的总体复杂度分别为  $Q \times dm \times dm$  、  $V \times dm \times dm$  和  $V \times dm \times dm$  。对于注意力权重和注意力输出矩阵的运算，复杂度为  $2 \times Q \times dm \times V$  。在自注意力机制中，Q、K、V 均为历史时间序列的原始嵌入表示 E。因此，注意力计算的总体（时间和空间）理论复杂度为  $\mathcal{O}(T \times dm^2) + \mathcal{O}(T^2 \times dm)$  。

FFN 的计算过程如公式（2-13）所示，由于其计算过程与公式（2-2）类似，因此本部分的理论复杂度推导过程与2.2.3小节类似。FFN 的理论（时间和空间）复杂度可推导为  $\mathcal{O}(T \times dm \times df)$ 。

综上所述，单层Transformer编码器的总体理论（时间和空间）复杂度为  $\mathcal{O}(T\times dm^2) + \mathcal{O}(T^2\times dm) + \mathcal{O}(T\times dm\times df)$  。而多层的（时间和空间）复杂度则为  $\mathcal{O}(T\times dm^2\times L) + \mathcal{O}(T^2\times dm\times L) + \mathcal{O}(T\times dm\times df\times L)$  。

# 2.5.3 基于注意力机制的主要变体方法及相关理论分析

早期的注意力机制变体主要聚焦于改进和替代Transformer中的自注意力机制，几个典型的变体方法包括LogTrans[85]、Reformer[86]、Informer[2]、Autoformer[55]等。

LogTrans 通过引入低秩近似和矩阵分解技术，提高了自注意力机制的计算效率。其核心思想是采用分块对角近似，仅计算自注意力矩阵中关键的非零元素，忽略对全局相关性影响较小的注意力权重，从而显著减少计算开销，使注意力机制的时间复杂度优化至  $\mathcal{O}(T\log T)$ ，然而由于仍需保留整个自注意力矩阵的元素，因此其空间复杂度仍为  $\mathcal{O}(T^2)$ 。其提取信息过程如图2-9所示，可以从图中看出，其信息传递路径与时间序列长程长度  $T$  呈超线性  $\mathcal{O}(G)$ 。

![](images/20e7a12f85785208558da64bcef78ce1afd19c3d680ca88cc47fc19bd5869e0c.jpg)



图2-9 LogTrans提取信息过程示意图



Fig. 2-9 Diagram of the information extraction process of LogTrans.


Reformer采用局部敏感哈希（LSH）技术，取代了传统自注意力机制中所有位置两两计算相似度的方式。通过LSH，Reformer能够将相似的查询Q和键K映射到同一个哈希桶内，仅对桶内相关的注意力权重进行计算，减少了不必要的全局计算开销，使注意力机制的理论（时间和空间）复杂度降至  $\mathcal{O}(T\log T)$  。其提取信息过程如图2-10所示，可以从图中看出，其并没有为每个点捕获全局信息，而是仅捕获了局部相关信息，其信息传递路径呈常数级别  $\mathcal{O}(1)$  。

Informer是首个专门用于长程时间序列预测任务的注意力方法。通过引入概率稀疏（ProbSparse）自注意力机制并结合蒸馏技术，该方法能够聚焦于最为关键的注意力权重，从而显著降低计算量，并将注意力机制的理论（时间和空间）复杂

![](images/aabdc1822601c1954f105fb70e61f76fa33436014942648ecc8257d768a97ace.jpg)



图2-10Reformer提取信息过程示意图



Fig. 2-10 Diagram of the information extraction process of Reformer.


度降至  $\mathcal{O}(T\log T)$  。

Autoformer 通过引入季节性分解策略，能够分别建模时间序列中的长期趋势和周期性成分。此外，它利用快速傅里叶变换（Fast Fourier Transform, FFT)[87]将时间序列转换至频域，并借助自相关机制（Autocorrelation Mechanism）计算序列间的相关性。通过这种改进，Autoformer 优化了计算流程，还有效减少了注意力机制的理论（时间和空间）复杂度至  $\mathcal{O}(T\log T)$  。

尽管上述方法在一定程度上优化了注意力机制的理论复杂度，但在处理时间序列时，特别是在面对长程时间序列任务时，其  $\mathcal{O}(T\log T)$  的理论复杂度仍然会随着序列长度的增加而显著上升。这种增长不仅加重了计算负担，还导致模型在训练和推理过程中面临效率瓶颈，进而影响其在长程序列任务中的实际应用效果。

Pyraformer[56]和FEDformer[54]是近年来针对长程时间序列预测任务提出的两个高效变体，它们通过不同策略进一步优化了注意力机制在长程时间序列任务中的计算效率和预测能力。与传统的Transformer架构不同，它们摒弃了传统的解码器结构，并避免了循环生成过程中可能引发的误差累积问题，提升了预测精度和效率。

Pyraformer 提出了金字塔型注意力机制，通过逐层聚合不同时间尺度的信息，从而同时捕获时间序列中的长期和短期周期性变化模式。该方法首先利用卷积神经网络（CNN）初始化金字塔结构的节点，然后通过分层的注意力机制，使得每个尺度上都能提取时间序列的依赖关系。通过这种方式，Pyraformer 有效地将注意力机制的理论（时间和空间）复杂度降至  $\mathcal{O}(T)$  。其信息传递过程如图2-11所示：

从图2-11中可以看出，尽管Pyraformer的信息传递路径需要通过多层结构来实现，但其金字塔型架构能够根据序列长度自适应调整，从而提升信息传递的效率。因此，Pyraformer的信息传递路径可视为常数级别，即  $\mathcal{O}(1)$  。

FEDformer 则采用频域变换技术，将时间序列从时域转换到频域，并在频域上进行自注意力操作。这种方法能够有效捕获全局周期性变化，并将注意力机制

![](images/c4759db26bfac70a7a65fb5cc0d2ac579ec6e5be60dec6b9f04519d074e8b5e9.jpg)



图2-11 Pyraformer提取信息过程示意图



Fig. 2-11 Diagram of the information extraction process of Pyraformer.


的理论（时间和空间）复杂度降低至  $\mathcal{O}(T)$ 。

然而，对于长程时间序列任务而言， $\mathcal{O}(T)$  的理论复杂度仍然面临较高的计算开销。此外，基于点积注意力计算的方法（如Transformer、Informer、FEDformer等）在捕获时间序列中的深层语义信息时存在一定的局限性[27,51]，但它们的信息传递路径与Transformer一致均为  $\mathcal{O}(1)$  （如图2-8）所示。针对这一问题，PatchTST应运而生，它通过进一步优化信息提取过程，显著提升了处理效率。其信息提取的具体过程如图2-12所示，橙黄色框代表Patch操作。

![](images/71f3197276c95213b458d04403be6419b3cb53a2abf964003ab392158f6bb08f.jpg)



图2-12 PatchTST提取信息过程示意图



Fig. 2-12 Diagram of the information extraction process of PatchTST.


从图2-12中可以看出，借助Patch化聚合方法，PatchTST能够有效提取时间序列的局部语义信息，并将注意力计算的（时间和空间）复杂度降低至  $\mathcal{O}((L / S)^2)$ ，从而显著提高了注意力运算的效率，其中  $S$  为Patch操作滑动的步长（Stride）。此外，其信息传递路径依然保持在  $\mathcal{O}(1)$  级别。

总体来看，尽管本小节提到的优化方法通过引入额外操作以降低Transformer传统自注意力的计算复杂度，在某些情况下增加了信息传递路径，但这些方法大


表 2-2 Transformer 及其主要变体的对比总结



Table 2-2 Comparison of Transformer and Its Main Variants.


<table><tr><td>方法</td><td>深层语义信息的有效捕获</td><td>周期性的直接捕获</td><td>信息传递路径</td><td>时间复杂度</td><td>空间复杂度</td></tr><tr><td>Transformer</td><td>X</td><td>X</td><td>O(1)</td><td>O(T2)</td><td>O(T2)</td></tr><tr><td>LogTrans</td><td>✓</td><td>X</td><td>O(G)</td><td>O(T log T)</td><td>O(T2)</td></tr><tr><td>Reformer</td><td>✓</td><td>X</td><td>O(1)</td><td>O(T log T)</td><td>O(T log T)</td></tr><tr><td>Informer</td><td>X</td><td>X</td><td>O(1)</td><td>O(T log T)</td><td>O(T log T)</td></tr><tr><td>Autoformer</td><td>✓</td><td>✓ (序列分解)</td><td>O(1)</td><td>O(T log T)</td><td>O(T log T)</td></tr><tr><td>Pyraformer</td><td>✓</td><td>✓ (金字塔型结构)</td><td>O(1)</td><td>O(T)</td><td>O(T)</td></tr><tr><td>FEDformer</td><td>X</td><td>✓ (频域转换)</td><td>O(1)</td><td>O(T)</td><td>O(T)</td></tr><tr><td>PatchTST</td><td>✓</td><td>X</td><td>O(1)</td><td>O((T/S)2)</td><td>O((T/S)2)</td></tr></table>

多仍能将信息传递路径保持在常数级别。为了更清晰地展示并总结上述分析，相关方法的对比情况整理于表2-2之中。

# 2.6 基于图神经网络的预测方法及其理论分析

图神经网络（Graph Neural Networks, GNN）凭借其在处理拓扑结构方面的优势，可用于建模多变量时间序列中变量之间的关系。因此，本节将分析图神经网络及其主要变体的信息提取过程，并推导相关的理论复杂度，为后续多变量时间序列预测任务的分析奠定基础。

# 2.6.1 图神经网络及其主要变体信息提取过程分析

图神经网络（GNN）[88-92]是一类专门用于处理拓扑结构数据的深度学习模型。一个拓扑图通常由节点（Node）、边（Edge）和节点特征（Feature）三部分组成。

在多变量时间序列分析中，基于GNN的方法通常将时间序列中的变量数  $N$  视为拓扑图的节点数，并用时间维度上的观测值或特征表示节点状态。变量之间的关系则由邻接矩阵  $\mathbf{A} \in \mathbb{R}^{N \times N}$  建模。

根据邻接矩阵  $\mathbf{A}$  的构建方式，GNN 可分为两类：（1）基于预定义图结构的方法：在模型构建前，邻接矩阵  $\mathbf{A}$  由先验知识或外部信息设定，边的连接关系固定不变。（2）基于自适应学习图结构的方法：在训练过程中，模型会通过参数自动学习拓扑结构，从而动态优化邻接矩阵  $\mathbf{A}$  。Graph WaveNet[93] 是一个典型的自适应 GNN 模型，其邻接矩阵的构建方式如公式（2-15）所示：

$$
\mathbf {A} = \operatorname {s o f t m a x} \left(\operatorname {R e l u} \left(\mathbf {W} _ {1} \cdot \mathbf {W} _ {2} ^ {\top}\right)\right), \tag {2-15}
$$

其中， $\mathbf{W}_* \in \mathbb{R}^{N \times dc}$  为生成邻接矩阵的权重矩阵， $dc$  为特征维度。

GNN 主要通过邻域聚合机制实现信息的流动与传递。在节点状态更新过程中，每个节点会融合邻居节点的信息，从而形成一个局部上下文感知的表示。随着 GNN 层数的堆叠，感受野逐渐扩大，节点的表示会融合更广泛的邻域信息，最终形成全局表示。两种最具代表性的 GNN 变体是图卷积网络（Graph Convolution Network, GCN）[94] 和图注意力网络（Graph Attention Network, GAT）[88]。

# (1) 基于拓扑图理论的卷积操作方法——GCN

GCN 通过拉普拉斯矩阵对输入特征进行归一化变换，并执行图卷积运算。其核心计算过程如公式（2-16）所示：

$$
\mathbf {H} ^ {(l)} = \sigma \left(\Delta^ {- \frac {1}{2}} \cdot \tilde {\mathbf {A}} \cdot \Delta^ {- \frac {1}{2}} \cdot \mathbf {H} ^ {(l - 1)} \cdot \mathbf {W} ^ {(l)}\right), \tag {2-16}
$$

其中， $\mathbf{H}^{(l)} \in \mathbb{R}^{N \times dm}$  表示第  $l$  层的输出节点特征矩阵， $\mathbf{H}^{(l-1)}$  为上一层的节点特征，当  $l = 1$  时， $\mathbf{H}^{(l-1)} \in \mathbb{R}^{N \times di}$  则为原始输入信息。 $\tilde{\mathbf{A}} = \mathbf{A} + \mathbf{I}$  为加上自环的邻接矩阵， $\Delta \in \mathbb{R}^{N \times N}$  为  $\tilde{\mathbf{A}}$  的度矩阵。 $\mathbf{W}^{(l)}$  是可学习的参数矩阵， $\sigma$  为非线性激活函数。

GCN 通过矩阵运算高效地传递信息，使每个节点能够融合其局部邻居的特征。然而，由于矩阵乘法的特性，其计算过程复杂度较高，且随着层数增加容易出现过平滑（Over-Smoothing）的问题。

# (2) 基于拓扑图注意力机制的卷积操作——GAT

GAT引入了注意力机制，在节点信息聚合过程中，通过为每个邻居节点分配不同的权重，从而更加灵活地捕获节点之间的关系。这种机制使得每个节点能够动态地调整与邻居节点的影响力，增强了模型对图结构的感知能力。通过这种方式，GAT能够自适应地学习图的局部信息，从而提高了信息传递的效率和灵活性。

# 2.6.2 相关理论复杂度分析

在时间序列分析领域中，GNN通常用于捕获变量间的相关性。因此，本小节在分析其理论复杂度分析时，不再关注时间序列维度的复杂度  $\mathcal{O}(T)$ ，而是重点考察变量维度的复杂度  $\mathcal{O}(N)$ 。在GNN的每次节点信息聚合中，计算过程均类似于公式（2-16）。尽管不同的GNN变体可能会引入多个信息聚合操作，以提升模型的表示能力，但由于这些操作的叠加并不会改变理论复杂度的量级，因此本小节仅对公式（2-16）进行分析。

若将公式（2-16）进一步简化，可以将GNN的信息聚合过程视为归一化邻接矩阵（维度为  $\mathbb{R}^{N\times N}$ ）、输入特征矩阵（维度为  $\mathbb{R}^{N\times di}$ ）以及权重矩阵（维度为  $\mathbb{R}^{di\times dm}$ ）逐次点乘计算的过程。第一次点乘计算的理论复杂度为  $N\times N\times di$ ，第

二次点乘计算的的理论复杂度为  $N \times di \times dm$  。通常情况下，di 和 dm 处于同一量级，即  $\mathcal{O}(di) = \mathcal{O}(dm)$ ，因此单层 GNN 的理论（时间和空间）复杂度可以总结为  $\mathcal{O}(N^2 \times dm) + \mathcal{O}(N \times dm^2)$  。对于多层 GNN，理论（时间和空间）复杂度可以进一步总结为  $\mathcal{O}(N^2 \times dm \times L) + \mathcal{O}(N \times dm^2 \times L)$  。

# 2.7 数据集与评价指标

本节将介绍所使用的数据集（包括其来源与预处理过程）以及相关评价指标，为后文的实验开展和结果分析奠定基础。

# 2.7.1 数据集

为验证相关时间序列预测方法的性能，本文选择了覆盖能源、交通和气象领域的五个真实世界基准数据集进行实验。本小节将全面介绍这些数据集，包括它们的来源、特征以及预处理过程。

(1) 电力数据集 (Electricity, ECL)  $^{1}$ : 该数据集包含 2012 年至 2014 年间 321 个节点的每小时用电量数据。当预测任务面向单变量时, 研究对象为 “MT_320”。

(2) 交通数据集（Traffic）²：记录旧金山湾区高速公路上不同传感器测量的每小时道路占用率，数据来源于加州交通部门。当预测任务面向单变量时，研究对象为“Node_862”。

(3) \(ETT\) 数据集<sup>3</sup>: 包含 2016 年 7 月至 2018 年 7 月期间两个不同地区 \(\left(ETT_{1}、\(ETT_{2}\right)\) 电力变压器的负载和油温数据, 每 15 分钟记录一次。当预测任务面向单变量时, 研究对象为 “油温 \((OT)\)”。

(4) 气象数据集（Weather）4: 该数据集包含 2010 年至 2013 年间每小时记录的 12 个气象指标 (如气温、湿度等)。当预测任务面向单变量时, 研究对象为 “湿度 (Wet_Bulb)”。

由于各数据集的数据采集粒度不同，为确保它们包含相同任务的语义信息，本文将数据集均聚合到小时级别进行实验。在建模过程中，所有数据集均按6:2:2的比例划分为训练集、验证集和测试集。关于数据集的概况描述，如表2-3所示：


表 2-3 本文使用的数据集的概况描述 Table 2-3 Description of the datasets.


<table><tr><td>数据集</td><td>数据维度</td><td>数据大小</td><td>采集频率</td><td>聚合频率</td><td>数据领域</td></tr><tr><td>Electricity</td><td>321</td><td>(15447, 5095, 5093)</td><td>1小时</td><td>1小时</td><td>能源</td></tr><tr><td>Traffic</td><td>862</td><td>(10191, 3343, 3341)</td><td>1小时</td><td>1小时</td><td>交通</td></tr><tr><td>ETT1</td><td>7</td><td>(10117, 3317, 3317)</td><td>15分钟</td><td>1小时</td><td>能源</td></tr><tr><td>ETT2</td><td>7</td><td>(10117, 3317, 3317)</td><td>15分钟</td><td>1小时</td><td>能源</td></tr><tr><td>Weather</td><td>12</td><td>(20703, 6847, 6845)</td><td>1小时</td><td>1小时</td><td>气象</td></tr></table>


* 数据大小按（训练集、验证集、测试集）进行整理。


# 2.7.2 评价指标

对于所有预测方法，本文均采用均方误差（Mean Square Error, MSE）和平均绝对误差（Mean Absolute Error, MAE）进行评估。这两个指标从不同角度衡量预测误差：MSE 更关注预测结果中较大误差的部分；而 MAE 则对所有误差给予同等权重，更关注整体的误差情况。MSE 和 MAE 的计算过程分别如公式（2-17）和公式（2-18）所示：

$$
\mathrm {M S E} = \frac {1}{F \times N} \sum_ {q = 1} ^ {F} \sum_ {j = 1} ^ {N} \left(y _ {q, j} - \hat {y} _ {q, j}\right) ^ {2}, \tag {2-17}
$$

$$
\mathrm {M A E} = \frac {1}{F \times N} \sum_ {q = 1} ^ {F} \sum_ {j = 1} ^ {N} | y _ {q, j} - \hat {y} _ {q, j} |, \tag {2-18}
$$

其中  $y_{q,j}$  和  $\hat{y}_{q,j}$  分别表示第  $q$  个时间步的第  $j$  个变量的真实值与预测值，它们的维度均为  $\mathbb{R}^1$ 。

# 2.8 本章小结

本章围绕时间序列预测任务展开讨论，系统性地分析了基于线性变换、RNN、CNN、注意力机制和GNN的代表性方法，涵盖了时间序列预测中常用的深度学习基础方法及其主要变体。通过对各类方法的原理、信息提取过程、优劣势及适用场景的深入分析和理论复杂度的详细推导，本章为实际任务中的基础方法选择与模型优化提供了坚实的理论支撑。此外，本章还介绍了常用的时间序列数据集和评价指标，为模型性能的验证与评估奠定了可靠的数据基础。

# 3 水波型信息传递的长程时间序列预测方法

本章针对时间序列中趋势性、周期性、短期性、长期性、局部性和全局性难以同时被捕获的挑战，提出了一种水波型信息传递框架（Water-wave Information Transmission, WIT），以全面建模时间序列的复杂模式。该框架通过“水平-垂直”双粒度的信息传递机制，能够有效从长期和短期的尺度上提取趋势性和周期性模式，并通过循环式的信息选择与融合过程捕获全局特性与局部特性。此外，为提升计算效率，本章提出了通用的循环加速网络（Recurrent Acceleration Network, RAN），实现复杂度的优化，来提高模型在长程预测任务上的可拓展性。WIT 和 RAN 组合构成水波型信息传递与循环加速网络（WITRAN）。通过在五个真实场景下的基准数据集上展开实验，验证了 WITRAN 的杰出预测性能与运行效率。

# 3.1 引言

正如第一章开篇所述，长程时间序列预测任务通常涉及预测数百甚至上千个时间步的未来状态。为了实现如此长时间跨度的精准预测，需要从历史序列中充分提取时间模式语义信息[27,51]。然而它们通常具有高度复杂性和多样性，使得捕获这些信息的过程面临巨大挑战。

具体而言，可以从三个主要方面进行分析：

(1) 长期与短期模式。长期模式与短期模式的区分不依赖于数据点的数量，而是基于数据所体现的语义尺度。短期模式通常反映短时间内的数据变化，而长期模式则展示跨越较长时间尺度的数据变化趋势。

(2) 周期性与趋势性模式。时间序列通常具有重复的变化模式[56,95]，例如，不同天的同一小时可能表现出相似的变化规律，这种规律性可视为周期性模式。在建模周期性的同时，周期之间的关联性刻画了长期趋势，而周期内部的关联性则体现短期趋势，二者共同构成趋势性语义信息[51]。

(3) 全局与局部模式。局部模式信息通常反映数据中的短期变化，而全局语义信息则揭示时间序列中的长期态势[26,96,97]。这两者的有效结合有助于提升模型的鲁棒性和准确性，使其能够在捕获短期波动的同时，也能理解并预测长期的演变趋势。

如何在建模过程中同时捕获这三类模式信息，并确保计算效率，是构建长程时间序列预测方法的关键挑战。此外，为了提高预测的准确性，应引入更长时间跨度的历史序列作为输入[27,56]。

遗憾的是，尽管现有的先进方法已展现出优异性能，但在同时解决上述挑战时仍然面临诸多困难。具体而言，基于CNN的方法[48-50]尽管在计算效率上表现良好，复杂度随序列长度  $T$  呈线性增长，但它们要么受限于卷积核感受野大小的限制，必须依赖多层堆叠才能捕获全局信息[26]；要么仅能在一维输入序列上进行计算，难以有效直接建模周期性模式[51]，从而限制了它们对关键语义信息的全面捕获。基于注意力机制的方法[2,55,86,98]可根据是否使用点积注意力机制，大致分为两类。使用点积注意力机制的方法[2,22,54]虽然能够捕获序列中各点之间的相关性，但难以有效捕获序列中隐藏的语义信息[27,51]。而使用非点积注意力机制的方法[55,56,85]则要么计算复杂度较高，要么难以有效捕获周期性模式。其他类型的方法[39,99]在捕获这些语义信息方面同样存在一定局限性。

基于 RNN 的方法[43,44,100,101]通过其循环结构，在捕获全局和局部模式信息方面展现出了显著优势，并且具有与时间序列长度  $T$  呈线性的理论复杂度。然而，这些方法仍面临梯度消失/爆炸[25]和信息遗忘的问题，限制了它们在长程时间序列建模中的应用能力。

信息遗忘问题指的是，当 RNN 处理较长序列时，序列中较早部分的信息可能会在通过多个单元的过程中被遗忘。为了验证这一现象，本小节首先在 ECL 数据集上进行了实验。为了消除输入长度和输出长度变化对训练集、验证集及测试集划分的影响，本小节将输入序列和预测长度均固定为 720，并据此进行数据集划分。在实验中，通过仅使用输入序列的后  $\{24, 48, 72, \ldots, 696, 720\}$  个点作为输入，分别对 LSTM 和 GRU 展开实验，结果如图3-1所示。

![](images/7bf6bb0c9830abc972fd1d2cb058d415bf5cc5fefcdcebd5ce6c6534898df94e.jpg)



图3-1 LSTM和GRU的信息遗忘问题



Fig. 3-1 The issue of information forgetting in LSTM and GRU.


观察图3-1，一方面，可以看到当输入序列长度较短时（红色框外），LSTM和GRU的预测性能随着序列长度的增加而逐渐提高。这表明，较长的输入序列能够提供更多的上下文信息，从而提升模型的预测性能，这与先前的研究结果一


表 3-1 WITRAN 与其他方法相比的优势



Table 3-1 Advantages of WITRAN compared to other methods.


<table><tr><td>优势</td><td>(a) RNN</td><td>(b) WITRAN</td><td>(c) PatchTST</td><td>(d) MICN</td><td>(e) Full Attention</td><td>(f) TimesNet</td></tr><tr><td>非点级别的语义信息捕获方面</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✘</td><td>✓</td></tr><tr><td>捕获长期重复模式的特殊设计</td><td>✘</td><td>✓</td><td>✘</td><td>✘</td><td>✘</td><td>✓</td></tr><tr><td>有效(1或2层)建模全局相关性</td><td>✓(1)</td><td>✓(1)</td><td>✓(2)</td><td>✓(2)</td><td>✓(1)</td><td>✘</td></tr><tr><td>较好解决 RNN 的梯度消失/爆炸问题</td><td>✘</td><td>✓</td><td>-</td><td>-</td><td>-</td><td>-</td></tr></table>

致[39,56]。另一方面，红色框内的部分表明，当向LSTM和GRU输入更长的历史序列时，它们的预测性能并未继续提升。这表明，进一步引入过多早期的信息并未为模型带来显著收益，从而验证了RNN中存在信息遗忘问题。

因此，上述问题使得基于 RNN 的方法难以直接应用于长程预测任务。幸运的是，已有研究[27]提出，通过将信息划分为若干相邻时间步的片段并分别处理(Patch化操作)，也可以同时保留全局和局部模式。这一思路具有重要启发性，表明通过将 RNN 的输入划分为多个子序列并分别处理，可以有效缓解 RNN 自身的局限性，同时保持运算过程的高效性。

基于以上分析，本章提出了一种适用于长程时间序列预测任务的新框架，命名为水波型信息传递与循环加速网络（Water-wave Information Transmission and Recurrent Acceleration Network, WITRAN）。该框架包含两个关键组件：水波型信息传递框架（Water-wave Information Transmission, WIT）和循环加速网络（Recurrent Acceleration Network, RAN）。

为了突出WITRAN在信息传递过程中的优势，将其与RNN、CNN和Transformer这三类典型模型进行了对比，结果如图3-2所示。（更详细的对比分析见第二章。）

WITRAN 的整体信息传递过程如图3-2(b) 所示。为了有效捕获周期性和趋势性语义模式，WITRAN 首先根据输入序列的自然周期对其进行重排布，如图3-3(a) 所示。这一重新排列使得信息可以沿两个方向进行传递。具体来说，水平红色箭头表示短期尺度的趋势性信息传递，而垂直蓝色箭头则表示长期尺度的周期性信息传递。这两个方向的信息传递过程，类似于水波能量的传播，如图3-3(b) 所示。

为了在长期和短期尺度上，捕获周期性和趋势性模式，本章提出了一种新颖的双粒度门控选择单元（Horizontal Vertical Gated Selective Unit, HVGSU）。该单元集成了两个方向上的门控选择细胞（Gated Selective Cell, GSC），通过设计信息选择与融合操作，能有效提取每个时间步的长期周期性信息和短期趋势性信息。通过循环结构，HVGSU能够逐步捕获局部模式信息到全局模式信息。

![](images/331409af2cf7c4c7abf8a5d43080d759395103fe1e3b2d3894cfdb613e02a33e.jpg)



(a) RNN 信息传递过程


![](images/c2c07b1a96f4d2d71fbdabcc0e7637091082a090d0e59fd0f8e7a297043884a1.jpg)



(b) WITRAN 整体信息传递过程


![](images/303f96d1d33623d3c98e2d70bc31165adcae67b72ed4ea4defe831e35b143216.jpg)



(c) PatchTST 信息传递过程


![](images/c65ecb363cbd287faf70f45c8db93a667d04faceb8e533a41ca91e574db51775.jpg)



(d)MICN信息传递过程


![](images/428d63ec70b3f7c619b5a2e9fa690f057366c9558221bb5b52f07631ce3d76ce.jpg)



(e) Transformer 信息传递过程


![](images/506591aab182749f595fb5eaa97ae1d0b06557d8c0fbcb45bf1f4d9eb68dd37e.jpg)



(f) TimesNet 信息传递过程



图3-2 信息传递过程



Fig. 3-2 Information transmission processes.



表 3-2 各种预测模型的理论复杂度



Table 3-2 Complexity of forecasting models in training.


<table><tr><td>方法</td><td>RNN</td><td>WITRAN</td><td>PatchTST</td><td>MICN</td><td>Transformer</td><td>TimesNet</td></tr><tr><td>时间复杂度</td><td>\(\mathcal{O}(T)\)</td><td>\(\mathcal{O}(\sqrt{T})\)</td><td>\(\mathcal{O}((T/S)^2)\)</td><td>\(\mathcal{O}(T)\)</td><td>\(\mathcal{O}(T^2)\)</td><td>\(\mathcal{O}(T)\)</td></tr><tr><td>空间复杂度</td><td>\(\mathcal{O}(T)\)</td><td>\(\mathcal{O}(T)\)</td><td>\(\mathcal{O}((T/S)^2)\)</td><td>\(\mathcal{O}(T)\)</td><td>\(\mathcal{O}(T^2)\)</td><td>\(\mathcal{O}(T)\)</td></tr></table>


*  $T$  是序列长度， $S$  是 PatchTST 模型中的步长。


总结来说，本章的主要贡献如下：

(1) 提出了一种用于长程时间序列预测任务的水波型信息传递与循环加速网络 WITRAN, 其具有新颖的水波型信息传递方式 WIT, 能够在长期和短期两个尺度上实现信息传递, 以捕获到周期性和趋势性模式信息。

(2) 提出了一种新颖的双粒度门控选择单元 (HVGSU), 它通过在两个方向上独立使用门控选择细胞 (GSC), 能够分别提取长期周期性和短期趋势性。此外,利用 HVGSU 的循环结构有助于逐步捕获序列的局部到全局模式信息。

(3) 提出了一种循环加速网络 RAN, 实现  $\mathcal{O}(\sqrt{T})$  的时间复杂度, 以提升模型的计算效率, 同时保持  $\mathcal{O}(T)$  的空间复杂度。

(4) 通过在多个真实场景（能源、交通和气象）下的五个基准数据集上展开实

![](images/9e55b1242c94611718b5163ad803652dc7bfbead02864992f930fc008368d91f.jpg)



(a) 输入重排布前后，信息传递区别示意图


![](images/dece34774ea2aa571cb8950859ce7e64641fab5cc6fb1843593144fd00000603.jpg)



(b) “水波”式信息传递过程示意图



图3-3 WITRAN的信息处理过程



Fig. 3-3 Information processing of WITRAN.


验，证明了WITRAN在长程和超长程时间序列预测任务中的出色性能。此外，通过实验验证了RAN的引入极大地提高了计算效率。

# 3.2 水波型信息传递与循环加速网络

时间序列预测任务是基于  $T$  个时间步长的历史输入序列  $\mathbf{X} = \{\pmb{x}_1, \pmb{x}_2, \dots, \pmb{x}_T\} \in \mathbb{R}^{T \times N}$ ，预测未来  $F$  个时间步长的值  $\mathbf{Y} \in \mathbb{R}^{F \times N}$ ，其中  $N$  表示输入和输出特征的数量。为了充分整合历史信息进行分析， $T$  需要具有足够的长度[39,56]。此外，从历史输入中建模趋势性、周期性、长期性、短期性、局部性以及全局性模式至关重要。为同时解决这些问题，本章提出了WITRAN，这是一种类似于水波能量传播的新型信息传递框架，其整体架构如图3-4所示。WITRAN的核心模块由双粒度门控选择单元和循环加速网络组成，此外，还包含输入模块和输出模块。

![](images/a2d5bb62937501a0784c2134bee050cb79a251015adcb86a8f8bd7f6a19674d2.jpg)



图3-4WITRAN的总体架构图



Fig 3-4 Overall structure of WITRAN.


# 3.2.1 输入模块

为了便于从长期和短期的尺度分析周期性和趋势性，WITRAN受TimesNet[51]的启发，首先依据时间序列的自然周期，将其从一维重新排列为二维，如图3-3(a)所示。值得注意的是，与TimesNet利用  $\mathrm{FFT}^{[87]}$  自适应学习多个周期不同，WITRAN直接设定超参数为时间序列的自然周期数，以确定输入的重排布方式，使方法更加直观且计算开销更低。

此外，为了降低数据分布偏移的影响，WITRAN借鉴了NLinear[39]的思路，在时间维度引入归一化层以增强稳定性。此过程的形式化表达如公式（3-1）所示：

$$
\mathbf {X} _ {\mathrm {I D}} = \left\{ \begin{array}{l l} \mathbf {X} & , n o r m = 0 \\ \mathbf {X} - \boldsymbol {x} _ {T} & , n o r m = 1 \end{array} , \right. \tag {3-1}
$$

其中， $\mathbf{X} \in \mathbb{R}^{T \times N}$  表示原始输入序列， $\pmb{x}_T \in \mathbb{R}^N$  表示原始序列中最后一个时间步的输入。norm 是一个沿时间维度用于归一化的超参数，能够针对不同任务进行适当调整。

为了直接捕获序列的周期模式，需要根据周期数  $P$  将归一化后的输入  $\mathbf{X}_{\mathrm{ID}}$  从一维重排布至二维。同时，为了使每个变量上的每个时间步都能引入时间戳信息，需要首先将原始时间戳  $\mathbf{TF}_{\mathrm{hist}}$  在  $N$  个变量上进行复制，并与拓展维度后的序列输入在最后一维上拼合，随后统一进行二维排布操作。该过程的形式化表达如公式（3-2）所示：

$$
\mathcal {X} _ {1 \mathrm {D}} = \operatorname {U n s q u e e z e} \left(\mathbf {X} _ {1 \mathrm {D}}\right), \tag {3-2a}
$$

$$
\mathcal {T} F _ {\text {h i s t}} = \operatorname {R e p e a t} \left(\mathbf {T F} _ {\text {h i s t}}\right), \tag {3-2b}
$$

$$
\mathcal {I} n _ {1 \mathrm {D}} = \left[ \mathcal {X} _ {1 \mathrm {D}}, \mathcal {T} F _ {\text {h i s t}} \right], \tag {3-2c}
$$

$$
\Im n _ {2 \mathrm {D}} = \operatorname {R e s h a p e} \left(\Im n _ {1 \mathrm {D}}\right), \tag {3-2d}
$$

其中  $\mathfrak{X}_{\mathrm{1D}}\in \mathbb{R}^{T\times N\times 1}$  表示在原始序列基础上拓展了一维后的张量，Unsqueeze(·）表示维度拓展操作。  $\mathcal{T}F_{\mathrm{hist}}\in \mathbb{R}^{T\times N\times D}$  表示在  $N$  个通道上复制后的时间戳信息，Repeat(·）表示复制操作。[ ]表示拼合（Concat）操作，  $\mathfrak{I}n_{\mathrm{1D}}\in \mathbb{R}^{T\times N\times (D + 1)}$  表示拼合时间戳信息后的序列输入。Reshape(·）表示重排布操作，  $\mathfrak{I}n_{2\mathrm{D}}\in \mathbb{R}^{R\times P\times N\times (D + 1)}$  表示最终输入至模型的数据格式。其中，  $R$  表示时间序列重排布后在时间维度上的行数，  $P$  为周期数，即时间序列重排布后在时间维度上的列数。

# 3.2.2 双粒度门控选择单元

为了有效捕获长期周期性与短期趋势性语义信息，并保持其完整性，本章提出了一种新颖的双粒度门控选择单元（Horizontal Vertical Gated Selective Unit, HVGSU）。HVGSU由两个方向上的门控选择细胞（Gated Selective Cell, GSC）组成，以分别建模长期周期性与短期趋势性。门控机制被设计用于捕获每个时间步上这两方面语义信息之间的相关性。此外，HVGSU采用循环结构，使其能够逐步整合局部信息，最终获得全局语义特征。本小节将对GSC和HVGSU的具体设计与实现过程进行详细介绍。

![](images/2eedbb9e358c1fd8bc7b130a95223e1c4c50e20ed1aa0e7e0223c4eeb0625a50.jpg)



(a) GSC结构图


![](images/aa6a6ed04a10a9e8ea3073f7c82d8cd0debb79bd7faa02e4b67908c54a4464e0.jpg)



(b)HVGSU结构图



图3-5 GSC和HVGSU的结构图



Fig. 3-5 The structure of proposed method.


# (1) 门控选择细胞 (GSC) 结构设计与计算过程

受到  $\mathrm{LSTM}^{[43]}$  和  $\mathrm{GRU}^{[44]}$  这两种流行的基于 RNN 模型的启发（如 2.3.2 小节所分析），本节提出了一种门控选择细胞（GSC），用于高效选择和融合信息。其结构如图 3-5(a) 所示，包含选择门（Selection Gate）和输出门（Output Gate）两个核心部分。融合信息由输入、主（Principal, pri）隐藏状态和从（Subordinate, sub）隐藏状态组成。选择门决定保留多少原始主隐藏状态的信息，并选择添加多少融合信息。输出门决定当前单元最终输出的信息。图 3-5(a) 中不同颜色的箭头表示不同的语义信息传递过程：黑色箭头表示输入信息的传递；红色箭头表示主隐藏状态的传递；蓝色箭头表示从隐藏状态的传递；紫色箭头表示融合信息的传递。

GSC 的计算过程可形式化表达如公式（3-3）所示：

$$
\boldsymbol {S} _ {t} = \sigma \left(\mathbf {W} _ {s} \left[ h _ {t - 1} ^ {\text {p r i}}, h _ {t - 1} ^ {\text {s u b}}, i n \right] + \boldsymbol {b} _ {s}\right) \tag {3-3a}
$$

$$
\boldsymbol {o} _ {t} = \sigma \left(\mathbf {W} _ {o} \left[ h _ {t - 1} ^ {\text {p r i}}, h _ {t - 1} ^ {\text {s u b}}, i n \right] + \boldsymbol {b} _ {o}\right) \tag {3-3b}
$$

$$
\boldsymbol {h} _ {f} = \tanh  \left(\mathbf {W} _ {f} \left[ \boldsymbol {h} _ {t - 1} ^ {\text {p r i}}, \boldsymbol {h} _ {t - 1} ^ {\text {s u b}}, \boldsymbol {i n} \right] + \boldsymbol {b} _ {f}\right) \tag {3-3c}
$$

$$
\widetilde {\boldsymbol {h}} _ {t - 1} ^ {\text {p r i}} = \left(1 - \boldsymbol {S} _ {t}\right) \odot \boldsymbol {h} _ {t - 1} ^ {\text {p r i}} + \boldsymbol {S} _ {t} \odot \boldsymbol {h} _ {f} \tag {3-3d}
$$

$$
\boldsymbol {h} _ {t} ^ {\text {p r i}} = \tanh  \left(\widetilde {\boldsymbol {h}} _ {t - 1} ^ {\text {p r i}}\right) \odot \boldsymbol {o} _ {t}, \tag {3-3e}
$$

其中， $h_{t-1}^{\mathrm{pri}}$  和  $h_{t-1}^{\mathrm{sub}} \in \mathbb{R}^{dm}$  分别表示当前时间步  $t$  输入的主隐藏状态和从隐藏状态， $\mathbf{i}n \in \mathbb{R}^{di}$  表示输入信息。 $\mathbf{W}_* \in \mathbb{R}^{dm \times (2dm + di)}$  为模型训练的权重矩阵， $b_* \in \mathbb{R}^{dm}$  为相应的偏置向量。 $\boldsymbol{S}_t$  和  $\boldsymbol{o}_t$  分别表示选择门和输出门， $\odot$  表示逐元素的乘法操作， $\sigma(\cdot)$  和  $\tanh(\cdot)$  分别表示 sigmoid 和  $\tanh$  激活函数。 $\boldsymbol{h}_f$  和  $\widetilde{\boldsymbol{h}}_{t-1}^{\mathrm{pri}} \in \mathbb{R}^{dm}$  为计算的中间变量， $\boldsymbol{h}_t^{\mathrm{pri}}$  表示最终输出的隐藏状态。

# (2) 双粒度门控选择单元 (HVGSU) 结构设计与计算过程

如图3-5 (b) 所示，循环结构化的HVGSU计算过程可形式化表示如公式（3-4）所示：

$$
\mathcal {H} _ {\text {h o r}}, \mathcal {H} _ {\text {v e r}}, \mathcal {O} u t = \operatorname {H V G S U} \left(\mathrm {I} n _ {2 \mathrm {D}}\right), \tag {3-4}
$$

其中， $\mathcal{H}_{\mathrm{hor}} \in \mathbb{R}^{L \times R \times dm}$  和  $\mathcal{H}_{\mathrm{ver}} \in \mathbb{R}^{L \times P \times dm}$  分别表示HVGSU的水平方向和垂直方向的隐藏状态输出。 $L$  为模型深度， $\mathcal{O}ut \in \mathbb{R}^{R \times P \times dm}$  表示最后一层的输出信息。

HVGSU 的基本计算单元结构如图3-5 (b) 所示，每个单元包含两个方向的 GSC，用于建模周期内和周期间的语义信息。在第  $l$  层的第  $r$  行、第  $p$  列单元的计算过程如下：

$$
\boldsymbol {h} _ {r, p} ^ {\operatorname {h o r} (l)} = \operatorname {G S C} _ {\text {h o r}} \left(\boldsymbol {i n} _ {r, p} ^ {(l)}, \boldsymbol {h} _ {r, p - 1} ^ {\operatorname {h o r} (l)}, \boldsymbol {h} _ {r - 1, p} ^ {\operatorname {v e r} (l)}\right) \tag {3-5a}
$$

$$
\boldsymbol {h} _ {r, p} ^ {\operatorname {v e r} (l)} = \operatorname {G S C} _ {\operatorname {v e r}} \left(\boldsymbol {i n} _ {r, p} ^ {(l)}, \boldsymbol {h} _ {r - 1, p} ^ {\operatorname {v e r} (l)}, \boldsymbol {h} _ {r, p - 1} ^ {\operatorname {h o r} (l)}\right) \tag {3-5b}
$$

$$
\boldsymbol {o} _ {r, p} ^ {(l)} = \left[ \boldsymbol {h} _ {r, p} ^ {\operatorname {h o r} (l)}, \boldsymbol {h} _ {r, p} ^ {\operatorname {v e r} (l)} \right], \tag {3-5c}
$$

其中， $\mathbf{i}n_{r,p}^{(l)} \in \mathbb{R}^{di}$  表示单元的输入数据。当  $l = 1$  时， $\mathbf{i}n_{r,p}^{(l)} = \mathbf{x}_{r,p} \in \mathbb{R}^{N + D}$  表示原始输入数据；当  $l > 1$  时， $\mathbf{i}n_{r,p}^{(l)} = \mathbf{o}_{r,p}^{(l - 1)} \in \mathbb{R}^{2 \times dm}$  表示来自上一层的输入。 $\pmb{h}_{r,p - 1}^{\mathrm{hor}(l)}$  和  $\pmb{h}_{r - 1,p}^{\mathrm{ver}(l)} \in \mathbb{R}^{dm}$  分别表示当前单元的水平方向和垂直方向的隐藏状态输入。需要注意的是，当  $r = 1$  时， $\pmb{h}_{r - 1,p}^{\mathrm{ver}(l)}$  被替换为相同大小的全零向量；当  $p = 1$  时， $\pmb{h}_{r,p - 1}^{\mathrm{hor}(l)}$  同样被替换为全零向量。 $[\cdot]$  表示拼合操作， $\pmb{o}_{r,p}^{(l)} \in \mathbb{R}^{2 \times dm}$  为该单元的最终输出。

# 3.2.3 循环加速网络

在传统的循环结构中，序列中相邻的两个时间步之间存在依赖关系，后一个时间步必须等待前一个时间步的信息计算完成后才能开始。这种顺序计算方式在序列较长时，尤其是在处理大型数据时，会导致计算效率低下，变得非常缓慢。

幸运的是，在本章设计的WIT框架中，部分时间步的信息可以并行处理，从而提高计算效率。具体来说，如图3-3(b)所示，当一个点计算完成后，水平方向上的右侧点和垂直方向上的下方点可以立即开始计算，且无需相互等待。因此，本小节提出了循环加速网络（RAN）作为加速框架，它能够通过并行计算数据点来显著提高HVGSU中信息传递的效率。

![](images/97ab51e518bc3b47a9ec72de6d7a94466e8ca7678cb6fe132334b42178168ea9.jpg)



图3-6 RAN的结构图



Fig. 3-6 The structure of RAN.


RAN 通过将可并行计算的点放置在同一个切片中，优化了信息传递过程。更新后的信息传递过程如图3-6所示，其中每个绿色框代表一个切片（Slice），绿色框的数量表示循环计算所需的次数。其他标记的含义与图3-3中相同。

# 3.2.4 预测模块

在预测模块中，本方法先通过拼合HVGSU水平方向和垂直方向的隐藏状态输出，并借鉴了Pyraformer[56]的思路，通过全连接层进行预测，解决了自回归结构中的误差累积问题，如图3-4所示。

具体来说，在预测模块中，仅使用HVGSU水平方向的最后一行隐藏状态，因为它包含了历史序列中足够的全局和最新的短期语义信息。与此同时，垂直方向的隐藏状态中所有列均被保留，因为它们代表了不同模式下的周期性语义信息。这样组合方式不仅最大限度地保留了预测点所需的各种语义信息，同时避免了信息冗余，从而获得准确的预测。该模块的计算过程可形式化表达如公式（3-6）所示：

$$
\mathcal {H} _ {\text {r e p}} ^ {\text {h o r}} = \text {R e p e a t} \left(\tilde {\mathcal {H}} _ {\text {h o r}}\right) \tag {3-6a}
$$

$$
\mathbf {H} _ {\mathrm {h} - \mathrm {v}} = \text {R e s h a p e} \left(\left[ \mathcal {H} _ {\text {r e p}} ^ {\text {h o r}}, \mathcal {H} _ {\text {v e r}} \right]\right) \tag {3-6b}
$$

$$
\widetilde {\mathbf {Y}} = \operatorname {F C 1} \left(\mathbf {H} _ {\mathrm {h} - \mathrm {v}}\right) \tag {3-6c}
$$

$$
\hat {\mathbf {Y}} = \operatorname {F C 2} \left(\operatorname {R e s h a p e} \left(\widetilde {\mathbf {Y}}\right) + \mathbf {T E} _ {\text {p r e d}}\right), \tag {3-6d}
$$

其中， $\mathbf{TE}_{\mathrm{pred}} \in \mathbb{R}^{F \times dm}$  表示预测点的时间特征编码。 $\tilde{\mathcal{H}}_{\mathrm{hor}} \in \mathbb{R}^{L \times 1 \times dm}$  表示  $\mathcal{H}_{\mathrm{hor}}$  中最后一行的隐藏状态。Repeat() 表示复制操作， $\mathcal{H}_{rep}^{\mathrm{hor}} \in \mathbb{R}^{L \times P \times dm}$  表示复制操作后的隐藏状态。 $\mathbf{H}_{\mathrm{h-v}} \in \mathbb{R}^{P \times (L*2dm)}$  表示经过转置的水平和垂直组合向量。FC1 和 FC2 分别表示两个全连接层。 $\widetilde{\mathbf{Y}} \in \mathbb{R}^{P \times (R_{\mathrm{de}}*dm)}$  是计算得到的中间变量，其中  $R_{\mathrm{de}} \times P = F$  。 $\hat{\mathbf{Y}}$  为最终输出，特别需要说明的是，当  $norm = 1$  时，还需要进行逆归一化操作，即  $\hat{\mathbf{Y}} = \hat{\mathbf{Y}} + \boldsymbol{x}_T$  。

# 3.2.5 理论复杂度分析

以序列长度  $T$  ，输入维度  $d\mathrm{i}$  ，隐藏层维度  $dm$  为例，分析单层WITRAN的计算复杂度。在RAN框架下，循环长度由序列长度  $T = R\times P$  变为  $R + P - 1$  ，其中  $R$  和  $P$  的复杂度均为  $\mathcal{O}(\sqrt{T})$  。基于此，WITRAN通过RAN框架能够将时间复杂度降低至  $\mathcal{O}(\sqrt{T})$  。需要说明的是，尽管WITRAN通过并行计算相关数据点可能会增加内存开销，但由于WITRAN需要保存序列中每个点的输出信息，因此其并行计算带来的开销  $\mathcal{O}(\sqrt{T})$  显著低于保存输出变量的复杂度  $\mathcal{O}(T)$  。因此，WITRAN的空间复杂度可以总结为  $\mathcal{O}(T)$  。

# 3.3 实验评估

为了全面评估本章所提出的WITRAN方法的性能，本节在第2.7节中提到的五个真实场景下的基准数据集上进行了广泛的实验，并将对实验结果进行详细讨论与分析。

# 3.3.1 基线方法

鉴于先前已有不少研究[2,55]指出，传统方法（如ARIMA和简单的RNN/CNN模型）表现不佳，同时早期基于注意力机制的模型（如LogTrans[85]和Reformer[86]）可以被新的研究方法明显超越。因此，本节选择了六种基于注意力机制的模型：

PatchTST[27]、FEDformer[54]、Pyraformer[56]、Autoformer[55]、Informer[2]、Transformer[22]，以及四种其他类别的方法：MICN[26]、TimesNet[51]、DLinear[39]、FiLM[99]，展开实验和分析。

# 3.3.2 实验设置

过去的研究[27]已经指出，变量的独立建模对于多变量时间序列的处理是有效的，但由于这种方式未对变量维度进行计算操作，而是仅在时间维度进行计算操作，因此这进一步说明了充分建模时间模式信息对预测性能的影响至关重要。为了去除通道间异质性[2]带来的干扰，并准确评估WITRAN在时间维度建模中的有效性，本节仅以单变量作为研究对象，展开实验。

本节参考了Pyraformer[56]的实验设置，设计了五种长程时间序列预测任务，包括：168-168（历史输入为168步，预测长度为168步）、168-336、336-336、336-720、720-720，以及三种超长程时间序列预测任务：720-1440、1440-1440和1440-2880。WITRAN和所有基线模型均基于PyTorch[102]实现，并在NVIDIA RTX A4000 16GB GPU上进行实验。

所有模型均使用相同的L2损失函数（MSE）和Adam优化器[103]进行训练，初始学习率设为  $10^{-3}$ ，批量大小（Batch size）为32。最大训练轮数设定为25，若验证集的L2损失在连续5轮内未下降，则提前停止训练。

为确保公平比较，本节为所有模型的公共参数设定了相同的搜索空间：具体而言：（1）设定模型的隐藏维度  $dm$  的范围为  $\{32,64,128,256,512,1024\}$ ；（2）设定模型编码器和解码器的层数的范围为  $\{1,2,3\}$ ；（3）设定注意力机制头数的范围为  $\{1,2,4,8\}$ 。对于各模型特有的超参数，参考其原始论文进行确定。所有模型的最佳参数均基于验证集上的最小损失函数值选择，以确保各模型在相同条件下达到最优性能。

# 3.3.3 预测性能分析

# (1) 长程预测任务实验结果及分析

长程时间序列预测任务的结果如表3-3所示，以左侧的168-336任务设置为例，它表示输入长度为168，预测长度为336。可以观察到，本章提出的WITRAN超越了所有基线方法，实现了最佳的预测性能，平均MSE降低了  $5.803\%$  。具体而言，WITRAN在ECL数据集上平均MSE降低了  $10.246\%$  ，在Traffic数据集上降低了 $3.879\%$  ，在  $ETTh_{1}$  数据集上降低了  $2.519\%$  ，在  $ETTh_{2}$  数据集上降低了  $4.431\%$  ，在Weather数据集上降低了  $7.93\%$  。从结果可以发现，虽然基线模型之间的竞争非常

激烈，但没有一个模型在所有任务中始终保持良好的表现。相比之下，WITRAN能在各数据集的不同任务上都展现出了显著的优势。并且在大多数情况下，当面对同样长度的预测任务，WITRAN的输入长度越长，预测效果也越好。上述所有发现共同证明了WITRAN在捕获现实场景中复杂时间模式信息的有效性。

# (2）超长程预测任务实验结果及分析

超长程时间序列预测任务的结果如表3-4所示。总体来说，WITRAN在三个超长程预测任务中均达到了最佳的预测性能，平均MSE降低了  $14.275\%$  。具体而言，WITRAN在ECL数据集上平均MSE降低了  $39.916\%$  ，在Traffic数据集上降低了 $3.122\%$  ，在  $ETTh_{1}$  数据集上降低了  $14.837\%$  ，在  $ETTh_{2}$  数据集上降低了  $2.441\%$  在Weather数据集上降低了  $11.062\%$  。

尤其值得注意的是，WITRAN在ECL、ETTh<sub>1</sub>和Weather数据集上均表现出了超过  $10\%$  的显著提升，进一步证明了其在超长程时间序列预测中的强大能力。通过比较长程预测与超长程预测的结果，可以发现WITRAN在超长程预测任务中的表现更为出色，这再次凸显了WITRAN从时间序列中充分提取相关模式信息方面的有效性。

# 3.3.4 运行效率分析

为全面评估WITRAN的实际运行效率，本小节对比了其与性能领先的基线模型在显存开销和运行速度方面的表现。需要指出的是， $\mathrm{FiLM}^{[99]}$  的实验结果表明， $\mathrm{Transformer}^{[22]}$ 、 $\mathrm{Informer}^{[2]}$  和  $\mathrm{Autoformer}^{[55]}$  的实际运行效率均低于FiLM。为保证对比方法的代表性和实验的高效性，本小节选取了FiLM作为基准方法进行比较，而不再对比上述三种方法。

具体而言，本小节设计了两种实验场景，以评估模型在不同输入与预测长度下的运行效率：（1）固定输入长度，仅调整预测长度；（2）固定预测长度，仅调整输入长度。在这两种场景中，输入长度和预测长度的固定值均设定为720，以确保实验的可比性。

为保证公平性，本小节严格控制所有对比方法的参数设置，确保模型的参数规模是相同的。具体而言，所有模型的隐藏维度  $dm$  统一设置为 1024，注意力头数固定为 8。此外，为最大程度涵盖更多模型，并减少显存溢出（Out of Memory, OOM）问题，所有实验的批量大小均设定为 8。各方法的对比结果如图3-7所示。需要强调的是，由于 TimesNet 的显存消耗极高，在上述参数设置情况下，即使将批量大小设置为 1，其仍然会出现 OOM 的问题，因此在图3-7中未包含 TimesNet。


表3-3 长程时间序列预测任务实验结果Table3-3Long-range time seriesforecasting results.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">WITRAN(Ours)</td><td colspan="2">MICN</td><td colspan="2">TimesNet</td><td colspan="2">PatchTST</td><td colspan="2">DLinear</td><td colspan="2">FiLM</td><td colspan="2">FEDformer</td><td colspan="2">Pyraformer</td><td colspan="2">Autoformer</td><td colspan="2">Informer</td><td colspan="2">Transformer</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="5">ECL</td><td>168-168</td><td>0.2397</td><td>0.3519</td><td>0.3168</td><td>0.4067</td><td>0.2825</td><td>0.3797</td><td>0.2980</td><td>0.3832</td><td>0.2605</td><td>0.3579</td><td>0.2587</td><td>0.3557</td><td>0.3028</td><td>0.4020</td><td>0.2651</td><td>0.3802</td><td>0.3496</td><td>0.4337</td><td>0.3779</td><td>0.4594</td><td>0.3036</td><td>0.4068</td></tr><tr><td>168-336</td><td>0.2607</td><td>0.3721</td><td>0.3002</td><td>0.4053</td><td>0.3505</td><td>0.4253</td><td>0.3840</td><td>0.4393</td><td>0.3080</td><td>0.3946</td><td>0.3062</td><td>0.3922</td><td>0.3522</td><td>0.4394</td><td>0.5392</td><td>0.5271</td><td>0.4733</td><td>0.5120</td><td>0.5037</td><td>0.5301</td><td>0.3583</td><td>0.4435</td></tr><tr><td>336-336</td><td>0.2517</td><td>0.3627</td><td>0.3092</td><td>0.4132</td><td>0.3702</td><td>0.4307</td><td>0.4377</td><td>0.4654</td><td>0.2740</td><td>0.3720</td><td>0.2722</td><td>0.3659</td><td>0.3378</td><td>0.4303</td><td>0.2994</td><td>0.4030</td><td>0.5153</td><td>0.5304</td><td>0.4591</td><td>0.4991</td><td>0.5771</td><td>0.5643</td></tr><tr><td>336-720</td><td>0.3084</td><td>0.4055</td><td>0.3820</td><td>0.4704</td><td>0.3879</td><td>0.4531</td><td>0.5502</td><td>0.5438</td><td>0.3208</td><td>0.4188</td><td>0.3171</td><td>0.4152</td><td>0.3813</td><td>0.4634</td><td>0.4856</td><td>0.5243</td><td>0.5045</td><td>0.5393</td><td>0.6545</td><td>0.5975</td><td>0.4368</td><td>0.4920</td></tr><tr><td>720-720</td><td>0.2478</td><td>0.3651</td><td>0.3463</td><td>0.4381</td><td>0.3537</td><td>0.4386</td><td>0.5927</td><td>0.5742</td><td>0.3203</td><td>0.4202</td><td>0.3158</td><td>0.4154</td><td>0.4023</td><td>0.4769</td><td>0.3115</td><td>0.4218</td><td>0.9639</td><td>0.7520</td><td>0.4850</td><td>0.5238</td><td>0.3992</td><td>0.4640</td></tr><tr><td rowspan="5">Traffic</td><td>168-168</td><td>0.1377</td><td>0.2051</td><td>0.2428</td><td>0.3543</td><td>0.1490</td><td>0.2293</td><td>0.1622</td><td>0.2320</td><td>0.1519</td><td>0.2195</td><td>0.1501</td><td>0.2143</td><td>0.2469</td><td>0.3479</td><td>0.2979</td><td>0.3815</td><td>0.2378</td><td>0.3490</td><td>0.3363</td><td>0.3994</td><td>1.5204</td><td>0.9594</td></tr><tr><td>168-336</td><td>0.1321</td><td>0.2059</td><td>0.2401</td><td>0.3514</td><td>0.1499</td><td>0.2356</td><td>0.1641</td><td>0.2364</td><td>0.1468</td><td>0.2210</td><td>0.1453</td><td>0.2165</td><td>0.2426</td><td>0.3449</td><td>0.5838</td><td>0.5652</td><td>0.2683</td><td>0.3803</td><td>0.5891</td><td>0.5608</td><td>0.6953</td><td>0.6015</td></tr><tr><td>336-336</td><td>0.1306</td><td>0.2054</td><td>0.2413</td><td>0.3549</td><td>0.1446</td><td>0.2300</td><td>0.1546</td><td>0.2332</td><td>0.1325</td><td>0.2114</td><td>0.1324</td><td>0.2104</td><td>0.2339</td><td>0.3365</td><td>0.4703</td><td>0.4964</td><td>0.2460</td><td>0.3567</td><td>0.5447</td><td>0.5384</td><td>0.8482</td><td>0.6424</td></tr><tr><td>336-720</td><td>0.1391</td><td>0.2175</td><td>0.2422</td><td>0.3513</td><td>0.1584</td><td>0.2440</td><td>0.1747</td><td>0.2536</td><td>0.1449</td><td>0.2252</td><td>0.1438</td><td>0.2229</td><td>0.2987</td><td>0.3976</td><td>0.5235</td><td>0.5292</td><td>0.2849</td><td>0.3956</td><td>1.2044</td><td>0.8254</td><td>0.7320</td><td>0.6233</td></tr><tr><td>720-720</td><td>0.1408</td><td>0.2191</td><td>0.2552</td><td>0.3709</td><td>0.1546</td><td>0.2410</td><td>0.1543</td><td>0.2441</td><td>0.1410</td><td>0.2241</td><td>0.1383</td><td>0.2208</td><td>0.2667</td><td>0.3685</td><td>0.4811</td><td>0.4962</td><td>0.2959</td><td>0.4045</td><td>1.2954</td><td>0.9205</td><td>1.1963</td><td>0.8271</td></tr><tr><td rowspan="5">ETTh1</td><td>168-168</td><td>0.1105</td><td>0.2589</td><td>0.1257</td><td>0.2803</td><td>0.1133</td><td>0.2612</td><td>0.1212</td><td>0.2704</td><td>0.1122</td><td>0.2605</td><td>0.1091</td><td>0.2558</td><td>0.1284</td><td>0.2826</td><td>0.1534</td><td>0.3287</td><td>0.1318</td><td>0.2872</td><td>0.1563</td><td>0.3299</td><td>0.1504</td><td>0.3257</td></tr><tr><td>168-336</td><td>0.1189</td><td>0.2714</td><td>0.1422</td><td>0.3006</td><td>0.1202</td><td>0.2732</td><td>0.1287</td><td>0.2808</td><td>0.1251</td><td>0.2794</td><td>0.1187</td><td>0.2708</td><td>0.1271</td><td>0.2810</td><td>0.1665</td><td>0.3419</td><td>0.1315</td><td>0.2878</td><td>0.1663</td><td>0.3335</td><td>0.1599</td><td>0.3324</td></tr><tr><td>336-336</td><td>0.1112</td><td>0.2638</td><td>0.1576</td><td>0.3159</td><td>0.1279</td><td>0.2846</td><td>0.1496</td><td>0.3039</td><td>0.1261</td><td>0.2803</td><td>0.1196</td><td>0.2738</td><td>0.1252</td><td>0.2794</td><td>0.1408</td><td>0.3087</td><td>0.1384</td><td>0.2959</td><td>0.1648</td><td>0.3291</td><td>0.1438</td><td>0.3121</td></tr><tr><td>336-720</td><td>0.1494</td><td>0.3092</td><td>0.2219</td><td>0.3729</td><td>0.1501</td><td>0.3127</td><td>0.2092</td><td>0.3659</td><td>0.1942</td><td>0.3462</td><td>0.1793</td><td>0.3335</td><td>0.1534</td><td>0.3178</td><td>0.3984</td><td>0.5202</td><td>0.1928</td><td>0.3450</td><td>0.1522</td><td>0.3203</td><td>0.1644</td><td>0.3304</td></tr><tr><td>720-720</td><td>0.1296</td><td>0.2868</td><td>0.2959</td><td>0.4402</td><td>0.1510</td><td>0.3118</td><td>0.2178</td><td>0.3694</td><td>0.1920</td><td>0.3435</td><td>0.1845</td><td>0.3379</td><td>0.1386</td><td>0.2995</td><td>0.1563</td><td>0.3253</td><td>0.2388</td><td>0.3869</td><td>0.1595</td><td>0.3259</td><td>0.1730</td><td>0.3414</td></tr><tr><td rowspan="5">ETTh2</td><td>168-168</td><td>0.2389</td><td>0.3813</td><td>0.2734</td><td>0.4162</td><td>0.2655</td><td>0.4051</td><td>0.2582</td><td>0.3983</td><td>0.2556</td><td>0.3944</td><td>0.2546</td><td>0.3942</td><td>0.2844</td><td>0.4285</td><td>0.2746</td><td>0.4080</td><td>0.2903</td><td>0.4326</td><td>0.3764</td><td>0.4863</td><td>0.3043</td><td>0.4365</td></tr><tr><td>168-336</td><td>0.2277</td><td>0.3778</td><td>0.3017</td><td>0.4429</td><td>0.2725</td><td>0.4163</td><td>0.3206</td><td>0.4515</td><td>0.2891</td><td>0.4256</td><td>0.2894</td><td>0.4263</td><td>0.2961</td><td>0.4355</td><td>0.2392</td><td>0.3834</td><td>0.4447</td><td>0.4964</td><td>0.3364</td><td>0.4583</td><td>0.3662</td><td>0.4671</td></tr><tr><td>336-336</td><td>0.2432</td><td>0.3922</td><td>0.3472</td><td>0.4796</td><td>0.3184</td><td>0.4431</td><td>0.3559</td><td>0.4779</td><td>0.2950</td><td>0.4329</td><td>0.2951</td><td>0.4347</td><td>0.2884</td><td>0.4314</td><td>0.2610</td><td>0.4010</td><td>0.2805</td><td>0.4255</td><td>0.3709</td><td>0.4785</td><td>0.3218</td><td>0.4412</td></tr><tr><td>336-720</td><td>0.2373</td><td>0.3888</td><td>0.4248</td><td>0.5268</td><td>0.2858</td><td>0.4253</td><td>0.4936</td><td>0.5592</td><td>0.4125</td><td>0.5136</td><td>0.4158</td><td>0.5162</td><td>0.3425</td><td>0.4656</td><td>0.2341</td><td>0.3818</td><td>0.3372</td><td>0.4625</td><td>0.3572</td><td>0.4675</td><td>0.3582</td><td>0.4629</td></tr><tr><td>720-720</td><td>0.2635</td><td>0.4018</td><td>0.3549</td><td>0.4805</td><td>0.2936</td><td>0.4238</td><td>0.5243</td><td>0.5745</td><td>0.3495</td><td>0.4749</td><td>0.4045</td><td>0.5105</td><td>0.3275</td><td>0.4534</td><td>0.2795</td><td>0.4151</td><td>0.4668</td><td>0.5477</td><td>0.3585</td><td>0.4699</td><td>0.3087</td><td>0.4320</td></tr><tr><td rowspan="5">Weather</td><td>168-168</td><td>0.2050</td><td>0.3338</td><td>0.2231</td><td>0.3489</td><td>0.2420</td><td>0.3608</td><td>0.2469</td><td>0.3597</td><td>0.2421</td><td>0.3578</td><td>0.2426</td><td>0.3544</td><td>0.2583</td><td>0.3774</td><td>0.2144</td><td>0.3451</td><td>0.2670</td><td>0.3813</td><td>0.2639</td><td>0.3926</td><td>0.2200</td><td>0.3438</td></tr><tr><td>168-336</td><td>0.2197</td><td>0.3470</td><td>0.2663</td><td>0.3837</td><td>0.2821</td><td>0.3885</td><td>0.3040</td><td>0.4049</td><td>0.2918</td><td>0.3975</td><td>0.2981</td><td>0.3988</td><td>0.2909</td><td>0.4030</td><td>0.2594</td><td>0.3833</td><td>0.2990</td><td>0.4096</td><td>0.2798</td><td>0.4061</td><td>0.2230</td><td>0.3488</td></tr><tr><td>336-336</td><td>0.2163</td><td>0.3482</td><td>0.2701</td><td>0.3804</td><td>0.2684</td><td>0.3752</td><td>0.3149</td><td>0.4145</td><td>0.2905</td><td>0.3969</td><td>0.2943</td><td>0.3969</td><td>0.2791</td><td>0.3984</td><td>0.2310</td><td>0.3591</td><td>0.3066</td><td>0.4162</td><td>0.2898</td><td>0.4129</td><td>0.2308</td><td>0.3556</td></tr><tr><td>336-720</td><td>0.2054</td><td>0.3424</td><td>0.3086</td><td>0.4138</td><td>0.2930</td><td>0.4045</td><td>0.4358</td><td>0.4937</td><td>0.3897</td><td>0.4739</td><td>0.4096</td><td>0.4767</td><td>0.2648</td><td>0.3915</td><td>0.3241</td><td>0.4300</td><td>0.3468</td><td>0.4592</td><td>0.2483</td><td>0.3778</td><td>0.2334</td><td>0.3570</td></tr><tr><td>720-720</td><td>0.2008</td><td>0.3417</td><td>0.2828</td><td>0.3969</td><td>0.2967</td><td>0.4070</td><td>0.5701</td><td>0.5491</td><td>0.3724</td><td>0.4614</td><td>0.3999</td><td>0.4661</td><td>0.2416</td><td>0.3728</td><td>0.2378</td><td>0.3684</td><td>0.4309</td><td>0.5085</td><td>0.3545</td><td>0.4569</td><td>0.2463</td><td>0.3722</td></tr></table>


* 表中较低的 MSE 或 MAE 表示更好的预测性能。每个任务上的最佳结果通过加粗标示，次优结果通过下划线标示。



表 3-4 超长程时间序列预测任务实验结果



Table 3-4 Ultra-long-range time series forecasting results.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">WITRAN(Ours)</td><td colspan="2">MICN</td><td colspan="2">TimesNet</td><td colspan="2">PatchTST</td><td colspan="2">DLinear</td><td colspan="2">FiLM</td><td colspan="2">FEDformer</td><td colspan="2">Pyraformer</td><td colspan="2">Autoformer</td><td colspan="2">Informer</td><td colspan="2">Transformer</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="3">ECL</td><td>720-1440</td><td>0.2499</td><td>0.3727</td><td>1.0460</td><td>0.7765</td><td>0.6119</td><td>0.5962</td><td>0.8243</td><td>0.6704</td><td>0.4923</td><td>0.5473</td><td>0.4730</td><td>0.5336</td><td>0.4833</td><td>0.5393</td><td>0.3250</td><td>0.4332</td><td>1.4957</td><td>0.9533</td><td>0.5064</td><td>0.5317</td><td>0.4030</td><td>0.4797</td></tr><tr><td>1440-1440</td><td>0.2408</td><td>0.3680</td><td>2.2862</td><td>1.2207</td><td>0.5720</td><td>0.5712</td><td>0.9053</td><td>0.7328</td><td>0.5146</td><td>0.5615</td><td>0.4849</td><td>0.5429</td><td>0.5142</td><td>0.5571</td><td>0.4895</td><td>0.5280</td><td>1.7873</td><td>1.0283</td><td>0.7247</td><td>0.6292</td><td>0.5531</td><td>0.5524</td></tr><tr><td>1440-2880</td><td>0.3359</td><td>0.4383</td><td>2.8936</td><td>1.3717</td><td>0.7683</td><td>0.6846</td><td>1.1282</td><td>0.8087</td><td>0.8355</td><td>0.7193</td><td>0.6847</td><td>0.6493</td><td>3.9018</td><td>1.5276</td><td>0.4320</td><td>0.5161</td><td>1.2867</td><td>0.8878</td><td>0.6152</td><td>0.5953</td><td>0.5243</td><td>0.5460</td></tr><tr><td rowspan="3">Traffic</td><td>720-1440</td><td>0.1672</td><td>0.2449</td><td>0.2876</td><td>0.3916</td><td>0.1882</td><td>0.2656</td><td>0.1904</td><td>0.2685</td><td>0.1639</td><td>0.2412</td><td>0.1638</td><td>0.2448</td><td>0.2753</td><td>0.3650</td><td>0.4463</td><td>0.4609</td><td>0.3104</td><td>0.4095</td><td>0.7614</td><td>0.6469</td><td>0.9876</td><td>0.7445</td></tr><tr><td>1440-1440</td><td>0.1543</td><td>0.2325</td><td>0.2950</td><td>0.3923</td><td>0.1598</td><td>0.2388</td><td>0.1817</td><td>0.2764</td><td>0.1599</td><td>0.2411</td><td>0.1602</td><td>0.2437</td><td>0.2848</td><td>0.3681</td><td>0.4710</td><td>0.4916</td><td>0.2970</td><td>0.3999</td><td>0.7375</td><td>0.6414</td><td>0.7430</td><td>0.6492</td></tr><tr><td>1440-2880</td><td>0.1425</td><td>0.2333</td><td>0.2823</td><td>0.3874</td><td>0.1560</td><td>0.2409</td><td>0.2029</td><td>0.3100</td><td>0.1550</td><td>0.2472</td><td>0.1744</td><td>0.2693</td><td>0.2952</td><td>0.3844</td><td>0.5165</td><td>0.5305</td><td>0.3035</td><td>0.3982</td><td>0.9849</td><td>0.7618</td><td>0.6000</td><td>0.5877</td></tr><tr><td rowspan="3">ETTh1</td><td>720-1440</td><td>0.1331</td><td>0.2943</td><td>0.4640</td><td>0.5836</td><td>0.1391</td><td>0.3049</td><td>0.3708</td><td>0.4906</td><td>0.2952</td><td>0.4370</td><td>0.2949</td><td>0.4388</td><td>0.1768</td><td>0.3409</td><td>0.1666</td><td>0.3315</td><td>0.3298</td><td>0.4741</td><td>0.1378</td><td>0.3051</td><td>0.1905</td><td>0.3555</td></tr><tr><td>1440-1440</td><td>0.1304</td><td>0.2902</td><td>0.5650</td><td>0.6293</td><td>0.1801</td><td>0.3372</td><td>0.4475</td><td>0.5329</td><td>0.2200</td><td>0.3714</td><td>0.2294</td><td>0.3759</td><td>0.3574</td><td>0.4878</td><td>0.3487</td><td>0.4866</td><td>0.4531</td><td>0.5507</td><td>0.1430</td><td>0.3156</td><td>0.1972</td><td>0.3630</td></tr><tr><td>1440-2880</td><td>0.1850</td><td>0.3452</td><td>0.7591</td><td>0.7215</td><td>0.2732</td><td>0.4094</td><td>0.9617</td><td>0.8271</td><td>0.3773</td><td>0.4794</td><td>0.6834</td><td>0.7096</td><td>0.4269</td><td>0.5252</td><td>0.5857</td><td>0.6760</td><td>1.3566</td><td>0.9235</td><td>0.3177</td><td>0.4733</td><td>0.3495</td><td>0.4911</td></tr><tr><td rowspan="3">ETTh2</td><td>720-1440</td><td>0.2915</td><td>0.4289</td><td>0.4922</td><td>0.5649</td><td>0.4186</td><td>0.5092</td><td>0.9401</td><td>0.7680</td><td>0.5037</td><td>0.5645</td><td>0.7166</td><td>0.6628</td><td>0.3731</td><td>0.4827</td><td>0.2952</td><td>0.4336</td><td>0.5633</td><td>0.5996</td><td>0.4025</td><td>0.4991</td><td>0.3712</td><td>0.4805</td></tr><tr><td>1440-1440</td><td>0.2815</td><td>0.4220</td><td>0.5030</td><td>0.5644</td><td>0.4409</td><td>0.5218</td><td>0.7860</td><td>0.6704</td><td>0.5176</td><td>0.5734</td><td>0.7446</td><td>0.6590</td><td>0.3906</td><td>0.4951</td><td>0.2946</td><td>0.4316</td><td>0.8029</td><td>0.7140</td><td>0.3484</td><td>0.4786</td><td>0.3797</td><td>0.4818</td></tr><tr><td>1440-2880</td><td>0.3280</td><td>0.4585</td><td>0.5549</td><td>0.5886</td><td>1.5304</td><td>0.9026</td><td>2.0561</td><td>1.1595</td><td>0.5053</td><td>0.5584</td><td>3.2835</td><td>1.6030</td><td>1.7167</td><td>0.9698</td><td>0.3345</td><td>0.4544</td><td>4.1031</td><td>1.7198</td><td>0.3335</td><td>0.4482</td><td>0.3737</td><td>0.4787</td></tr><tr><td rowspan="3">Weather</td><td>720-1440</td><td>0.1872</td><td>0.3312</td><td>0.3999</td><td>0.4848</td><td>0.2407</td><td>0.3694</td><td>0.5453</td><td>0.5631</td><td>0.4406</td><td>0.5264</td><td>0.6360</td><td>0.5997</td><td>0.2352</td><td>0.3733</td><td>0.6810</td><td>0.6352</td><td>0.8599</td><td>0.7064</td><td>0.2466</td><td>0.3849</td><td>0.2188</td><td>0.3512</td></tr><tr><td>1440-1440</td><td>0.1907</td><td>0.3366</td><td>0.2873</td><td>0.4201</td><td>0.2869</td><td>0.4033</td><td>0.5371</td><td>0.5559</td><td>0.3147</td><td>0.4417</td><td>0.6002</td><td>0.5880</td><td>0.2226</td><td>0.3609</td><td>0.2401</td><td>0.3777</td><td>0.9766</td><td>0.7739</td><td>0.2556</td><td>0.3969</td><td>0.2610</td><td>0.3823</td></tr><tr><td>1440-2880</td><td>0.1769</td><td>0.3257</td><td>0.3570</td><td>0.4810</td><td>0.2199</td><td>0.3563</td><td>0.9061</td><td>0.7220</td><td>0.3197</td><td>0.4533</td><td>1.2605</td><td>0.8805</td><td>0.2138</td><td>0.3599</td><td>0.1852</td><td>0.3332</td><td>1.7465</td><td>1.0962</td><td>0.2126</td><td>0.3600</td><td>0.1993</td><td>0.3436</td></tr></table>


* 表中较低的 MSE 或 MAE 表示更好的预测性能。每个任务上的最佳结果通过加粗标示，次优结果通过下划线标示。


![](images/601275173f8595030637b257a755c5082a9e7ffe9dff63f1b5a740681fb3ac4e.jpg)



(a) 显存占用情况（输入长度固定为720）


![](images/6b6e5dd6fbc44804a9162ea5bb41b02e1496030a6d5a0e5a624e9ea17193e262.jpg)



(b) 时间开销情况（输入长度固定为720）


![](images/93f0e6ce5f9742574ff3a00a6702ded13e161e239488a65fd765067a568ab51d.jpg)



(c) 显存占用情况（输出长度固定为 720）


![](images/365969685c56a50914d50e81802bfc93d730009cea97ef3f5f64c8dc39ec994c.jpg)



(d) 时间开销情况（输出长度固定为720）



图3-7 时间和显存消耗，WIT是不包含RAN的框架



Fig. 3-7 Time and memory consumption. WIT is the framework that does not involve the RAN.


# (1) 显存占用情况

从图3-7 (a) 可以观察到，在输入序列固定的情况下，WITRAN 与 WIT 的显存占用基本一致，因为二者采用相同的预测模块。同时，随着输出长度的增加，WITRAN 和 WIT 的内存消耗呈线性增长，但仍保持在最低水平。另一方面，从图3-7 (c) 可以看出，随着输入序列长度的增加，WITRAN 的内存使用增长极为缓慢，甚至低于 WIT。这一现象主要源于 WITRAN 无需在每个切片（Slice）的计算过程中存储大量中间变量，而 WIT 则需要存储整个序列的中间变量。此外，与其他方法相比，WITRAN 在显存开销方面的优势仍尤为明显。

# (2) 运行速度情况

如图3-7(b)和(d)所示，随着输入长度和输出长度的增加，WITRAN的训练速度显著优于其他方法。需要强调的是，在运行速度的验证性实验中，遵循了FiLM[99]中用于比较训练速度的实验设置。由于WITRAN的空间复杂度极低，为了充分利用GPU显存，WITRAN能够在上述参数设置下，将批量大小从8增加到32。同理，FiLM也能将批量大小设置为32。然而，WITRAN依然表现出最快的运行速度。由于RAN作用于输入序列上，WITRAN的运行速度随输入长度增加的变化规律可以在图3-7(d)中直接观察到，且呈平方根关系。通过与其他方法的比较，可以明显看出，WITRAN在运行速度方面具有显著优势。

# 3.3.5 模型分析及讨论

本小节主要针对WITRAN的消融实验、鲁棒性实验、参数敏感性分析以及案例分析四个方面展开，以全面评估WITRAN其他方面的性能和实际应用效果。

# (1) 消融实验

在本小节中，展示了WITRAN消融实验的结果，以验证WIT框架中各个组件的有效性。为此，本小节设计了五种变体方法，并在五个数据集上评估了它们的性能。实验结果如表3-5所示。需要特别指出的是，RAN的作用主要是提高计算效率，对模型的准确性影响不大。因此，本节的重点将聚焦于讨论WIT框架的设计与各个组件的作用上。


表 3-5 WITRAN 在长程和超长程时间序列预测任务上的消融实验结果



Table 3-5 Results of the ablation study on long-range and ultra-long-range forecasting tasks.


<table><tr><td colspan="2">方法</td><td colspan="2">WITRAN</td><td colspan="2">WITRAN-FC</td><td colspan="2">WITRAN-2DLSTM</td><td colspan="2">WITRAN-2DGRU</td><td colspan="2">WITRAN-LSTM</td><td colspan="2">WITRAN-GRU</td></tr><tr><td colspan="2">评价指标</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="8">ECL</td><td>168-168</td><td>0.2397</td><td>0.3519</td><td>0.3005</td><td>0.4029</td><td>0.2662</td><td>0.3736</td><td>0.2578</td><td>0.3677</td><td>0.2749</td><td>0.3800</td><td>0.2536</td><td>0.3640</td></tr><tr><td>168-336</td><td>0.2607</td><td>0.3721</td><td>0.3425</td><td>0.4355</td><td>0.3027</td><td>0.3996</td><td>0.2916</td><td>0.3924</td><td>0.3164</td><td>0.4087</td><td>0.2872</td><td>0.3863</td></tr><tr><td>336-336</td><td>0.2517</td><td>0.3627</td><td>0.3242</td><td>0.4232</td><td>0.2916</td><td>0.3896</td><td>0.2826</td><td>0.3851</td><td>0.3151</td><td>0.4066</td><td>0.2811</td><td>0.3805</td></tr><tr><td>336-720</td><td>0.3084</td><td>0.4055</td><td>0.3566</td><td>0.4523</td><td>0.3279</td><td>0.4262</td><td>0.3172</td><td>0.4187</td><td>0.3435</td><td>0.4350</td><td>0.3123</td><td>0.4153</td></tr><tr><td>720-720</td><td>0.2478</td><td>0.3651</td><td>0.4544</td><td>0.4972</td><td>0.3120</td><td>0.4184</td><td>0.2948</td><td>0.4060</td><td>0.3362</td><td>0.4325</td><td>0.2912</td><td>0.4009</td></tr><tr><td>720-1440</td><td>0.2499</td><td>0.3727</td><td>0.4732</td><td>0.5277</td><td>0.3426</td><td>0.4505</td><td>0.3337</td><td>0.4440</td><td>0.3517</td><td>0.4540</td><td>0.3296</td><td>0.4414</td></tr><tr><td>1440-1440</td><td>0.2408</td><td>0.3680</td><td>0.6433</td><td>0.6172</td><td>0.3954</td><td>0.4876</td><td>0.3822</td><td>0.4819</td><td>0.4164</td><td>0.5006</td><td>0.3864</td><td>0.4843</td></tr><tr><td>1440-2880</td><td>0.3359</td><td>0.4383</td><td>0.7406</td><td>0.6906</td><td>0.5936</td><td>0.6215</td><td>0.5680</td><td>0.6077</td><td>0.5583</td><td>0.6005</td><td>0.5859</td><td>0.6173</td></tr><tr><td rowspan="8">Traffic</td><td>168-168</td><td>0.1377</td><td>0.2051</td><td>0.1541</td><td>0.2382</td><td>0.1918</td><td>0.2811</td><td>0.1824</td><td>0.2699</td><td>0.2065</td><td>0.2935</td><td>0.1846</td><td>0.2666</td></tr><tr><td>168-336</td><td>0.1321</td><td>0.2059</td><td>0.1572</td><td>0.2503</td><td>0.2070</td><td>0.2975</td><td>0.1945</td><td>0.2837</td><td>0.2201</td><td>0.3058</td><td>0.2059</td><td>0.2887</td></tr><tr><td>336-336</td><td>0.1306</td><td>0.2054</td><td>0.1549</td><td>0.2455</td><td>0.1923</td><td>0.2846</td><td>0.1808</td><td>0.2732</td><td>0.2029</td><td>0.2935</td><td>0.1840</td><td>0.2715</td></tr><tr><td>336-720</td><td>0.1391</td><td>0.2175</td><td>0.1725</td><td>0.2611</td><td>0.2087</td><td>0.3000</td><td>0.2042</td><td>0.2958</td><td>0.2197</td><td>0.3080</td><td>0.2072</td><td>0.2940</td></tr><tr><td>720-720</td><td>0.1408</td><td>0.2191</td><td>0.1722</td><td>0.2622</td><td>0.2157</td><td>0.3048</td><td>0.2097</td><td>0.2997</td><td>0.2242</td><td>0.3123</td><td>0.2150</td><td>0.3023</td></tr><tr><td>720-1440</td><td>0.1672</td><td>0.2449</td><td>0.2178</td><td>0.2979</td><td>0.2404</td><td>0.3178</td><td>0.2450</td><td>0.3245</td><td>0.2586</td><td>0.3346</td><td>0.2501</td><td>0.3264</td></tr><tr><td>1440-1440</td><td>0.1543</td><td>0.2325</td><td>0.2150</td><td>0.2954</td><td>0.2343</td><td>0.3148</td><td>0.2340</td><td>0.3151</td><td>0.2406</td><td>0.3199</td><td>0.2469</td><td>0.3249</td></tr><tr><td>1440-2880</td><td>0.1425</td><td>0.2333</td><td>0.2072</td><td>0.3082</td><td>0.2060</td><td>0.3081</td><td>0.2134</td><td>0.3182</td><td>0.2113</td><td>0.3116</td><td>0.2129</td><td>0.3162</td></tr><tr><td rowspan="8">ETTh1</td><td>168-168</td><td>0.1105</td><td>0.2589</td><td>0.1143</td><td>0.2649</td><td>0.1132</td><td>0.2624</td><td>0.1120</td><td>0.2622</td><td>0.1141</td><td>0.2642</td><td>0.1141</td><td>0.2643</td></tr><tr><td>168-336</td><td>0.1189</td><td>0.2714</td><td>0.1211</td><td>0.2753</td><td>0.1160</td><td>0.2694</td><td>0.1172</td><td>0.2710</td><td>0.1191</td><td>0.2733</td><td>0.1173</td><td>0.2708</td></tr><tr><td>336-336</td><td>0.1112</td><td>0.2638</td><td>0.1167</td><td>0.2715</td><td>0.1125</td><td>0.2668</td><td>0.1125</td><td>0.2668</td><td>0.1147</td><td>0.2696</td><td>0.1138</td><td>0.2676</td></tr><tr><td>336-720</td><td>0.1494</td><td>0.3092</td><td>0.1347</td><td>0.2933</td><td>0.1317</td><td>0.2905</td><td>0.1314</td><td>0.2902</td><td>0.1310</td><td>0.2902</td><td>0.1317</td><td>0.2906</td></tr><tr><td>720-720</td><td>0.1296</td><td>0.2868</td><td>0.1515</td><td>0.3109</td><td>0.1438</td><td>0.3037</td><td>0.1436</td><td>0.3034</td><td>0.1450</td><td>0.3048</td><td>0.1513</td><td>0.3111</td></tr><tr><td>720-1440</td><td>0.1331</td><td>0.2943</td><td>0.1807</td><td>0.3378</td><td>0.1759</td><td>0.3361</td><td>0.1764</td><td>0.3375</td><td>0.1766</td><td>0.3361</td><td>0.1791</td><td>0.3391</td></tr><tr><td>1440-1440</td><td>0.1304</td><td>0.2902</td><td>0.2627</td><td>0.4096</td><td>0.1861</td><td>0.3439</td><td>0.2063</td><td>0.3616</td><td>0.1969</td><td>0.3562</td><td>0.2123</td><td>0.3656</td></tr><tr><td>1440-2880</td><td>0.1850</td><td>0.3452</td><td>0.2655</td><td>0.4134</td><td>0.2485</td><td>0.3998</td><td>0.2463</td><td>0.3925</td><td>0.2444</td><td>0.3923</td><td>0.2486</td><td>0.3962</td></tr><tr><td rowspan="8">ETTh2</td><td>168-168</td><td>0.2389</td><td>0.3813</td><td>0.2507</td><td>0.3859</td><td>0.2577</td><td>0.4012</td><td>0.2567</td><td>0.3998</td><td>0.2593</td><td>0.4013</td><td>0.2556</td><td>0.3980</td></tr><tr><td>168-336</td><td>0.2277</td><td>0.3778</td><td>0.2377</td><td>0.3896</td><td>0.2791</td><td>0.4193</td><td>0.2791</td><td>0.4193</td><td>0.2818</td><td>0.4211</td><td>0.2690</td><td>0.4108</td></tr><tr><td>336-336</td><td>0.2432</td><td>0.3922</td><td>0.2928</td><td>0.4273</td><td>0.2614</td><td>0.4085</td><td>0.2621</td><td>0.4084</td><td>0.2680</td><td>0.4130</td><td>0.2604</td><td>0.4058</td></tr><tr><td>336-720</td><td>0.2373</td><td>0.3888</td><td>0.2948</td><td>0.4355</td><td>0.3051</td><td>0.4434</td><td>0.2815</td><td>0.4253</td><td>0.3113</td><td>0.4458</td><td>0.2798</td><td>0.4239</td></tr><tr><td>720-720</td><td>0.2635</td><td>0.4018</td><td>0.3243</td><td>0.4548</td><td>0.2990</td><td>0.4369</td><td>0.2848</td><td>0.4283</td><td>0.3096</td><td>0.4428</td><td>0.2832</td><td>0.4262</td></tr><tr><td>720-1440</td><td>0.2915</td><td>0.4289</td><td>0.3212</td><td>0.4598</td><td>0.3308</td><td>0.4659</td><td>0.3396</td><td>0.4723</td><td>0.3241</td><td>0.4617</td><td>0.3446</td><td>0.4759</td></tr><tr><td>1440-1440</td><td>0.2815</td><td>0.4220</td><td>0.4162</td><td>0.5145</td><td>0.3950</td><td>0.4962</td><td>0.4214</td><td>0.5144</td><td>0.4199</td><td>0.5132</td><td>0.4243</td><td>0.5193</td></tr><tr><td>1440-2880</td><td>0.3280</td><td>0.4585</td><td>0.5532</td><td>0.5959</td><td>0.6846</td><td>0.6639</td><td>0.6554</td><td>0.6530</td><td>0.6581</td><td>0.6531</td><td>0.7473</td><td>0.7006</td></tr><tr><td rowspan="8">Weather</td><td>168-168</td><td>0.2050</td><td>0.3338</td><td>0.2066</td><td>0.3324</td><td>0.2180</td><td>0.3419</td><td>0.2199</td><td>0.3437</td><td>0.2194</td><td>0.3435</td><td>0.2211</td><td>0.3462</td></tr><tr><td>168-336</td><td>0.2197</td><td>0.3470</td><td>0.2200</td><td>0.3585</td><td>0.2580</td><td>0.3789</td><td>0.2723</td><td>0.3871</td><td>0.2596</td><td>0.3794</td><td>0.2668</td><td>0.3843</td></tr><tr><td>336-336</td><td>0.2163</td><td>0.3482</td><td>0.2259</td><td>0.3586</td><td>0.2472</td><td>0.3730</td><td>0.2613</td><td>0.3816</td><td>0.2462</td><td>0.3726</td><td>0.2501</td><td>0.3732</td></tr><tr><td>336-720</td><td>0.2054</td><td>0.3424</td><td>0.2125</td><td>0.3497</td><td>0.2497</td><td>0.3840</td><td>0.2775</td><td>0.4004</td><td>0.2473</td><td>0.3796</td><td>0.2859</td><td>0.4099</td></tr><tr><td>720-720</td><td>0.2008</td><td>0.3417</td><td>0.2104</td><td>0.3458</td><td>0.2564</td><td>0.3843</td><td>0.2861</td><td>0.4030</td><td>0.2633</td><td>0.3873</td><td>0.2772</td><td>0.3990</td></tr><tr><td>720-1440</td><td>0.1872</td><td>0.3312</td><td>0.1984</td><td>0.3397</td><td>0.2301</td><td>0.3676</td><td>0.2853</td><td>0.4156</td><td>0.2376</td><td>0.3751</td><td>0.2737</td><td>0.4063</td></tr><tr><td>1440-1440</td><td>0.1907</td><td>0.3366</td><td>0.2084</td><td>0.3507</td><td>0.2419</td><td>0.3832</td><td>0.2671</td><td>0.4070</td><td>0.2454</td><td>0.3847</td><td>0.2631</td><td>0.4013</td></tr><tr><td>1440-2880</td><td>0.1769</td><td>0.3257</td><td>0.2148</td><td>0.3570</td><td>0.2308</td><td>0.3735</td><td>0.2460</td><td>0.3887</td><td>0.2317</td><td>0.3736</td><td>0.2305</td><td>0.3751</td></tr></table>


* 表中较低的 MSE 或 MAE 表示更好的预测性能。每个任务上的最佳结果通过加粗标示。


由于预测模块是模型设计的重要组成部分，旨在有效地将WIT框架从长期和短期尺度上捕获到的周期性和趋势性模式特征映射到预测序列的各个点上。为了验证WITRAN的预测模块是否能够通过组合对应位置特征表示的操作，充分利用相关信息进行有效预测，本小节将WITRAN中原有预测模块的组合对应位置特征表示的过程进行简化，即首先将水平隐藏状态和垂直隐藏状态拼合，然后使用全连接层直接预测，该变体被命名为WITRAN-FC。

表3-5中对比了WITRAN和WITRAN-FC的结果，虽然这两种方法使用了相同的信息，但结果表明WITRAN-FC仍难以识别每个预测点最相关的周期性信息。这进一步证明了WITRAN预测模块中对应位置特征表示组合的有效性。

由于信息的选择和融合操作是在所设计的门控选择单元（GSC）中一起完成的，因此需要验证其有效性。为此，本节将HVGSU中两个方向上的单元分别替换为LSTM和GRU，并将其命名为WITRAN-2DLSTM和WITRAN-2DGRU。需要注意的是，在这种情况下，两个方向上的LSTM/GRU单元之间的信息未进行融合，因此HVGSU水平方向最后一行的信息无法包含全局信息，故不能使用WITRAN原有的预测模块，而只能使用上文中提到的全连接（FC）方法进行预测。需要特别指出的是，WITRAN-2DLSTM/WITRAN-2DGRU与WITRAN-FC的比较反映了信息冗余对实验性能的影响，而WITRAN-2DLSTM/WITRAN-2DGRU与WITRAN的比较则反映了信息选择与融合对实验性能的影响。

表3-5中WITRAN-2DLSTM/WITRAN-2DGRU与WITRAN-FC的结果对比表明，过多的信息冗余可能对模型的预测性能产生负面影响。对于WITRAN-FC来说，接收到的水平隐藏状态包含的信息越多，越往下的信息越丰富，同时还包含其上方水平方向的所有信息，垂直方向也是如此，隐藏状态越往右，包含的信息越多。此外，WITRAN-2DLSTM和WITRAN-2DGRU捕获到的信息在不同水平行和垂直列之间是独立的，水平隐藏状态和垂直隐藏状态之间的语义信息也不同。因此，WITRAN-2DLSTM和WITRAN-2DGRU不受信息冗余带来的负面影响。与此同时，WITRAN与WITRAN-2DLSTM/WITRAN-2DGRU的结果对比表明，信息选择与融合设计能够有效提取相关信息，进一步证明了WIT框架中GSC设计的必要性。

在WITRAN的设计中，信息可以沿两个方向传递，并且由于这两个方向上序列传递信息的时间粒度不同，它们分别捕获到的尺度信息也不同。为了验证HVGSU中设置的两个独立GSC能够有效捕获周期内和周期间的语义信息，本小节将WITRAN-2DLSTM/WITRAN-2DGRU两个方向上的单元替换为单个LSTM/GRU单元，并统一使用一个隐藏状态信息在两个方向上传递信息。此时，模型在水平和垂直方向上传播的信息完全相同，该模型被命名为WITRAN-LSTM/WITRAN-

GRU。

表3-5中WITRAN-2DLSTM/WITRAN-2DGRU与WITRAN-LSTM/WITRAN-GRU的结果对比表明，未能区分长期周期性和短期趋势性模式信息会显著影响预测任务的性能，产生负面效果。

总结以上分析过程，可以证明WIT中每个模块设计的重要性。通过逐步移除WIT中的各个模块，实验结果表明性能出现了显著下降，充分证明了WIT框架的合理性和有效性。具体来说，对WIT的消融实验结论总结如下：（I）GSC的选择和融合设计使得每个历史输入数据点的周期性和趋势性都能够被有效捕获。（II）在两个方向上设置独立的单元，能够分别从长期和短期两个尺度上，提取周期性和趋势性模式信息。（III）特别设计的对应位置特征表示组合操作能够更充分地利用捕获到的局部和全局模式信息，同时确保信息不冗余。

# (2）鲁棒性实验

本小节遵循了MICN[26]的方法，引入了简单的白噪声来验证所提出模型的鲁棒性。具体来说，首先从原始输入序列中随机选择比例为  $\varepsilon$  的数据，并对选中的数据施加随机扰动，扰动范围在  $[-2\pmb{x}_i, 2\pmb{x}_i]$ ，其中  $\pmb{x}_i$  表示原始数据。随后，使用注入噪声的数据进行模型训练，结果如表3-6所示。

可以发现，随着扰动比例的增加，预测的MSE和MAE指标略有上升。这表明WITRAN在处理噪声较少的数据（最高  $10\%$  ）时表现出良好的鲁棒性，并且在有效应对各种异常数据波动方面具有显著优势。

# (3) 参数敏感性分析

本小节将分析WITRAN的参数敏感性，重点讨论模型中的独有的参数设置及其对预测性能的影响。norm参数的设置范围为  $\{0,1\}$ ，用于确定数据是否需要归一化。 $P$  表示周期值大小，其取值范围为  $\{12,24,48\}$ ，并且要求输入序列长度  $T$  能被  $P$  整除。本节将详细说明这些参数的选择及其对模型预测结果的影响。

对于不同数据集上的不同预测任务，WITRAN通过验证集确定了norm的值。为了验证norm的值是否符合数据集的分布，本节对不同预测任务的训练集和验证集的分布进行了实验，结果和norm的值如表3-7所示。可以注意到，尽管训练集和验证集的数据均值可能存在显著差异，但当它们的方差没有显著差异时，表明两组数据波动相似。在这种情况下，数据分布的差异并不显著，选择norm为0是合理的。然而，当训练集和验证集的方差差异较大（大约为两倍或一半）时，两组数据分布存在显著差异，此时应将norm设置为1，以重新归一化模型的输入。需要注意的是，在Weather数据集中存在负值，导致其均值接近0，使得其方差与均值之间的差异较大，这在数据处理中合理的。而对于Traffic数据集，由于没有负值，即使其训练集和验证集的方差相似，结合其均值也可以看到其显著波动。在模型


表 3-6 鲁棒性实验结果



Table 3-6 Robustness experiment results.


<table><tr><td rowspan="2" colspan="2">预测任务 评价指标</td><td colspan="2">168-168</td><td colspan="2">168-336</td><td colspan="2">336-336</td><td colspan="2">336-720</td><td colspan="2">720-720</td><td colspan="2">720-1440</td><td colspan="2">1440-1440</td><td colspan="2">1440-2880</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>ε=0%</td><td>0.2397</td><td>0.3519</td><td>0.2607</td><td>0.3721</td><td>0.2517</td><td>0.3627</td><td>0.3084</td><td>0.4055</td><td>0.2478</td><td>0.3651</td><td>0.2499</td><td>0.3727</td><td>0.2408</td><td>0.3680</td><td>0.3359</td><td>0.4383</td></tr><tr><td>ε=1%</td><td>0.2420</td><td>0.3534</td><td>0.2630</td><td>0.3738</td><td>0.2516</td><td>0.3626</td><td>0.3078</td><td>0.4060</td><td>0.2345</td><td>0.3960</td><td>0.2502</td><td>0.3739</td><td>0.2395</td><td>0.3672</td><td>0.3372</td><td>0.4476</td></tr><tr><td>ε=5%</td><td>0.2463</td><td>0.3573</td><td>0.2692</td><td>0.3788</td><td>0.2567</td><td>0.3652</td><td>0.3039</td><td>0.4046</td><td>0.2525</td><td>0.3703</td><td>0.2565</td><td>0.3786</td><td>0.2410</td><td>0.3687</td><td>0.3315</td><td>0.4408</td></tr><tr><td>ε=10%</td><td>0.2543</td><td>0.3621</td><td>0.2726</td><td>0.3811</td><td>0.2702</td><td>0.3736</td><td>0.3098</td><td>0.4061</td><td>0.2569</td><td>0.3756</td><td>0.2674</td><td>0.3880</td><td>0.2444</td><td>0.3716</td><td>0.3366</td><td>0.4445</td></tr><tr><td rowspan="4">Traffic</td><td>ε=0%</td><td>0.1377</td><td>0.2051</td><td>0.1321</td><td>0.2059</td><td>0.1306</td><td>0.2054</td><td>0.1391</td><td>0.2175</td><td>0.1408</td><td>0.2191</td><td>0.1672</td><td>0.2449</td><td>0.1543</td><td>0.2325</td><td>0.1425</td><td>0.2333</td></tr><tr><td>ε=1%</td><td>0.1376</td><td>0.2063</td><td>0.1329</td><td>0.2083</td><td>0.1316</td><td>0.2074</td><td>0.1423</td><td>0.2218</td><td>0.1409</td><td>0.2218</td><td>0.1676</td><td>0.2466</td><td>0.1551</td><td>0.2372</td><td>0.1436</td><td>0.2360</td></tr><tr><td>ε=5%</td><td>0.1370</td><td>0.2115</td><td>0.1362</td><td>0.2148</td><td>0.1323</td><td>0.2106</td><td>0.1432</td><td>0.2260</td><td>0.1416</td><td>0.2247</td><td>0.1699</td><td>0.2519</td><td>0.1572</td><td>0.2373</td><td>0.1519</td><td>0.2480</td></tr><tr><td>ε=10%</td><td>0.1409</td><td>0.2164</td><td>0.1355</td><td>0.2193</td><td>0.1372</td><td>0.2200</td><td>0.1467</td><td>0.2325</td><td>0.1450</td><td>0.2291</td><td>0.1652</td><td>0.2475</td><td>0.1561</td><td>0.2383</td><td>0.1575</td><td>0.2580</td></tr><tr><td rowspan="4">ETTh1</td><td>ε=0%</td><td>0.1105</td><td>0.2589</td><td>0.1189</td><td>0.2714</td><td>0.1112</td><td>0.2638</td><td>0.1494</td><td>0.3092</td><td>0.1296</td><td>0.2868</td><td>0.1331</td><td>0.2943</td><td>0.1304</td><td>0.2902</td><td>0.1850</td><td>0.3452</td></tr><tr><td>ε=1%</td><td>0.1112</td><td>0.2596</td><td>0.1208</td><td>0.2726</td><td>0.1111</td><td>0.2637</td><td>0.1463</td><td>0.3035</td><td>0.1304</td><td>0.2885</td><td>0.1367</td><td>0.2978</td><td>0.1319</td><td>0.2907</td><td>0.1834</td><td>0.3484</td></tr><tr><td>ε=5%</td><td>0.1135</td><td>0.2622</td><td>0.1221</td><td>0.2751</td><td>0.1199</td><td>0.2689</td><td>0.1527</td><td>0.3124</td><td>0.1304</td><td>0.2888</td><td>0.1336</td><td>0.2952</td><td>0.1359</td><td>0.2955</td><td>0.1801</td><td>0.3435</td></tr><tr><td>ε=10%</td><td>0.1137</td><td>0.2628</td><td>0.1227</td><td>0.2757</td><td>0.1196</td><td>0.2688</td><td>0.1559</td><td>0.3148</td><td>0.1358</td><td>0.2952</td><td>0.1374</td><td>0.2994</td><td>0.1405</td><td>0.3015</td><td>0.1842</td><td>0.3479</td></tr><tr><td rowspan="4">ETTh2</td><td>ε=0%</td><td>0.2389</td><td>0.3813</td><td>0.2277</td><td>0.3778</td><td>0.2432</td><td>0.3922</td><td>0.2373</td><td>0.3888</td><td>0.2635</td><td>0.4018</td><td>0.2915</td><td>0.4289</td><td>0.2815</td><td>0.4220</td><td>0.3280</td><td>0.4585</td></tr><tr><td>ε=1%</td><td>0.2535</td><td>0.3904</td><td>0.2284</td><td>0.3777</td><td>0.2459</td><td>0.3942</td><td>0.2390</td><td>0.3902</td><td>0.2629</td><td>0.3902</td><td>0.3049</td><td>0.4358</td><td>0.2936</td><td>0.4297</td><td>0.3353</td><td>0.4642</td></tr><tr><td>ε=5%</td><td>0.2364</td><td>0.3799</td><td>0.2379</td><td>0.3834</td><td>0.2563</td><td>0.4025</td><td>0.2501</td><td>0.3967</td><td>0.2661</td><td>0.4056</td><td>0.3207</td><td>0.4482</td><td>0.2935</td><td>0.4308</td><td>0.3307</td><td>0.4603</td></tr><tr><td>ε=10%</td><td>0.2603</td><td>0.3959</td><td>0.2475</td><td>0.3902</td><td>0.2613</td><td>0.4054</td><td>0.2581</td><td>0.4022</td><td>0.2674</td><td>0.4053</td><td>0.3193</td><td>0.4481</td><td>0.2847</td><td>0.4237</td><td>0.3317</td><td>0.4612</td></tr><tr><td rowspan="4">Weather</td><td>ε=0%</td><td>0.2050</td><td>0.3338</td><td>0.2197</td><td>0.3470</td><td>0.2163</td><td>0.3482</td><td>0.2054</td><td>0.3424</td><td>0.2008</td><td>0.3417</td><td>0.1872</td><td>0.3312</td><td>0.1907</td><td>0.3366</td><td>0.1769</td><td>0.3257</td></tr><tr><td>ε=1%</td><td>0.2050</td><td>0.3343</td><td>0.2154</td><td>0.3470</td><td>0.2214</td><td>0.3522</td><td>0.2055</td><td>0.3419</td><td>0.2005</td><td>0.3419</td><td>0.1872</td><td>0.3313</td><td>0.1903</td><td>0.3361</td><td>0.1828</td><td>0.3327</td></tr><tr><td>ε=5%</td><td>0.2057</td><td>0.3362</td><td>0.2241</td><td>0.3517</td><td>0.2268</td><td>0.3557</td><td>0.2058</td><td>0.3426</td><td>0.2008</td><td>0.3421</td><td>0.1867</td><td>0.3305</td><td>0.1897</td><td>0.3353</td><td>0.1831</td><td>0.3357</td></tr><tr><td>ε=10%</td><td>0.2059</td><td>0.3369</td><td>0.2220</td><td>0.3484</td><td>0.2308</td><td>0.3595</td><td>0.2059</td><td>0.3438</td><td>0.2007</td><td>0.3418</td><td>0.1854</td><td>0.3290</td><td>0.1900</td><td>0.3370</td><td>0.1828</td><td>0.3336</td></tr></table>


* 不同的  $\varepsilon$  表示不同的噪音注入比例。



表 3-7 训练和验证集的数据分布（均值和标准差）和 norm 值



Table 3-7 The distribution of data in the training and validation sets (Mean and STD) and the value of norm.


<table><tr><td rowspan="2">数据集
预测任务</td><td colspan="3">ECL</td><td colspan="3">Traffic</td><td colspan="3">ETTh1</td></tr><tr><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td></tr><tr><td>168-168</td><td>3425.733±564.8776</td><td>3036.397±388.2128</td><td></td><td>0.029±0.0170</td><td>0.034±0.0201</td><td></td><td>16.880±8.2921</td><td>6.667±4.1794</td><td></td></tr><tr><td>168-336</td><td>3427.480±566.9556</td><td>3036.291±388.0110</td><td></td><td>0.029±0.0170</td><td>0.035±0.0202</td><td></td><td>16.606±8.0735</td><td>6.258±3.8462</td><td></td></tr><tr><td>336-336</td><td>3428.455±569.1108</td><td>3036.291±388.0110</td><td>0</td><td>0.029±0.0170</td><td>0.035±0.0202</td><td>1</td><td>16.207±7.5364</td><td>6.258±3.8462</td><td>1</td></tr><tr><td>336-720</td><td>3434.150±573.2660</td><td>3037.919±387.2758</td><td></td><td>0.029±0.0170</td><td>0.035±0.0203</td><td></td><td>15.446±6.6217</td><td>5.583±3.4658</td><td></td></tr><tr><td>720-720</td><td>3437.773±578.4705</td><td>3037.919±387.2758</td><td></td><td>0.029±0.0170</td><td>0.035±0.0203</td><td></td><td>14.832±5.9927</td><td>5.583±3.4658</td><td></td></tr><tr><td>720-1440</td><td>3439.817±586.5029</td><td>3046.877±397.7761</td><td></td><td>0.029±0.0170</td><td>0.035±0.0204</td><td></td><td>14.044±5.5077</td><td>4.273±2.7600</td><td></td></tr><tr><td>1440-1440</td><td>3452.135±594.6857</td><td>3046.877±397.7761</td><td>0</td><td>0.029±0.0169</td><td>0.035±0.0204</td><td>1</td><td>13.722±5.5456</td><td>4.273±2.7600</td><td>1</td></tr><tr><td>1440-2880</td><td>3458.328±610.2118</td><td>3093.128±446.4128</td><td></td><td>0.029±0.0171</td><td>0.036±0.0208</td><td></td><td>14.195±5.5780</td><td>2.623±2.5005</td><td></td></tr></table>

<table><tr><td rowspan="2">数据集
预测任务</td><td colspan="3">ETTh₂</td><td colspan="3">Weather</td></tr><tr><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td></tr><tr><td>168-168</td><td>28.959±12.0653</td><td>18.680±9.0427</td><td></td><td>0.500±6.6321</td><td>1.143±7.7659</td><td></td></tr><tr><td>168-336</td><td>28.767±12.0604</td><td>17.922±8.5800</td><td></td><td>0.536±6.6444</td><td>1.017±7.8162</td><td></td></tr><tr><td>336-336</td><td>28.434±11.8740</td><td>17.922±8.5800</td><td>0</td><td>0.585±6.6409</td><td>1.017±7.8162</td><td>0</td></tr><tr><td>336-720</td><td>27.774±11.6120</td><td>16.360±7.7594</td><td></td><td>0.700±6.6410</td><td>0.721±7.9234</td><td></td></tr><tr><td>720-720</td><td>27.111±11.3299</td><td>16.360±7.7594</td><td></td><td>0.825±6.6270</td><td>0.721±7.9234</td><td></td></tr><tr><td>720-1440</td><td>26.403±11.4257</td><td>13.646±6.5725</td><td></td><td>0.978±6.6791</td><td>-0.547±7.5174</td><td></td></tr><tr><td>1440-1440</td><td>26.355±11.8918</td><td>13.646±6.5725</td><td>1</td><td>1.029±6.7679</td><td>-0.547±7.5174</td><td>0</td></tr><tr><td>1440-2880</td><td>28.303±12.1275</td><td>9.130±5.5363</td><td></td><td>0.725±6.8812</td><td>-3.859±5.5129</td><td></td></tr></table>


表 3-8 在 ECL 和 Traffic 数据集上  $C$  的参数敏感性



Table 3-8 Parameter Sensitivity of  $C$  on ECL and Traffic datasets.


<table><tr><td colspan="2">C的设置</td><td colspan="2">12</td><td colspan="2">24</td><td colspan="2">48</td></tr><tr><td>数据集</td><td>预测任务</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="8">ECL</td><td>168-168</td><td>0.2461</td><td>0.3648</td><td>0.2397</td><td>0.3519</td><td>-</td><td>-</td></tr><tr><td>168-336</td><td>0.3166</td><td>0.4230</td><td>0.2607</td><td>0.3721</td><td>-</td><td>-</td></tr><tr><td>336-336</td><td>0.3217</td><td>0.4099</td><td>0.2517</td><td>0.3627</td><td>0.2634</td><td>0.3847</td></tr><tr><td>336-720</td><td>0.3397</td><td>0.4310</td><td>0.3084</td><td>0.4055</td><td>0.3233</td><td>0.4130</td></tr><tr><td>720-720</td><td>0.2802</td><td>0.3951</td><td>0.2478</td><td>0.3651</td><td>0.3175</td><td>0.4063</td></tr><tr><td>720-1440</td><td>0.2907</td><td>0.4051</td><td>0.2499</td><td>0.3727</td><td>0.2985</td><td>0.3946</td></tr><tr><td>1440-1440</td><td>0.3007</td><td>0.4110</td><td>0.2408</td><td>0.3680</td><td>0.2748</td><td>0.3768</td></tr><tr><td>1440-2880</td><td>0.4301</td><td>0.5150</td><td>0.3359</td><td>0.4383</td><td>0.3464</td><td>0.4347</td></tr><tr><td rowspan="8">Traffic</td><td>168-168</td><td>0.1598</td><td>0.2408</td><td>0.1377</td><td>0.2051</td><td>-</td><td>-</td></tr><tr><td>168-336</td><td>0.2272</td><td>0.2783</td><td>0.1321</td><td>0.2059</td><td>-</td><td>-</td></tr><tr><td>336-336</td><td>0.2131</td><td>0.2967</td><td>0.1306</td><td>0.2054</td><td>0.1412</td><td>0.2278</td></tr><tr><td>336-720</td><td>0.2022</td><td>0.2804</td><td>0.1391</td><td>0.2175</td><td>0.1510</td><td>0.2371</td></tr><tr><td>720-720</td><td>0.2028</td><td>0.2846</td><td>0.1408</td><td>0.2191</td><td>0.1505</td><td>0.2326</td></tr><tr><td>720-1440</td><td>0.2710</td><td>0.3311</td><td>0.1672</td><td>0.2449</td><td>0.1813</td><td>0.2605</td></tr><tr><td>1440-1440</td><td>0.2676</td><td>0.3301</td><td>0.1543</td><td>0.2325</td><td>0.1881</td><td>0.2652</td></tr><tr><td>1440-2880</td><td>0.2407</td><td>0.3443</td><td>0.1425</td><td>0.2333</td><td>0.1692</td><td>0.2765</td></tr></table>

训练过程中将norm值设置为1时，这一点也得到了验证。

模型对  $p$  的选择代表了对序列周期的确定。由于每个数据集的原始采集粒度不同，为了确保它们在相同任务上包含相同的语义信息，在本节中的实验通过将它们聚合为一小时来进行。为了便于发现序列中的长期重复模式，本节将  $p$  设置为12,24,48，具体实验结果如表3-8所示。

从表3-8中可以清楚地看到，对于时间步长为小时的序列，使用24小时（1天）作为周期进行划分会得到更好的结果。这是因为在WIT中，信息在水平方向上以小时为粒度传递，而在垂直方向上以天为粒度传递。这种方法能够更充分地捕获时间序列数据中隐藏的多方面复杂的时间模式信息。

# (4) 案例分析

本小节展示了WITRAN在部分测试数据的预测结果，并进行了对比分析，具体见图3-8至图3-13。对于长程预测任务，本节选择了FiLM和Pyraformer作为次优模型；对于超长程预测任务，则选择了Pyraformer和TimesNet。实验结果表明，WITRAN在所有模型中表现最佳。在长程时间序列预测任务中，WITRAN模型展现出了卓越的性能，能够更全面地捕获时间序列中的趋势性、周期性、长期性、短期性、局部性和全局性特征。具体分析如下：

![](images/61eaa05056ee98182cb5f84dd1e8820349d85f8ec9cd3a09f8543948f05ff410.jpg)


![](images/e1779b91048b8d209f62a0e12408b809eb3254d2f6f5931b0537789bb9a9129c.jpg)


![](images/265ca8c24d3c1ec49d4fadc079e806088b647c58b8afa8f7cdcef74b9eb15df1.jpg)



图3-8 在数据集ECL中的168-336任务预测案例



Fig 3-8 Forecasting cases for 168-336 tasks in dataset ECL.


首先，在ECL数据集上的长程预测任务中，如图3-8所示，与其他方法相比，WITRAN在多方面表现出显著优势。相比于FiLM方法，WITRAN能够更精确地捕

![](images/237cd96cadc9700ee615f261ee55eef030cc927ffb546e4661bdf6cc70ea3545.jpg)


![](images/c2bbfcd9efaa31d3cb9f0b92c73ef2b3c99ba8c53122abb6dd3ee95f4818327e.jpg)


![](images/9d3586f7d0d3e76685426e9e3d6b05cf756d4e6a82014099f8eb9f3fc7d000f4.jpg)



图3-9 在数据集ECL中的720-720任务预测案例



Fig 3-9 Forecasting cases for 720-720 tasks in dataset ECL.


![](images/132a49f05225a9c4f6b41fc0b9e9a8cfc1f35b9a0ee8167be633cbc6aaeea2be.jpg)


![](images/f8643de73ab4da000f4f5125f9f8957fdb068856cf4ab8399c37ef4f8a8bf577.jpg)


![](images/4f804ffdeb474eb0598a3767d9d692b697db93256552bb07b35d2bb838ea53c1.jpg)



图3-10 在数据集ECL中的1440-2880任务预测案例



Fig 3-10 Forecasting cases for 1440-2880 tasks in dataset ECL.


获时间序列中的趋势性，尤其在峰值预测方面更加准确；相比于Pyraformer方法，

WITRAN在周期性特征的捕获和预测值变化规律的拟合上更具优势。如图3-9所示，WITRAN模型在较长时间尺度上对时间序列的拟合能力优于FiLM和Pyraformer，能够更好地预测未来的变化趋势。

其次，在超长程预测任务中，WITRAN同样表现优异。如图3-10所示，在ECL数据集上，WITRAN模型的预测值与真实值的重叠面积最大，显著优于Pyraformer和TimesNet，全面捕获了时间序列的趋势性、周期性以及全局性特征。

![](images/e7798b341061fbee7a148e450d4e840bdd03cf078967a44ce528ebb14428759f.jpg)


![](images/d5b35b9ac22c8106300594b2abc35b38b98d439db897ee28a20f3e712f013ca9.jpg)


![](images/71c8fddc7b47b2c270480483b8d24192e48a733620ec88b9685d32ea6048126d.jpg)



图3-11 在数据集  $\mathrm{ETTh}_1$  中的168-336任务预测案例



Fig 3-11 Forecasting cases for 168-336 tasks in dataset ETTh1.


进一步地，在  $ETTh_{1}$  数据集上的长程预测任务中，WITRAN模型依然展现出明显优势。如图3-11所示，在168-336步长预测任务中，WITRAN的预测值变化规律与真实值更为贴近，拟合效果显著优于其他方法，能够准确捕获时间序列的全局性、局部性、长期性、短期性、周期性和趋势性。如图3-12所示，在336-720步长任务中，WITRAN模型相较于FiLM和Pyraformer方法，周期性和趋势性特征的捕获更为准确。同时，FiLM方法存在预测值整体偏低的现象，而Pyraformer方法预测值整体偏高。

最后，在超长程预测任务中，WITRAN 的表现更加突出。如图3-13所示，在1440-2880步长预测任务中，WITRAN 模型的预测值与真实值在变化规律上保持高度一致，能够很好地捕获时间序列的全局性、周期性和长期性。相比之下，Pyraformer方法的预测值偏离真实值严重，而TimesNet 方法虽然捕获到一定的变化规律，但在关键变化点上仍存在较大偏差，未能充分捕获时间序列的周期性、长期性和全

局性。

![](images/41db5e1b1c6312d6fbf58a70decac8e3c3cbaf3ce798ba849eb36f19d7e6679c.jpg)



图3-12 在数据集  $\mathrm{ETTh}_1$  中的720-720任务预测案例



Fig 3-12 Forecasting cases for 720-720 tasks in dataset  $\mathrm{ETTh}_1$ .


![](images/405e96bd669613b49fbfa78850098dfd44989d3d93c0d8b2147a180bdf14cc77.jpg)



图3-13 在数据集  $\mathrm{ETTh}_1$  中的1440-2880任务预测案例



Fig 3-13 Forecasting cases for 1440-2880 tasks in dataset  $\mathrm{ETTh}_1$ .


综合来看，WITRAN模型在多种长程和超长程时间序列预测任务中均优于现有的主流方法，这充分验证了其在捕获多种时间序列特征方面的优越性，为复杂时间序列预测问题提供了一个强有力的解决方案。

# 3.4 本章小结

本章提出了WITRAN，一种新颖的水波信息传递框架和通用加速框架，以解决长程时间序列预测中充分捕获复杂时间模式信息的挑战，包括长期性与短期性、周期性与趋势性、全局性与局部性模式的有效提取，同时兼顾模型的运行效率和计算资源消耗。具体来说，WITRAN通过构建双粒度门控选择单元（HVGSU），实现了对不同时间尺度特性的精确建模，并结合循环加速网络（RAN），显著提升了模型的计算效率，使其达到  $\mathcal{O}(\sqrt{T})$  的复杂度和  $\mathcal{O}(T)$  的空间复杂度，在确保捕获关键模式的基础上降低了计算成本。实验结果验证了WITRAN在多种长程时间序列预测任务中均展现出卓越的性能和效率。然而，由于切片之间的信息等待，该循环结构在基于Python的实现中仍存在一定的效率瓶颈，未来的工作可以考虑将WITRAN集成到基于C++的高性能接口中，类似于PyTorch中nn.GRU/nn.LSTM的实现，从而进一步提升其运行效率，并探索更优的并行处理机制，以减少信息传递过程中的计算等待等问题。

# 4 并行门控机制的长程时间序列预测方法

第三章主要探讨了水波型信息传递框架在捕获复杂时间模式（趋势性模式、周期性模式、长期模式、短期模式、局部模式和全局模式）信息的有效性。然而，在捕获上述复杂信息的同时，减少信息传递过程中的损失至关重要，二者相辅相成，共同决定了模型对信息的利用能力。

为减少信息传递过程中的损失，本章提出了一种全新的范式——并行门控网络（Parallel Gated Network, PGN）。PGN采用线性层对每个时间步并行地捕获其完整的历史信息，随后通过专门设计的门控机制进行信息的选择与融合，实现了O(1)复杂度的信息传递路径。

此外，为同时捕获复杂的时间模式信息，将 PGN 更好地应用于长程时间序列预测任务，本章还提出了时间并行门控网络（Temporal Parallel Gated Network, TPGN）。TPGN 采用双分支架构，以分别地对不同时间特性进行建模，实现信息的全面捕获。通过在五个真实场景下的基准数据集上展开实验，验证了 TPGN 在预测性能和运行效率方面的卓越性，进一步验证了 PGN 范式的有效性。

# 4.1 引言

在长程时间序列预测任务中，已有研究表明，利用充足的历史输入能够提升预测性能[56,104]。然而，在实际应用场景中，考虑到训练设备的负载能力和数据采集成本等因素，利用有限的历史序列对未来进行长程预测，是一个更具应用价值的重要课题。本章聚焦于此展开相关研究。

无论历史序列充足还是有限，利用其对未来进行长程预测都涉及信息的传递过程，这不可避免地会带来一定程度的信息损失[28]。通过缩短信息传递路径，可以有效缓解这种影响，从而更好地捕获长期依赖关系[56]，同时降低训练难度[26]。

然而，现有方法要么存在信息传递路径过长的问题，要么难以处理序列中隐藏的复杂模式，要么计算复杂度过高。具体分析已在第二章展开，因此本节仅对分析结果进行总结。基于线性变换的方法，由于缺乏非线性建模能力，难以捕获序列中的复杂模式和深层依赖关系。基于循环神经网络（RNN）的方法，由于其循环结构的固有限制，导致信息传递路径较长，与序列长度  $T$  呈线性关系，为  $\mathcal{O}(T)$  。同时由于串行计算方式，使得实际运行速度较低。基于卷积神经网络（CNN）的方法，由于卷积核感受野的限制，需要通过多层堆叠才能捕获全局信息，在此过程中引入了与序列长度  $T$  呈超线性关系的信息传递路径  $\mathcal{O}(G)$ ，仍然不够短。此外，

多层堆叠增加了训练难度和计算开销[26]。基于注意力机制的方法，尽管能够将信息传递路径缩短至  $\mathcal{O}(1)$ ，但计算复杂度仍然过高。

基于上述动机，本章提出了一种全新的通用范式——并行门控网络（Parallel Gated Network, PGN）。PGN通过引入历史信息提取层（Historical Information Extraction, HIE）并行聚合每一时间步的完整历史信息，随后利用门控机制进行信息选择与融合，从而有效缩短信息传递路径至  $\mathcal{O}(1)$ ，这使得PGN在捕获长期模式方面更具优势。

为有效捕获时间序列中的周期性模式，现有方法表明，将时间序列从一维转换为二维建模是一种直接的解决方案[51,104,105]。在二维建模框架下，沿行方向捕获的短期尺度信息通常反映趋势变化，而沿列方向捕获的长期尺度信息则揭示周期性特性。但这两类信息存在明显差异，因此分别对两者采用独立分支建模是一种合理的选择。此外周期性模式贯串整个时间序列，有效利用该模式能显著提升长程预测的稳定性。因此在建模过程中应优先考虑对周期信息的有效提取。

鉴于以上分析，为将 PGN 更好地应用于时间序列预测任务，本章还提出了一种基于 PGN 的时间建模框架——时间并行门控网络（Temporal Parallel Gated Network, TPGN）。TPGN 通过构建两个独立的分支来捕获二维输入序列中的长期周期性和短期趋势性模式信息。其中，PGN 负责对二维输入的每一列进行建模，以保留各自的局部长期周期性特性。同时，利用分段（Patch）化操作在聚合信息方面的优势[27]，TPGN 先将趋势模式信息聚合为不同段，再进一步聚合这些段的信息以获取全局模式。最终，TPGN 通过整合两个分支的信息，实现对语义信息的全面捕获，从而提升预测精度。值得注意的是，TPGN 作为一个通用时间建模框架，长期周期性信息提取分支中的模块可被其他方法替代，以适应不同的应用需求。此外，TPGN 的时间和空间复杂度均为  $\mathcal{O}(\sqrt{T})$  ，为长程时间序列预测提供了一种有效性兼具高效性的解决方案。

总结来说，本章的主要贡献如下：

(1) 提出了并行门控网络 (PGN)。其作为一种新颖的通用范式, 能够将信息传递路径缩短至  $\mathcal{O}(1)$ , 从而更有效地捕获输入序列中的长期依赖关系, PGN 与其他几个范式的信息传递对比如图4-1所示。

(2) 提出了时间并行门控网络 (TPGN), 是一种基于 PGN 的新型时间建模框架。其采用双分支结构以全面捕获时间序列中复杂的时间模式信息。其中, 一个分支利用 PGN 从长期尺度上捕获周期性模式, 同时保留局部特性, 如图4-1(e) 所示; 另一个分支通过 Patch 化操作从短期尺度上建模趋势性模式, 并将其进一步聚合以获得序列的全局表示, 如图 4-1(f) 所示。值得注意的是, TPGN 具有良好的兼容性, 分支中的模块可替换成其他方法, 使其成为一个通用的时间建模框架。

(3) 在效率方面, 虽然 PGN 的理论复杂度为  $\mathcal{O}(T)$ , 但由于其可并行计算的特性, 其在实际运行效率上具有明显优势。TPGN 作为一种通用的时间建模框架, 实现了  $\mathcal{O}(\sqrt{T})$  的理论复杂度, 进一步提升了长程时间序列预测的计算效率。

(4) 通过在多个真实场景下的五个基准数据集上展开实验, 证明了TPGN在各类长程时间序列预测任务中的出色性能。此外, 运行效率实验进一步验证了TPGN的高效性。

![](images/af8f3c27e658d02747c2194d0f7bd4faa9b5e8137add329be101f90bd977d1c0.jpg)



(a) RNN


![](images/a23aade9b3c1d6b27b5159c641e58b58ec5267863ed5ca1cbc9e10f682a5a95b.jpg)



(b) PGN


![](images/6d7eae103c3d8f3e04da135c21f986250a7fdf1696a2b4a16f3019eb5c47039c.jpg)



(c) CNN


![](images/c7a04b99c9eb5279364b55647db56087a85d1fa25d1360ffc2d08b434a422911.jpg)



(d) 自注意力机制


![](images/76e4483866f89682f440fae0ae92715966ec28f22310585af9da334906eaa96a.jpg)



(e) TPGN长期周期信息提取分支


![](images/c6eeef72444e83a81a83984fde4e3f1fde8c1d3b4994ce7bcaf862c1d971b71e.jpg)



(f)TPGN趋势信息提取分支



图4-1 各方法提取信息过程示意图



Fig. 4-1 Information processing of various methods.


# 4.2 并行门控网络

在长程时间序列预测任务中，高效的信息传递过程对于提升预测准确性至关重要。较短的信息传递路径不仅有助于减少信息损失，还能降低训练难度，并更有效地捕获长期依赖模式。然而，基于前文的分析，现有方法在信息传递路径方面均存在一定局限性。

基于此，本章提出了一种新型范式——并行门控网络（PGN）。该方法通过线

性历史信息提取（HIE）层的设计，使得每个时间步均能并行捕获完整的历史信息，并将信息传递路径缩短至  $\mathcal{O}(1)$ ，从而实现高效的信息传递。此外，PGN采用简单的门控机制，在所有时间步上并行执行信息的选择与融合操作，充分利用历史信息，降低了计算资源开销，大大提高了运行效率。

# 4.2.1 网络结构

PGN 的信息传递过程和结构分别如图4-1(b)与图4-2所示。具体来说，为了在较短的信息传递路径内捕获所有历史数据点的信息，PGN 引入了一个线性历史信息提取层（Historical Information Extraction, HIE），该层在均能对每个数据点的完整历史信息进行聚合，且它们间的计算相互独立，因而可进行高效的并行处理。同时，PGN 引入了门控机制，在所有时间步中并行地控制信息的选择与融合，从而显著降低了计算开销。对于长度为  $T$  的输入信号  $\mathbf{X} \in \mathbb{R}^{T \times 1}$ ，PGN 的计算过程可形式化表达为：

$$
\mathbf {H} = \operatorname {H I E} (\text {P a d d i n g} (\mathbf {X})), \tag {4-1a}
$$

$$
\mathbf {G} = \sigma \left(\mathbf {W} _ {g} [ \mathbf {X}, \mathbf {H} ] + \boldsymbol {b} _ {g}\right), \tag {4-1b}
$$

$$
\hat {\mathbf {H}} = \tanh  \left(\mathbf {W} _ {t} [ \mathbf {X}, \mathbf {H} ] + b _ {t}\right), \tag {4-1c}
$$

$$
\mathbf {O u t} = \mathbf {G} \odot \mathbf {H} + (1 - \mathbf {G}) \odot \hat {\mathbf {H}}, \tag {4-1d}
$$

其中，Padding(\cdot) 表示在长度维度上对处理后的信号前端进行零填充操作，填充向量的大小为  $\mathbb{R}^{(T - 1)}$  。HIE(\cdot) 是一个线性层，其权重矩阵为  $\mathbf{W}_h\in \mathbb{R}^{dm\times (T - 1)}$  ，偏置向量为  $b_{h}\in \mathbb{R}^{dm}$  。该层沿序列长度方向滑动，以并行方式聚合每个时间步的所有历史信息，输出结果为  $\mathbf{H}\in \mathbb{R}^{T\times dm}$  。在计算过程中，还使用了权重矩阵  $\mathbf{W}_g,\mathbf{W}_t\in \mathbb{R}^{dm\times (dm + 1)}$  和偏置向量  $b_{g},b_{t}\in \mathbb{R}^{dm}$  。G和  $\hat{\mathbf{H}}$  是门控机制中的中间变量。符号  $\odot$  表示逐元素乘积，  $\sigma (\cdot)$  和  $\tanh (\cdot)$  分别为 sigmoid和tanh 激活函数。最终，Out  $\in \mathbb{R}^{T\times dm}$  为PGN的输出结果。

# 4.2.2 理论复杂度分析

尽管PGN通过并行化设计，能够在序列长度上实现高效计算，但在每个数据点上仍需捕获其完整的历史信息。因此在此部分中，理论复杂度仍与信号长度  $T$  呈线性关系，即为  $O(T)$  。同时，PGN门控机制的计算与信号长度无关，因此其计算开销可视为不随序列长度变化的常数量级。基于此，PGN的总体理论复杂度可总结为  $O(T)$ ，但其可并行计算的机制，为处理长序列提供了更为高效的解决方案。

![](images/a665f4f2d39b5c4c8446ae1370610315ec7e6801bfe344bd72574d5449fde79d.jpg)



图4-2 PGN网络结构图



Fig 4-2 The structures of PGN.


![](images/70c09e260ed7328e1a050e4a8d645c55b7f57be2720b70419d78ec4763db4ed1.jpg)



图4-3 基于PGN的时间序列预测方法TPGN模型架构图 Fig 4-3 The structures of TPGN.


# 4.3 基于并行门控网络的长程时间序列预测方法

时间序列预测任务的核心目标是在给定长度为  $T$  的历史序列的基础上，预测长度为  $F$  的未来序列。然而，现有方法在提取时间序列的周期性语义信息方面存在一定局限性，具体表现如第4.1节所述，PGN虽然能够有效建模时间序列的局部模式，但在直接捕捉长期周期性特征时表现受限，这限制了其在长程时间序列预测任务中的应用。为解决这一问题，本研究提出了一种基于并行门控网络（TPGN）的预测方法。TPGN将输入序列从一维（1D）转换为二维（2D）进行建模，通过引入两个独立的建模分支，以充分挖掘时间序列的短期变化模式和长期周期性特征。其中，长期信息提取分支用于捕获时间序列的周期性模式，而短期信息提取分支则聚合短时信息以增强模型的预测能力。两个分支提取的信息最终融合，以生成对未来时间步的精准预测。TPGN的信息传递示意图和整体结构分别展示在图4-1(e)(f)和图4-3中。

# 4.3.1 输入模块

为了使TPGN能够直接捕捉周期性语义信息，受以往研究[51,104,105]的启发，本章将原始一维序列重塑为二维形式。与TimesNet[51]和PDF[105]采用多尺度周期处理不同，本章借鉴了WITRAN[104]的思路，仅根据时间序列的自然周期进行重塑，避免了额外的计算开销。此外，为了减少数据波动对模型训练的负面影响，本章在时间维度上引入了归一化层，以提高模型的稳定性和泛化能力。假设输入序列为 $\mathbf{X}_{\mathrm{ID}} = \{\pmb{x}_1,\pmb{x}_2,\dots,\pmb{x}_T\} \in \mathbb{R}^{T\times N}$ ，同时给定时间外部特征TFhist  $\in \mathbb{R}^{T\times D}$  （ $N$  和  $D$  分别表示变量数量和时间外部特征数量）时，该模块的数学表达式可形式化表达如公式（4-2）所示：

$$
\boldsymbol {\mu} = \frac {1}{T} \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t}, \tag {4-2a}
$$

$$
\boldsymbol {\sigma} ^ {2} = \frac {1}{T} \sum_ {t = 1} ^ {T} \left(\boldsymbol {x} _ {t} - \boldsymbol {\mu}\right) ^ {2}, \tag {4-2b}
$$

$$
\mathbf {X} _ {\mathrm {I D}} = \left\{ \begin{array}{l l} \mathbf {X} & \text {n o r m} = 0 \\ (\mathbf {X} - \boldsymbol {\mu}) / \boldsymbol {\sigma}, & \text {n o r m} = 1 \end{array} , \right. \tag {4-2c}
$$

其中， $\pmb{\mu} \in \mathbb{R}^{N}$  表示序列个变量的均值向量， $\sigma$  则表示序列各变量的标准差向量。 $\mathbf{X}_{\mathrm{ID}} \in \mathbb{R}^{T \times N}$  表示归一化后的序列，超参数norm需要根据不同数据集的特性进行调整。

为直接捕获序列的周期特性，需要根据周期数  $P$  将归一化后的输入  $\mathbf{X}_{\mathrm{ID}}$  从一维转换到二维排列。同时，为给每个变量的每个时间步引入时间戳信息，本章将原始时间戳  $\mathbf{TF}_{\mathrm{hist}}$  在  $N$  个通道上进行复制，并进行相应的二维转换。最终，将转换后的时间戳信息与二维输入拼接，形成模型的最终输入。该过程可形式化表达如公式（4-3）所示：

$$
\mathcal {X} _ {\mathrm {2 D}} = \operatorname {R e s h a p e} \left(\mathbf {X} _ {\mathrm {1 D}}\right), \tag {4-3a}
$$

$$
\mathcal {T} F _ {\text {h i s t}} = \operatorname {R e p e a t} \left(\mathbf {T} \mathbf {F} _ {\text {h i s t}}\right), \tag {4-3b}
$$

$$
\mathcal {T} F _ {\text {h i s t}} ^ {2 \mathrm {D}} = \operatorname {R e s h a p e} \left(\mathcal {T} F _ {\text {h i s t}}\right), \tag {4-3c}
$$

$$
\mathfrak {I} n _ {\mathrm {2 D}} = \left[ \mathcal {X} _ {\mathrm {2 D}}, \mathcal {T} F _ {\text {h i s t}} \right], \tag {4-3d}
$$

其中  $\mathcal{X}_{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N \times 1}$  表示序列从一维转换到二维后的张量， $\mathrm{Reshape}(\cdot)$  表示转置操作。 $R$  为时间序列转置后在时间维度上的行数， $P$  为周期数，即时间序列转换后在时间维度上的列数。 $\mathfrak{T}F_{\mathrm{hist}} \in \mathbb{R}^{T \times N \times D}$  表示在  $N$  个通道上复制后的时间戳信息，

Repeat(·) 表示复制操作。 $\mathfrak{F}_{\mathrm{hist}}^{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N \times D}$  表示时间戳二维化后的结果， $D$  为时间戳特征的维度。 $[\cdot]$  表示拼接（Concat）操作， $\mathfrak{J}_{\mathrm{2D}} \in \mathbb{R}^{R \times P \times N \times (D + 1)}$  表示模型的最终输入。

# 4.3.2 长期信息提取分支

在长期信息提取分支中，本节直接采用PGN进行信息捕捉。一方面，它能够有效提取每个时间步中的长期重复历史信息。另一方面，通过门控机制，在每个时间步选择并融合当前信息与历史信息，以增强模型的时间依赖性，从而最大程度地保留长期周期性特征。具体而言，该分支的计算过程可形式化表达如公式（4-4）所示：

$$
\mathcal {X} _ {\text {l o n g}} ^ {m} = \operatorname {P G N} \left(\mathcal {I} n _ {\mathrm {2 D}} ^ {m}\right), \tag {4-4a}
$$

$$
\mathbf {H} _ {\text {l o n g}} ^ {m} = \operatorname {L i n e a r} _ {\text {l o n g}} \left(\mathcal {X} _ {\text {l o n g}} ^ {m}\right), \tag {4-4b}
$$

其中， $\mathrm{PGN}(\cdot)$  表示输入经过PGN模型的处理。需要注意的是，PGN的计算是沿着  $R$  维度进行的。这种处理方式的优势在于能够保留每一列各自的独特特征，从而更好地服务于预测任务。其输出记为  $\mathcal{X}_{\mathrm{long}}^{m}\in \mathbb{R}^{R\times P\times dm}$  。为了便于将长期信息用于预测，使用一个线性层Linearlong(·）对每一列中所有行的信息进行聚合。该分支的输出记为  $\mathbf{H}_{\mathrm{long}}^{m}\in \mathbb{R}^{P\times dm}$  。

# 4.3.3 短期信息提取分支

在短期信息提取分支的核心思想是利用patch在聚合短期信息方面的优势来提取局部信息，本节首先使用一个线性层将短期信息聚合为多个patch。随后，再通过另一个线性层将这些patch进一步融合为序列的全局信息。其计算过程如(4-5)所示

$$
\mathbf {H} _ {\text {s h o r t}} ^ {m} = \operatorname {L i n e a r} _ {\text {s h o r t}} ^ {\text {r o w}} \left(\mathcal {I} n _ {2 \mathrm {D}} ^ {m}\right), \tag {4-5a}
$$

$$
\mathbf {H} _ {\text {g l o b a l}} ^ {m} = \operatorname {L i n e a r} _ {\text {s h o r t}} ^ {\text {c o l}} \left(\mathbf {H} _ {\text {s h o r t}} ^ {m}\right), \tag {4-5b}
$$

其中,  $\operatorname{Linear}_{\text {short }}^{\text {row }}(\cdot)$  沿着  $P$  维度进行操作, 其输出为  $\mathbf{H}_{\text {short }}^{m} \in \mathbb{R}^{R \times dm}$  。随后,  $\operatorname{Linear}_{\text {short }}^{\text {col }}(\cdot)$  对  $\mathbf{H}_{\text {short }}^{m}$  进行进一步聚合, 得到序列的全局表示  $\mathbf{H}_{\text {global }}^{m} \in \mathbb{R}^{1 \times dm}$  。最后, 为了便于后续预测, 将  $\mathbf{H}_{\text {global }}^{m}$  在第一个维度上重复  $P$  次, 从而得到一个与长期信息提取分支输出维度相同的新表示,  $\mathbb{R}^{P \times dm}$  。

# 4.3.4 预测模块

在预测模块中，首先对长期和短期信息提取分支的输出进行拼接，以结合局部长期周期性模式与全局短期信息。然后，通过一个线性层预测未来的时间序列值，最终将结果重塑为目标输出格式。该模块过程表达如公式（4-6）所示：

$$
\hat {\mathbf {Y}} = \operatorname {R e s h a p e} \left(\operatorname {L i n e a r} \left(\left[ \mathbf {H} _ {\text {l o n g}} ^ {m}, \mathbf {H} _ {\text {g l o b a l}} ^ {m} \right]\right)\right), \tag {4-6}
$$

其中，[·]表示拼接操作。经过Linear(·)处理后的输出维度为  $\mathbb{R}^{P\times R_{\mathrm{f}}}$ ，其中  $R_{\mathrm{f}}$  与  $P$  的乘积等于预测序列长度  $F$ 。最后，通过Reshape(·)操作对输出进行维度置换和重塑，将其转化为一维形式，得到结果  $\hat{\mathbf{Y}}\in \mathbb{R}^{F\times 1}$ 。

# 4.3.5 理论复杂度分析

由于TPGN具有两个独立的分支，因此需要分别对其进行复杂度分析。对于长期信息提取分支，TPGN在  $R$  维度上应用PGN范式，该步骤的复杂度与  $R$  成线性关系，记作  $\mathcal{O}(R)$  。随后，通过一个线性层对所有行的信息进行聚合，该过程的复杂度同样为  $\mathcal{O}(R)$  。因此，长期信息提取分支的总复杂度为  $\mathcal{O}(R)$  。对于短期信息提取分支，TPGN应用了两个线性层。第一个线性层将时间维度从  $P$  压缩到1，第二个线性层将另一个时间维度  $R$  压缩到1，因此它们的复杂度分别为  $\mathcal{O}(P)$  和  $\mathcal{O}(R)$  。由于  $R$  与  $P$  的乘积等于输入序列长度  $T$  ，因此  $\mathcal{O}(R)$  和  $\mathcal{O}(P)$  的复杂度均为  $\mathcal{O}(\sqrt{T})$  。综上所述，TPGN的两个分支复杂度均为  $\mathcal{O}(\sqrt{T})$  ，因此TPGN的总体（时间和空间）复杂度也为  $\mathcal{O}(\sqrt{T})$  。然后，由于预测的结果长度必须与预测序列长度保持一致，因此，预测模块的时间复杂度为  $\mathcal{O}(\sqrt{T})$  ，而空间复杂度则为  $\mathcal{O}(T)$  。

# 4.4 实验评估

为了全面评估本章所提出的TPGN方法的性能，本节在第2.7节中提到的五个真实场景下的基准数据集上进行了广泛的实验，并将对实验结果进行详细讨论与分析。

# 4.4.1 基线方法

一些较早的方法，如Transformer[22]、Informer[2]、Autoformer[55]、Pyraformer[56]和FEDformer[54]，已经被本节所选取的其他方法显著超越。因此，本节选取了十

三种方法进行了全面比较，涵盖了不同的架构。其中，包括两种基于RNN的方法：WITRAN[104]、SegRNN[106]；三种基于CNN的方法：ModernTCN[53]、TimesNet[51]和MICN[26]；三种基于线性变换的方法：FITS[41]、TimeMixer[40]和DLinear[39]；四种基于注意力机制的方法：iTransformer[61]、PDF[105]、Basisformer[107]和PatchTST[27]以及FiLM[99]，展开实验与分析。

# 4.4.2 实验设置

为验证TPGN的性能，本小节借鉴了WITRAN[104]的实验设置，在五个涵盖能源、交通和天气领域的真实场景下的基准数据集上进行了实验。输入序列长度固定为168步，设置168、336、720和1440四种预测步长。所有模型均基于PyTorch[102]实现，并在NVIDIA RTX A4000 16GB GPU上进行了实验。

TPGN及所有基线模型均使用L2损失函数（MSE）和Adam优化器[103]进行训练，初始学习率设为  $10^{-3}$ ，批量大小（Batch size）为32。最大训练轮数设定为25，若验证集的L2损失在连续5轮内未下降，则提前停止训练。将随机种子设为2023。

为确保公平比较，本节为所有模型的公共参数设定了相同的搜索空间：具体而言：(1) 设定模型的隐藏维度  $dk$ 、 $dm$  的范围为  $\{2,4,8,16,32,64,128,256,512,1024\}$ ；(2) 设定模型编码器和解码器的层数的范围为  $\{1,2,3\}$ ；（3）设定注意力机制头数的范围为  $\{1,2,4,8\}$ 。对于各模型特有的超参数，参考其原始论文进行确定。所有模型的最佳参数均基于验证集上的最小损失函数值选择，以确保各模型在相同条件下达到最优性能。

# 4.4.3 预测性能分析

尽管已有大量研究聚焦于建模时间序列中多个变量之间的关系，但为了更好地适应多变量上异质的时间特性[2]，有效捕获复杂的时间模式信息是前提基础。基于此，本章参考了WITRAN[104]的实验设置，在实验中仅使用单变量进行实验验证。此外，为了保证公平性，本节对每个基线模型进行了参数搜索，以确保它们在不同任务中都能达到各自的最优性能。

# (1) 长程预测结果

本章在每个数据集上进行了四项长程时间序列预测任务，结果如表4-1所示。例如，在表4-1左侧的任务设定“168-1440”中，“168”代表输入序列长度，“1440”代表预测序列长度。值得注意的是，本章提出的TPGN在所有任务中均取得了最先进（SOTA）的性能，相较于此前的最优方法，MSE平均降低  $12.35\%$  ，MAE平均


表 4-1 长程时间序列预测结果



Table 4-1 Long-range time series forecasting results.


<table><tr><td rowspan="2">方法 评价指标</td><td colspan="2">TPGN (ours)</td><td colspan="2">WITRAN</td><td colspan="2">SegRNN</td><td colspan="2">ModernTCN</td><td colspan="2">TimesNet</td><td colspan="2">MICN</td><td colspan="2">FITS</td><td colspan="2">TimeMixer</td><td colspan="2">DLinear</td><td colspan="2">iTransformer</td><td colspan="2"></td><td colspan="2">Basisformer</td><td colspan="2">PatchTST</td><td colspan="2">FiLM</td><td></td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td></td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.2107</td><td>0.3264</td><td>0.2397</td><td>0.3519</td><td>0.2600</td><td>0.3622</td><td>0.2473</td><td>0.3437</td><td>0.2825</td><td>0.3797</td><td>0.3168</td><td>0.3797</td><td>0.2598</td><td>0.3573</td><td>0.2804</td><td>0.3792</td><td>0.2606</td><td>0.3579</td><td>0.2479</td><td>0.3516</td><td>0.2483</td><td>0.3491</td><td>0.3116</td><td>0.4026</td><td>0.2980</td><td>0.3832</td><td>0.2587</td><td>0.3557</td></tr><tr><td>168-336</td><td>0.2276</td><td>0.3446</td><td>0.2607</td><td>0.3721</td><td>0.3166</td><td>0.4017</td><td>0.3110</td><td>0.3887</td><td>0.3505</td><td>0.4253</td><td>0.3002</td><td>0.4253</td><td>0.3072</td><td>0.3938</td><td>0.3183</td><td>0.4029</td><td>0.3080</td><td>0.3946</td><td>0.3128</td><td>0.3974</td><td>0.3094</td><td>0.3902</td><td>0.4844</td><td>0.4824</td><td>0.3446</td><td>0.4094</td><td>0.3062</td><td>0.3922</td></tr><tr><td>168-720</td><td>0.2303</td><td>0.3550</td><td>0.2906</td><td>0.3965</td><td>0.3964</td><td>0.4660</td><td>0.3624</td><td>0.4478</td><td>0.4261</td><td>0.4686</td><td>0.4453</td><td>0.4686</td><td>0.3504</td><td>0.4366</td><td>0.3835</td><td>0.4560</td><td>0.3515</td><td>0.4374</td><td>0.3660</td><td>0.4438</td><td>0.3541</td><td>0.4423</td><td>0.6448</td><td>0.5653</td><td>0.4324</td><td>0.4782</td><td>0.3486</td><td>0.4349</td></tr><tr><td>168-1440</td><td>0.2484</td><td>0.3775</td><td>0.3255</td><td>0.4302</td><td>0.7574</td><td>0.6547</td><td>0.5307</td><td>0.5573</td><td>0.6688</td><td>0.6102</td><td>0.8784</td><td>0.6102</td><td>0.5176</td><td>0.5591</td><td>0.6857</td><td>0.6194</td><td>0.5300</td><td>0.5681</td><td>0.7028</td><td>0.6348</td><td>0.9029</td><td>0.6913</td><td>0.6368</td><td>0.5967</td><td>0.7349</td><td>0.6464</td><td>0.5146</td><td>0.5565</td></tr><tr><td rowspan="4">Traffic</td><td>168-168</td><td>0.1196</td><td>0.1857</td><td>0.1377</td><td>0.2051</td><td>0.1901</td><td>0.2816</td><td>0.1473</td><td>0.2212</td><td>0.1490</td><td>0.2293</td><td>0.2418</td><td>0.3537</td><td>0.1498</td><td>0.2134</td><td>0.1340</td><td>0.2124</td><td>0.1519</td><td>0.2195</td><td>0.1343</td><td>0.2083</td><td>0.1397</td><td>0.2119</td><td>0.1634</td><td>0.2553</td><td>0.1622</td><td>0.2320</td><td>0.1501</td><td>0.2143</td></tr><tr><td>168-336</td><td>0.1156</td><td>0.1868</td><td>0.1321</td><td>0.2059</td><td>0.2227</td><td>0.3129</td><td>0.1410</td><td>0.2214</td><td>0.1499</td><td>0.2356</td><td>0.2420</td><td>0.3568</td><td>0.1445</td><td>0.2148</td><td>0.1298</td><td>0.2147</td><td>0.1468</td><td>0.2210</td><td>0.1366</td><td>0.2221</td><td>0.1351</td><td>0.2132</td><td>0.1544</td><td>0.2493</td><td>0.1641</td><td>0.2364</td><td>0.1453</td><td>0.2165</td></tr><tr><td>168-720</td><td>0.1293</td><td>0.2057</td><td>0.1439</td><td>0.2226</td><td>0.2674</td><td>0.3436</td><td>0.1574</td><td>0.2389</td><td>0.1621</td><td>0.2471</td><td>0.2488</td><td>0.3592</td><td>0.1603</td><td>0.2330</td><td>0.1396</td><td>0.2285</td><td>0.1629</td><td>0.2389</td><td>0.1402</td><td>0.2265</td><td>0.1502</td><td>0.2290</td><td>0.1538</td><td>0.2490</td><td>0.1770</td><td>0.2548</td><td>0.1617</td><td>0.2358</td></tr><tr><td>168-1440</td><td>0.1390</td><td>0.2114</td><td>0.1611</td><td>0.2369</td><td>0.3453</td><td>0.3929</td><td>0.1980</td><td>0.2739</td><td>0.1691</td><td>0.2517</td><td>0.2817</td><td>0.3818</td><td>0.1845</td><td>0.2571</td><td>0.1547</td><td>0.2392</td><td>0.1890</td><td>0.2640</td><td>0.1519</td><td>0.2321</td><td>0.2074</td><td>0.2779</td><td>0.1735</td><td>0.2654</td><td>0.2139</td><td>0.2875</td><td>0.1861</td><td>0.2615</td></tr><tr><td rowspan="4">ETTh1</td><td>168-168</td><td>0.1061</td><td>0.2533</td><td>0.1105</td><td>0.2589</td><td>0.1189</td><td>0.2705</td><td>0.1210</td><td>0.2694</td><td>0.1133</td><td>0.2612</td><td>0.1257</td><td>0.2803</td><td>0.1089</td><td>0.2556</td><td>0.1110</td><td>0.2587</td><td>0.1112</td><td>0.2605</td><td>0.1112</td><td>0.2598</td><td>0.1115</td><td>0.2579</td><td>0.1169</td><td>0.2646</td><td>0.1212</td><td>0.2704</td><td>0.1091</td><td>0.2558</td></tr><tr><td>168-336</td><td>0.1110</td><td>0.2625</td><td>0.1189</td><td>0.2714</td><td>0.1378</td><td>0.2972</td><td>0.1342</td><td>0.2884</td><td>0.1202</td><td>0.2732</td><td>0.1422</td><td>0.3006</td><td>0.1162</td><td>0.2682</td><td>0.1209</td><td>0.2716</td><td>0.1251</td><td>0.2794</td><td>0.1203</td><td>0.2709</td><td>0.1207</td><td>0.2725</td><td>0.1227</td><td>0.2734</td><td>0.1287</td><td>0.2808</td><td>0.1187</td><td>0.2708</td></tr><tr><td>168-720</td><td>0.1346</td><td>0.2908</td><td>0.1566</td><td>0.3150</td><td>0.2134</td><td>0.3697</td><td>0.1676</td><td>0.3238</td><td>0.1458</td><td>0.3059</td><td>0.1609</td><td>0.3200</td><td>0.1544</td><td>0.3109</td><td>0.1362</td><td>0.2927</td><td>0.1919</td><td>0.3465</td><td>0.1423</td><td>0.3020</td><td>0.1720</td><td>0.3278</td><td>0.1521</td><td>0.3121</td><td>0.1727</td><td>0.3297</td><td>0.1717</td><td>0.3266</td></tr><tr><td>168-1440</td><td>0.1343</td><td>0.2941</td><td>0.1541</td><td>0.3157</td><td>0.4033</td><td>0.5296</td><td>0.2756</td><td>0.4247</td><td>0.1543</td><td>0.3119</td><td>0.1444</td><td>0.3032</td><td>0.2319</td><td>0.3863</td><td>0.1480</td><td>0.3068</td><td>0.3606</td><td>0.4939</td><td>0.1520</td><td>0.3107</td><td>0.2792</td><td>0.4272</td><td>0.1664</td><td>0.3230</td><td>0.3206</td><td>0.4561</td><td>0.3056</td><td>0.4494</td></tr><tr><td rowspan="4">ETTh2</td><td>168-168</td><td>0.2174</td><td>0.3623</td><td>0.2389</td><td>0.3813</td><td>0.2566</td><td>0.4013</td><td>0.2564</td><td>0.3980</td><td>0.2655</td><td>0.4051</td><td>0.2734</td><td>0.4162</td><td>0.2547</td><td>0.3947</td><td>0.2507</td><td>0.3936</td><td>0.2556</td><td>0.3944</td><td>0.2630</td><td>0.4053</td><td>0.2606</td><td>0.412</td><td>0.2806</td><td>0.4138</td><td>0.2582</td><td>0.3983</td><td>0.2546</td><td>0.3942</td></tr><tr><td>168-336</td><td>0.2237</td><td>0.3769</td><td>0.2277</td><td>0.3778</td><td>0.3017</td><td>0.4398</td><td>0.2918</td><td>0.4312</td><td>0.2725</td><td>0.4163</td><td>0.3017</td><td>0.4429</td><td>0.2874</td><td>0.4250</td><td>0.2642</td><td>0.4085</td><td>0.2891</td><td>0.4256</td><td>0.2658</td><td>0.4092</td><td>0.3064</td><td>0.4440</td><td>0.2697</td><td>0.4132</td><td>0.3206</td><td>0.4514</td><td>0.2894</td><td>0.4263</td></tr><tr><td>168-720</td><td>0.2356</td><td>0.3898</td><td>0.2718</td><td>0.4146</td><td>0.3897</td><td>0.4988</td><td>0.3991</td><td>0.5022</td><td>0.3186</td><td>0.4465</td><td>0.4770</td><td>0.5602</td><td>0.3983</td><td>0.5023</td><td>0.3259</td><td>0.4510</td><td>0.4090</td><td>0.5090</td><td>0.2951</td><td>0.4312</td><td>0.4546</td><td>0.5415</td><td>0.3034</td><td>0.4372</td><td>0.4398</td><td>0.5304</td><td>0.4039</td><td>0.5061</td></tr><tr><td>168-1440</td><td>0.2514</td><td>0.4070</td><td>0.3350</td><td>0.4624</td><td>0.8067</td><td>0.7307</td><td>0.8537</td><td>0.7437</td><td>0.3839</td><td>0.4933</td><td>0.4876</td><td>0.5602</td><td>0.7852</td><td>0.7256</td><td>0.3937</td><td>0.5040</td><td>0.7921</td><td>0.7262</td><td>0.3806</td><td>0.4894</td><td>0.8699</td><td>0.7651</td><td>0.3963</td><td>0.4996</td><td>0.8339</td><td>0.7330</td><td>0.7843</td><td>0.7210</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.1877</td><td>0.3166</td><td>0.2050</td><td>0.3338</td><td>0.2165</td><td>0.3405</td><td>0.2692</td><td>0.4088</td><td>0.2420</td><td>0.3608</td><td>0.2231</td><td>0.3489</td><td>0.2423</td><td>0.3561</td><td>0.2275</td><td>0.3466</td><td>0.2421</td><td>0.3578</td><td>0.2636</td><td>0.4056</td><td>0.2557</td><td>0.3989</td><td>0.2301</td><td>0.3541</td><td>0.2469</td><td>0.3597</td><td>0.2426</td><td>0.3544</td></tr><tr><td>168-336</td><td>0.1978</td><td>0.3278</td><td>0.2197</td><td>0.3470</td><td>0.2693</td><td>0.3868</td><td>0.2916</td><td>0.4314</td><td>0.2821</td><td>0.3885</td><td>0.2663</td><td>0.3837</td><td>0.2977</td><td>0.4007</td><td>0.2775</td><td>0.3836</td><td>0.2918</td><td>0.3975</td><td>0.2658</td><td>0.4092</td><td>0.3065</td><td>0.4440</td><td>0.2593</td><td>0.3751</td><td>0.3040</td><td>0.4049</td><td>0.2981</td><td>0.3988</td></tr><tr><td>168-720</td><td>0.1925</td><td>0.3255</td><td>0.2538</td><td>0.3796</td><td>0.3478</td><td>0.4519</td><td>0.4279</td><td>0.4812</td><td>0.2941</td><td>0.4013</td><td>0.3077</td><td>0.4202</td><td>0.4044</td><td>0.4758</td><td>0.2873</td><td>0.3931</td><td>0.3915</td><td>0.4739</td><td>0.2754</td><td>0.3900</td><td>0.3988</td><td>0.4673</td><td>0.3984</td><td>0.3916</td><td>0.4023</td><td>0.4662</td><td>0.4093</td><td>0.4737</td></tr><tr><td>168-1440</td><td>0.1786</td><td>0.3184</td><td>0.2695</td><td>0.3966</td><td>0.6456</td><td>0.6484</td><td>0.7049</td><td>0.6351</td><td>0.2988</td><td>0.4092</td><td>0.4306</td><td>0.4994</td><td>0.7027</td><td>0.6555</td><td>0.3010</td><td>0.4078</td><td>0.5837</td><td>0.6177</td><td>0.3007</td><td>0.4113</td><td>0.7334</td><td>0.6557</td><td>0.2959</td><td>0.4095</td><td>0.7150</td><td>0.6336</td><td>0.7028</td><td>0.6453</td></tr><tr><td rowspan="25" colspan="29">Average improvement of TPGN</td><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr></table>


* 最佳结果以加粗标示，次优结果以下划线标示。MSE或MAE越低，表示预测效果越好。


降低  $7.25\%$  。具体而言，TPGN在ECL数据集上的MSE平均降低  $17.31\%$  ，Traffic数据集降低  $9.38\%$  ， $ETTh_{1}$  数据集降低  $3.79\%$  ， $ETTh_{2}$  数据集降低  $12.26\%$  ，Weather数据集降低  $19.09\%$  。此外，本章计算了TPGN相较于各方法在所有任务上的平均提升，并在表4-1的最后一行展示。基于上述结果，可以得出结论：TPGN能够有效应对不同领域的长时序预测任务。

# (2) 不同预测长度对模型性能的影响

通过表4-1不难看出，随着预测任务长度的增加，所有模型的性能均呈现不同程度的下降。然而，TPGN的性能下降趋势相对较缓。为了进一步验证TPGN的优越性，本章在实验设置上进行了扩展，从表4-1中选取了多种不同范式下的代表性方法，包括WITRAN（基于RNN）、TimesNet（基于CNN）、TimeMixer（基于MLP）和Transformer（基于Transformer），并与TPGN进行对比。ECL数据集上的实验结果如图4-4所示。结果表明，随着预测任务长度的逐步增加，TPGN的性能虽有所下降，但整体趋势较为平稳，且始终优于其他对比方法。这一结果充分表明，TPGN能够在有限输入数据中有效提取关键信息，并在长序列预测任务中保持其优势。

![](images/43575fb21a84e5d8f08d4898bbc6322be8c3d8888ab69fb1b9501107a3e9a1aa.jpg)


![](images/39e05f611c442a1749dfe4634e5a2bd6be96abce2f53f6276d88ca4b4844b552.jpg)



图4-4ECL数据集上不同预测长度的实验结果



Fig 4-4 Experimental results with different forecasting lengths on the ECL dataset.


# 4.4.4 运行效率分析

尽管本章主要聚焦于利用更短的历史输入来预测较长时间范围的未来输出，但为了全面验证本章所提出的方法实际运行效率，本小节设计了两组对比实验。第一组实验中，输入长度固定为168，并分别设置输出长度为168、336、720和1440，以研究预测长度对模型运行效率的影响。第二组实验则固定输出长度为1440，分别调整输入长度为168、336、720和1440，以分析历史输入序列长度对模型运行效率的影响。在效率分析中，本章综合考虑了时间开销和显存占用两方面。对比方法的选择依据表4-1中的实验结果，从不同范式中挑选出具有代表性的模型进行比较。为消除不同公共参数对实验结果的影响，所有实验均在批量大小固定为32、

模型维度设定为128，并采用单层模型的条件下进行测试。实验结果如图4-5所示。需要注意的是，由于TimesNet[51]在时间开销和显存占用方面显著高于其他对比方法，为了更清晰地展示其他方法的对比情况细节，图4-5中未包含TimesNet的结果。同样，由于FiLM的时间开销较高，它也未被包含在时间的对比结果图中。

![](images/b7f253be11f4cc7c10b50bc2fd86d4492b862c973a0f541d2562e0beda4edf03.jpg)



(a) 时间开销情况（输入长度固定为168）


![](images/a1b941e9ddd71505e24aa4e368f56c8d57fa135eb4b1929ae0760d9f11bd5378.jpg)



(b) 显存占用情况（输入长度固定为168）


![](images/fe59e3127860e9cfc07cf9929e9975a7ceb7a92b10c9e2eb7a2fbef957ab5301.jpg)



(c) 时间开销情况（输出长度固定为1440）


![](images/b85484db939784d600e8564fc933afd6fc973063536e25f42bebc84411ca1a71.jpg)



(d) 显存占用情况（输出长度固定为 1440）



图4-5 不同模型的时间开销和显存占用情况



Fig 4-5 Time and memory overhead of different models.


从图4-5可以看出，虽然TPGN在时间开销和内存占用方面并非最低，但总体上，其仍保持了较优水平。需要强调的是，TPGN仅使用单层结构，而大多数其他模型则需要更多层才能实现更佳的性能，这不可避免地带来更高的开销。这一点进一步证明了，本章所提出的方法不仅在预测性能上达到了SOTA水平，同时在运行效率上也表现出色。

# 4.4.5 模型分析及讨论

本小节主要通过消融实验、鲁棒性分析、参数敏感性分析和案例分析,对TPGN进行全面深入的讨论，以更充分验证其在长程时间序列预测中的优势。

# (1) 消融实验

为了验证TPGN中两个信息提取分支的作用，本章进行了仅使用单一分支时

模型性能的测试。此外, 为了验证 PGN 的有效性, 本章通过分别用 GRU 和 MLP 替换 PGN, 进行了消融实验。“TPGN-long” 表示仅使用长期信息提取分支, “TPGN-short” 表示仅使用短期信息提取分支。“TPGN-GRU/-LSTM/-MLP/-Attn” 分别表示在长期信息提取分支中用 GRU、LSTM、MLP 和自注意力替换 PGN。这些实验的结果如表4-2所示。


表 4-2 消融研究在长程时间序列预测任务中的结果



Table 4-2 Results of the ablation study on long-range forecasting tasks.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">TPGN</td><td colspan="2">TPGN-long</td><td colspan="2">TPGN-short</td><td colspan="2">TPGN-GRU</td><td colspan="2">TPGN-LSTM</td><td colspan="2">TPGN-MLP</td><td colspan="2">TPGN-Attn</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.2107</td><td>0.3264</td><td>0.2223</td><td>0.3399</td><td>0.7226</td><td>0.6755</td><td>0.2363</td><td>0.3388</td><td>0.2263</td><td>0.3344</td><td>0.2377</td><td>0.3425</td><td>0.2279</td><td>0.3376</td></tr><tr><td>168-336</td><td>0.2276</td><td>0.3446</td><td>0.2422</td><td>0.3567</td><td>0.7598</td><td>0.6901</td><td>0.2393</td><td>0.3497</td><td>0.2591</td><td>0.3641</td><td>0.2669</td><td>0.3636</td><td>0.2660</td><td>0.3709</td></tr><tr><td>168-720</td><td>0.2303</td><td>0.3550</td><td>0.2405</td><td>0.3628</td><td>0.7841</td><td>0.6997</td><td>0.2719</td><td>0.3774</td><td>0.2703</td><td>0.3855</td><td>0.2967</td><td>0.3946</td><td>0.3149</td><td>0.4115</td></tr><tr><td>168-1440</td><td>0.2484</td><td>0.3775</td><td>0.2710</td><td>0.3951</td><td>0.8323</td><td>0.7224</td><td>0.3557</td><td>0.4550</td><td>0.2936</td><td>0.4197</td><td>0.3456</td><td>0.4424</td><td>0.3649</td><td>0.4589</td></tr><tr><td rowspan="4">Traffic</td><td>168-168</td><td>0.1196</td><td>0.1857</td><td>0.1215</td><td>0.1871</td><td>1.8730</td><td>1.1806</td><td>0.1269</td><td>0.1923</td><td>0.1271</td><td>0.1920</td><td>0.1456</td><td>0.2139</td><td>0.1391</td><td>0.2145</td></tr><tr><td>168-336</td><td>0.1156</td><td>0.1868</td><td>0.1166</td><td>0.1867</td><td>1.8665</td><td>1.1790</td><td>0.1204</td><td>0.1892</td><td>0.1195</td><td>0.1926</td><td>0.1419</td><td>0.2174</td><td>0.1378</td><td>0.2209</td></tr><tr><td>168-720</td><td>0.1293</td><td>0.2057</td><td>0.1294</td><td>0.2041</td><td>1.8548</td><td>1.1746</td><td>0.1306</td><td>0.2063</td><td>0.1307</td><td>0.2109</td><td>0.1565</td><td>0.2349</td><td>0.1565</td><td>0.2436</td></tr><tr><td>168-1440</td><td>0.1390</td><td>0.2114</td><td>0.1391</td><td>0.2119</td><td>1.8589</td><td>1.1721</td><td>0.1440</td><td>0.2168</td><td>0.1435</td><td>0.2157</td><td>0.1838</td><td>0.2567</td><td>0.1987</td><td>0.2838</td></tr><tr><td rowspan="4">\( ETTh_1 \)</td><td>168-168</td><td>0.1061</td><td>0.2533</td><td>0.1153</td><td>0.2666</td><td>0.1101</td><td>0.2594</td><td>0.1081</td><td>0.2548</td><td>0.1090</td><td>0.2560</td><td>0.1079</td><td>0.2549</td><td>0.1092</td><td>0.2569</td></tr><tr><td>168-336</td><td>0.1110</td><td>0.2625</td><td>0.1163</td><td>0.2698</td><td>0.1183</td><td>0.2729</td><td>0.1117</td><td>0.2641</td><td>0.1120</td><td>0.2652</td><td>0.1117</td><td>0.2652</td><td>0.1134</td><td>0.2636</td></tr><tr><td>168-720</td><td>0.1346</td><td>0.2908</td><td>0.1399</td><td>0.2971</td><td>0.1416</td><td>0.2994</td><td>0.1462</td><td>0.3057</td><td>0.1464</td><td>0.3068</td><td>0.1356</td><td>0.2930</td><td>0.1425</td><td>0.2995</td></tr><tr><td>168-1440</td><td>0.1343</td><td>0.2941</td><td>0.1352</td><td>0.2949</td><td>0.1551</td><td>0.3115</td><td>0.1497</td><td>0.3079</td><td>0.1502</td><td>0.3091</td><td>0.1544</td><td>0.3112</td><td>0.1572</td><td>0.3141</td></tr><tr><td rowspan="4">\( ETTh_2 \)</td><td>168-168</td><td>0.2174</td><td>0.3623</td><td>0.2402</td><td>0.3850</td><td>0.3250</td><td>0.4531</td><td>0.2572</td><td>0.3969</td><td>0.2567</td><td>0.3918</td><td>0.2472</td><td>0.3906</td><td>0.2509</td><td>0.3960</td></tr><tr><td>168-336</td><td>0.2237</td><td>0.3769</td><td>0.2477</td><td>0.3969</td><td>0.3312</td><td>0.4535</td><td>0.2587</td><td>0.4014</td><td>0.2647</td><td>0.4141</td><td>0.2550</td><td>0.3987</td><td>0.2652</td><td>0.4072</td></tr><tr><td>168-720</td><td>0.2356</td><td>0.3898</td><td>0.2475</td><td>0.3995</td><td>0.3382</td><td>0.4617</td><td>0.2619</td><td>0.4072</td><td>0.2714</td><td>0.4101</td><td>0.2698</td><td>0.4144</td><td>0.2744</td><td>0.4203</td></tr><tr><td>168-1440</td><td>0.2514</td><td>0.4070</td><td>0.2932</td><td>0.4341</td><td>0.3723</td><td>0.4841</td><td>0.2611</td><td>0.4136</td><td>0.2865</td><td>0.4225</td><td>0.2901</td><td>0.4358</td><td>0.4226</td><td>0.5147</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.1877</td><td>0.3166</td><td>0.2035</td><td>0.3317</td><td>0.2690</td><td>0.3864</td><td>0.2184</td><td>0.3445</td><td>0.2024</td><td>0.3323</td><td>0.2354</td><td>0.3555</td><td>0.2269</td><td>0.3594</td></tr><tr><td>168-336</td><td>0.1978</td><td>0.3278</td><td>0.2088</td><td>0.3401</td><td>0.3138</td><td>0.4215</td><td>0.2222</td><td>0.3540</td><td>0.2182</td><td>0.3476</td><td>0.2790</td><td>0.3919</td><td>0.2517</td><td>0.3820</td></tr><tr><td>168-720</td><td>0.1925</td><td>0.3255</td><td>0.2028</td><td>0.3351</td><td>0.3576</td><td>0.4573</td><td>0.2139</td><td>0.3479</td><td>0.2060</td><td>0.3392</td><td>0.3226</td><td>0.4319</td><td>0.2796</td><td>0.4044</td></tr><tr><td>168-1440</td><td>0.1786</td><td>0.3184</td><td>0.1823</td><td>0.3218</td><td>0.4523</td><td>0.5372</td><td>0.1969</td><td>0.3309</td><td>0.1896</td><td>0.3244</td><td>0.4198</td><td>0.5164</td><td>0.3417</td><td>0.4639</td></tr></table>


* 最好的结果以红色加粗突出显示。MSE 或 MAE 越低，表示预测效果越好。


通过消融实验，可以得出以下结论：(I) TPGN中设计的两个分支是合理的，它们分别捕捉了长期和短期信息，同时保留了各自的特点。在大多数情况下，单独使用一个分支会导致较差的结果，因为无法完整捕捉到关键特征。(II）在TPGN中，捕捉长期信息的分支更为重要。通过比较仅使用一个分支与同时使用两个分支的性能下降情况，可以观察到这一点。特别是对于像交通这种周期性强的数据，在某些任务中，仅使用长期信息捕捉分支就能取得较好的结果。这也与本章在第4.1节中提到的优先建模周期性的重要性相一致。(III）与具有更多门控的GRU和LSTM相比，PGN仅引入了一个门控，但仍能取得更好的性能。这有力地证明了PGN作为RNN新继任者的潜力。(IV）“TPGN-GRU/-LSTM/-MLP/-Attn”与基线结果的比较表明，TPGN框架具有强大的通用性和优越的性能。尽管它们的表现不及TPGN，但在某些任务中，它们甚至超越了之前的最先进时间序列预测方法。

# (2) 鲁棒性分析

为了评估TPGN的鲁棒性，本章按照MICN[26]和WITRAN[104]的实验设置，进行了实验，并引入了简单的白噪声注入。具体而言，本章从原始输入序列中随机选择了一个比例为  $\varepsilon$  的数据，并对所选数据应用了范围为  $[-2X_i, 2X_i]$  的随机扰动，

其中  $X_{i}$  表示原始数据。随后，注入噪声后的数据被用于训练，MSE 和 MAE 的度量结果记录在表4-3中。


表 4-3 TPGN 预测结果的鲁棒性实验



Table 4-3 Robustness experiments of TPGN's forecasting results.


<table><tr><td rowspan="2" colspan="2">预测任务 评价指标</td><td colspan="2">168-168</td><td colspan="2">168-336</td><td colspan="2">168-720</td><td colspan="2">168-1440</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>ε = 0%</td><td>0.2107</td><td>0.3264</td><td>0.2276</td><td>0.3446</td><td>0.2303</td><td>0.3550</td><td>0.2484</td><td>0.3775</td></tr><tr><td>ε = 1%</td><td>0.2116</td><td>0.3248</td><td>0.2277</td><td>0.3447</td><td>0.2311</td><td>0.3557</td><td>0.2484</td><td>0.3776</td></tr><tr><td>ε = 5%</td><td>0.2117</td><td>0.3270</td><td>0.2295</td><td>0.3464</td><td>0.2314</td><td>0.3553</td><td>0.2495</td><td>0.3783</td></tr><tr><td>ε = 10%</td><td>0.2142</td><td>0.3288</td><td>0.2303</td><td>0.3466</td><td>0.2332</td><td>0.3561</td><td>0.2497</td><td>0.3784</td></tr><tr><td rowspan="4">Traffic</td><td>ε = 0%</td><td>0.1196</td><td>0.1857</td><td>0.1156</td><td>0.1868</td><td>0.1293</td><td>0.2057</td><td>0.1390</td><td>0.2114</td></tr><tr><td>ε = 1%</td><td>0.1201</td><td>0.1861</td><td>0.1154</td><td>0.1869</td><td>0.1295</td><td>0.2059</td><td>0.1393</td><td>0.2120</td></tr><tr><td>ε = 5%</td><td>0.1219</td><td>0.1899</td><td>0.1176</td><td>0.1913</td><td>0.1296</td><td>0.2064</td><td>0.1439</td><td>0.2200</td></tr><tr><td>ε = 10%</td><td>0.1261</td><td>0.1964</td><td>0.1205</td><td>0.1960</td><td>0.1324</td><td>0.2119</td><td>0.1472</td><td>0.2241</td></tr><tr><td rowspan="4">ETTh1</td><td>ε = 0%</td><td>0.1061</td><td>0.2533</td><td>0.1110</td><td>0.2625</td><td>0.1346</td><td>0.2908</td><td>0.1343</td><td>0.2941</td></tr><tr><td>ε = 1%</td><td>0.1061</td><td>0.2534</td><td>0.1110</td><td>0.2628</td><td>0.1348</td><td>0.2908</td><td>0.1350</td><td>0.2944</td></tr><tr><td>ε = 5%</td><td>0.1067</td><td>0.2546</td><td>0.1111</td><td>0.2631</td><td>0.1355</td><td>0.2916</td><td>0.1407</td><td>0.2990</td></tr><tr><td>ε = 10%</td><td>0.1068</td><td>0.2549</td><td>0.1113</td><td>0.2630</td><td>0.1365</td><td>0.2932</td><td>0.1446</td><td>0.3023</td></tr><tr><td rowspan="4">ETTh2</td><td>ε = 0%</td><td>0.2174</td><td>0.3623</td><td>0.2237</td><td>0.3769</td><td>0.2356</td><td>0.3898</td><td>0.2514</td><td>0.4070</td></tr><tr><td>ε = 1%</td><td>0.2178</td><td>0.3629</td><td>0.2237</td><td>0.3770</td><td>0.2358</td><td>0.3900</td><td>0.2521</td><td>0.4086</td></tr><tr><td>ε = 5%</td><td>0.2180</td><td>0.3632</td><td>0.2240</td><td>0.3772</td><td>0.2358</td><td>0.3901</td><td>0.2521</td><td>0.4090</td></tr><tr><td>ε = 10%</td><td>0.2187</td><td>0.3639</td><td>0.2242</td><td>0.3775</td><td>0.2360</td><td>0.3904</td><td>0.2525</td><td>0.4097</td></tr><tr><td rowspan="4">Weather</td><td>ε = 0%</td><td>0.1877</td><td>0.3166</td><td>0.1978</td><td>0.3278</td><td>0.1925</td><td>0.3255</td><td>0.1786</td><td>0.3184</td></tr><tr><td>ε = 1%</td><td>0.1884</td><td>0.3184</td><td>0.1980</td><td>0.3282</td><td>0.1944</td><td>0.3273</td><td>0.1788</td><td>0.3186</td></tr><tr><td>ε = 5%</td><td>0.1886</td><td>0.3184</td><td>0.1987</td><td>0.3295</td><td>0.1950</td><td>0.3278</td><td>0.1788</td><td>0.3188</td></tr><tr><td>ε = 10%</td><td>0.1889</td><td>0.3185</td><td>0.1993</td><td>0.3320</td><td>0.1952</td><td>0.3281</td><td>0.1797</td><td>0.3197</td></tr></table>


* 不同的  $\varepsilon$  表示不同的噪声注入比例。


可以观察到，随着扰动比例的增加，预测结果中的MSE和MAE指标略有上升。这表明，TPGN在处理低噪声水平（最高达到  $10\%$  ）的数据时表现出良好的鲁棒性，并且在有效应对各种异常数据波动方面具有显著优势。

# (3) 参数敏感性分析

本章沿用了WITRAN[104]的方法，在本章提出的模型中，只有两个超参数。一个是隐藏单元的数量，记作  $dm$ ，这是许多模型中的常见超参数。它的值通过参数搜索和在验证集上的进一步验证来确定。在参数搜索过程中，可以观察到，不同的


表 4-4 训练集和验证集中数据集的分布 (均值和标准差)



Table 4-4 The distribution (Mean and STD) of dataset in the training and validation sets.


<table><tr><td rowspan="2">数据集
预测任务</td><td colspan="3">ECL</td><td colspan="3">Traffic</td><td colspan="3">ETTh1</td></tr><tr><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td></tr><tr><td>168-168</td><td>3425.7773±562.8469</td><td>3043.2100±382.1743</td><td></td><td>0.0288±0.0170</td><td>0.0341±0.0200</td><td></td><td>17.3383±8.5791</td><td>7.6739±4.2814</td><td></td></tr><tr><td>168-336</td><td>3426.0938±563.6643</td><td>3031.5738±362.8032</td><td>0</td><td>0.0287±0.0170</td><td>0.0340±0.0200</td><td>1</td><td>17.3711±8.6347</td><td>7.8227±4.3176</td><td>1</td></tr><tr><td>168-720</td><td>3423.0552±563.4796</td><td>3026.3346±343.3309</td><td></td><td>0.0287±0.0169</td><td>0.0339±0.0199</td><td></td><td>17.4107±8.7921</td><td>8.5642±4.0161</td><td></td></tr><tr><td>168-1440</td><td>3407.1474±558.3798</td><td>3017.0031±327.7298</td><td></td><td>0.0286±0.0169</td><td>0.0336±0.0197</td><td></td><td>17.1370±9.0535</td><td>10.0193±3.5586</td><td></td></tr><tr><td rowspan="6"></td><td rowspan="2">数据集
预测任务</td><td colspan="3">ETTh2</td><td colspan="3">Weather</td><td rowspan="2"></td><td rowspan="2"></td></tr><tr><td>训练集</td><td>验证集</td><td>norm</td><td>训练集</td><td>验证集</td><td>norm</td></tr><tr><td>168-168</td><td>29.0542±12.1271</td><td>20.8957±9.1261</td><td></td><td>0.3893±6.6630</td><td>1.3814±7.7366</td><td></td><td></td><td></td></tr><tr><td>168-336</td><td>28.8913±12.1396</td><td>21.2674±9.1471</td><td>0</td><td>0.3712±6.6834</td><td>1.5999±7.6813</td><td>0</td><td></td><td></td></tr><tr><td>168-720</td><td>28.4763±12.1533</td><td>22.7715±8.6228</td><td></td><td>0.3372±6.7363</td><td>2.1966±7.4464</td><td></td><td></td><td></td></tr><tr><td>168-1440</td><td>27.1838±11.6251</td><td>26.0480±7.1308</td><td></td><td>0.3601±6.8383</td><td>3.3196±6.9377</td><td></td><td></td><td></td></tr></table>

模型在同一任务上对最优  $dm$  值有显著差异。同样，即使是同一个模型，面对不同任务时，这种变化也依然存在。因此，本章的分析重点仅放在超参数 norm 上，因为它展示了显著的差异，并对模型的性能产生影响。

在第4.3小节中提到，参数norm应根据数据集来确定，这一点在相关工作[104]中也得到认可。为了验证在前期工作中选择的norm的合理性，本章对不同任务数据集之间的变化进行了统计分析，结果如表4-4所示。

通过对数据集的统计分析，可以发现训练集和验证集之间存在一些差异。这些差异是由于时间序列数据的固有特性所导致的，属于正常波动。如果训练集和验证集的方差大致处于同一范围内，则可以假设它们的波动大致一致。在这种情况下，训练集和验证集之间的数据分布没有显著差异，因此无需进行归一化。超参数norm应设置为0。

然而，当训练集和验证集之间的方差差异较大（大约是两倍或一半）时，表明两者的数据分布存在显著差异。在这种情况下，超参数norm应设置为1，以便更好地训练模型。

另外，天气数据集是一个特殊情况，因为它们包含负值，这导致其均值接近零，方差和均值之间存在显著差异。这对于天气数据来说是合理的。另一方面，交通数据集没有负值。因此，即使训练集和验证集的方差相似，当与均值结合分析时，它们之间的差异仍然可以观察到。

# (4）案例分析

为了突出TPGN在长程时间序列预测任务中的优势，本节随机选取了两个数据集——ECL数据集和Weather数据集，将TPGN的预测结果与基于均方误差（MSE）评估指标选出的第二优和第三优模型的预测结果进行对比。其中，ECL数据集各任务上TPGN、WITRAN（次优）和FiLM（第三优）的预测案例对比，分别如图4-6、图4-7和图4-8所示。Weather数据集各任务上TPGN、WITRAN（次优）和Basisformer（第三优）的预测案例对比，分别如图4-9、图4-10和图4-11所示。

在ECL数据集的长程预测任务中，如图4-6与图4-7和图4-8对比所示，TPGN展现出明显的优势。首先，其预测准确度更高，特别是在168-1440时间步的长时间预测任务中，TPGN的预测曲线与真实数据高度重合；WITRAN的表现仅稍显逊色，存在一些轻微的误差和周期偏移问题；而FiLM在长时间步时波动较为剧烈，误差较大。其次，TPGN具备更优的相位对齐能力，能够精确捕捉波峰和波谷的位置，避免了WITRAN和可FiLM能出现的相位偏移问题。此外，TPGN对数据的周期性特征捕捉能力更强，在168-720及更长时间步的任务中，预测波动趋势与真实数据更为一致。

在Weather数据集上的预测表现对比中，如图4-9、图4-10和图4-11对比所示，

![](images/dcdf59bddb2b9903b136fad41c6fc953fb98aa762fa38a010719f1c1faf6fafa.jpg)


![](images/3af82ec2891013df73593bbdb6929b9f8dd94beac45ef6c74b8eb4e96c5faa8a.jpg)



TPGN 168-720


![](images/57d5a66a750a06a4ff40cc797fda41514826fcf5198ac8baf2693af14c19218c.jpg)



TPGN 168-1440


![](images/3bf38b41f6097a4235b03d289c0476d5530c466c159d847a43fda9b4c930a156.jpg)



图4-6TPGN在数据集ECL中的所有任务预测案例



Fig 4-6 Forecasting cases of TPGN for all tasks in dataset ECL.


![](images/6fffb97b940d4e125e7c18b6279a2ec71f74a42f236abeeea0d575c6a35d6471.jpg)


![](images/43ad05030b25ec7f2e5b9fcf7dd73bce3002cc41e0f176ea441723258bcb772b.jpg)



WITRAN 168-720


![](images/12aaeda6f58e1c79013cb0373a6db5bfa36cd4454e927efa8e735d8ac4570ac8.jpg)



WITRAN 168-1440


![](images/08158f3f692569a9ce92bc700dcd9cc07384a0982227fb4bb4532ead015376c7.jpg)



图4-7 WITRAN在数据集ECL中的所有任务预测案例



Fig 4-7 Forecasting cases of WITRAN for all tasks in dataset ECL.


![](images/e0fdbc769c030fb3d1a786a0d3292fff696522f7da957951137abc91d71c7c4b.jpg)


![](images/605cb6518338d67be302b7ba67b2b5839af00f209057ac533f41e7c40474e540.jpg)


![](images/b81b376996de05e961053f3d2163884015f2092dbfb5788ef91164a426f37085.jpg)


![](images/9ae5bd1e48b71b389fc8a02c5f36c153a34a999d1f77c92137907dcf1d8e7c70.jpg)



图4-8 FiLM在数据集ECL中的所有任务预测案例



Fig 4-8 Forecasting cases of FiLM for all tasks in dataset ECL.


![](images/9c7141cfc58d56a7130d513b23857f2de07ac9c1e560b92256e35ce58deb0089.jpg)


![](images/71cbe6ec3139473c620a2ef236fdde9316261b96d878f007f449cf4732d987fe.jpg)


![](images/d853fa3c98e291ca943fe23446627424075e5ccf76f2ce6778432c77edc7d76f.jpg)


![](images/1543931f985e3b6db1da77c1203157fa251d2e70f414bdfab3ef739451095612.jpg)



图4-9TPGN在数据集Weather中的所有任务预测案例



Fig 4-9 Forecasting cases of TPGN for all tasks in dataset Weather.


![](images/c8431e72bc036192f8812b1c294c300240e13db75af627033de50cda5d6af338.jpg)


![](images/f9f0eb61eca3647f3db85104f5a6cd709631160048f03a409b8b670147f0a67e.jpg)


![](images/718210eeb09bd7a18e2d63bbe5489fc230cfcb8c5a05054ac50ef3b92f6ef001.jpg)


![](images/1c0607f99d09df9f90ce45d3259e078a9d86e59a510ed1d75ca4cf1bdff85f99.jpg)



图4-10 WITRAN在数据集Weather中的所有任务预测案例



Fig 4-10 Forecasting cases of WITRAN for all tasks in dataset Weather.


![](images/19e4b8897aa5562cda81d7a271f134e33e2b09a25c1e9536af32b9b1f4a39d25.jpg)


![](images/4e460774856e729d43cdf9561223917ca179b4a9c48eb4144cfcd9fd614a0c5b.jpg)


![](images/b8375bc5ac70fa6b610c11bb494d5f8f6a1456e66a042fd833f7b979bc712301.jpg)


![](images/7f4a8dfbd35c5ba84b949eaae005ba5db095e26d0e8ccbb057c5f5c0001a2e05.jpg)



图4-11 Basisformer在数据集Weather中的所有任务预测案例



Fig 4-11 Forecasting cases of Basisformer for all tasks in dataset Weather.


TPGN展现了卓越的预测能力，其预测曲线与真实值较为贴合，尤其在长时间步任务——168-720和168-1440上，能够较好地捕捉数据的周期性波动和趋势变化。尽管WITRAN在某些任务有一定可取之处，但其长期预测仍明显存在偏差，未能准确跟随真实趋势。相比之下，Basisformer的表现则较为欠佳，其预测曲线与真实值严重偏离，尤其在较长时间步任务中，波动模式与真实数据相差甚远，几乎无法提供可靠的趋势预测，凸显其在复杂时间序列建模中的不足。

综合来看，上述比较清晰地展示了本章提出的方法在预测结果上的优越性——TPGN在长程预测任务中具备更高的精度、更好的相位对齐能力、更强的周期性捕捉能力以及更稳定的长期预测表现；并且明确无误地再次确认了TPGN在各个领域中的SOTA性能。

# 4.5 本章小结

本章提出了一种新颖且通用的范式——并行门控网络（Parallel Gated Network, PGN）。PGN具备  $\mathcal{O}(1)$  级的信息传递路径和并行计算能力，在保持  $\mathcal{O}(T)$  理论（时间和空间）复杂度的同时，实现了更快的运行速度。为进一步增强PGN在长程时间序列预测任务中的应用效果，本章引入了一种新的时间建模框架——时序并行门控网络（Temporal PGN, TPGN），整个预测框架的时间复杂度为  $\mathcal{O}(\sqrt{T})$  ，空间复杂度为  $\mathcal{O}(T)$  。通过引入双分支结构，分别建模长期和短期信息，TPGN有效地捕捉序列的周期性模式以及局部与全局语义信息，同时保留各自的特性。在五个基准数据集上的实验结果表明，本章基于PGN构建的TPGN框架在性能和效率上均达到了最优水平。这些结果进一步验证了PGN作为新范式在长程时间序列预测任务中的优秀潜质。

# 5 变量完全独立建模的多变量长程时间序列预测方法

第三章和第四章主要探讨了如何充分捕获复杂时间模式以及减少信息在传递过程中的损失，这两个关键问题可归结为时间维度上的建模挑战。在实际应用场景中，研究对象通常不止一个，因此多变量时间序列分析更契合广泛的需求，具有更高的应用价值。然而，不同变量往往呈现出各自独特的时间模式，即异质性，这给多变量时间序列的准确预测带来了巨大挑战。现有方法要么难以有效处理变量间的差异性，要么计算复杂度过高，限制了其实际应用能力。

基于以上分析，本章提出了一种新颖的变量完全独立、又称通道完全独立（Separate Channel Independent, SCI）的建模范式。SCI 通过为每个变量分配独立参数，实现对各变量信息的差异化处理，从而全面解决异质性变量之间的相互影响。

此外，为更好地捕获时间维度的模式，并尽可能缩短信息传递路径以降低信息损失，本章提出了一种基于线性变换的双分支（Dual-Branch, DB）时间建模架构。DB采用两层线性变换，先聚合原始信息生成局部表示，再进一步聚合局部表示形成全局表示，从而实现对周期性和趋势性模式、长期和短期模式以及全局和局部模式的全面建模，同时实现O(1)的信息传递路径。

通过系统性地整合SCI建模范式与基于线性变换的DB时间建模架构，本章提出了一种专门针对异质性多变量时间序列的长程预测模型——SCILINE。在五个真实场景的基准数据集上进行的验证性实验表明，SCILINE在处理变量间异质性方面表现出色，并在预测性能和运行效率上都展现了卓越的能力。

# 5.1 引言

多变量时间序列是一种常见的时间序列数据类型，其中路网多节点交通流量数据即为一种典型实例。异质性是多变量时间序列的重要性质之一，其指的是在同一时间段内各变量之间关系的显著差异。例如，气象数据中温度通常表现出平稳且具有周期性的变化，而风速则可能呈现出高度波动性，且周期性特征较弱。

由于异质性的存在，多变量时间序列建模面临巨大挑战。异质性导致多变量建模过程中各变量相同时段的时间特性产生冲突，显著影响模型的信息提取效能。例如，当某些变量具有相反趋势时，直接融合将会导致各自的变化特性混淆，降低模式识别的能力；而变化趋势相同的变量的叠加，也可能会由于幅度差异导致其各自的局部特性被全局特性所掩盖，进而丢失关键信息。

因此，为更好地捕获各变量时间模式的独特性，必须在建模时充分考虑异质性

对多变量时间序列建模的影响，以增强有效信息的提取能力。本章所聚焦的任务是具有显著异质性的多变量长程时间序列的预测。从变量建模维度对现有方法进行分类，主要可分为以下四类：基于变量（通道）融合的方法（Channel Dependent, CD）的方法[2,22]，如图5-1(a)所示；基于变量（通道）独立的方法（Channel Independent, CI）的方法[27,39]，如图5-1(b)所示；基于注意力机制的方法[60,61]；以及基于图神经网络（GNN）的方法[59]。

![](images/e4ba002d7b2ed8a3bd467d76140dbb53f0da591cbc2516d392282c9698d982a6.jpg)



(a) 变量融合的建模方式


![](images/13491dcf0ea95ccf9111862709f960be51508e4d3f5113a6fe84a8c8be4f93f0.jpg)



(b) 变量独立 (CI) 的建模方式


![](images/6614826f816908baf1023291cf4f3a259780d38b873add3328f23f1d5e8cc3d7.jpg)



(c) 变量完全独立（SCI）的建模方式



图5-1 对于变量建模三种方法的对比示意图



Fig. 5-1 Comparison diagram of three methods for variable modeling.


然而，这些方法在处理变量异质性方面仍面临显著挑战：基于CD的方法将多变量特征直接映射为混合表示，导致变量间直接融合形成干扰，影响预测精度；基于CI的方法虽然在模型前向计算中对各变量进行独立处理，但由于参数在变量间共享，反向传播时模型仍倾向于学习变量的一致性模式，导致部分变量差异性捕获不足；基于注意力机制的方法和基于GNN的方法则面临高达  $\mathcal{O}(N^2)$  的计算复杂度问题，限制了其在大规模多变量时间序列预测场景下的应用。

为克服以上局限性，本章提出了变量（通道）完全独立（Separate Channel Independent, SCI）范式，如图5-1(c)所示。与基于CI的方法不同，SCI能够为每个变量分配独立的参数，确保前向计算和反向传播过程中参数的完全独立性。该范式设计具有以下优势：

(1) 仅对关键层使用SCI范式，其他层依然使用CI方法，使得模型在总体上依然能保持独立的建模方式，并且开销更低；

(2) 有效消除变量异质性所带来的干扰;

(3) 保持  $\mathcal{O}(N)$  的复杂度, 显著优于基于注意力机制和基于 GNN 的方法;

(4) 增强模型的可解释性，便于分析每个变量的变化模式。

SCI能够有效处理通道差异性，但对于时间序列来说，时间维度的信息提取本身也至关重要。如第一、三、四章所述，长程时间序列预测任务在时间维度建模方面需要重点关注四个关键要素：（1）周期性模式和趋势性模式[51,104,105]，（2）长期模式和短期模式[26,104,105]，（3）全局模式和局部模式，（4）较短的信息传递路

径[56,108]。

![](images/7fad14c7eb8828aa60208276e2fb86ce556c627af89e77ab5518ea65cb4866b2.jpg)



(a) 趋势性提取分支



频率


![](images/91a7986e9253b56e6a8227ce199f9df498b09251ace9421ac3292911a300f6a5.jpg)



(b) 周期性提取分支



图5-2 双分支（DB）时间建模架构示意图



Fig 5-2 Diagram of the Dual-Branch (DB) temporal modeling framework.


基于以上分析，本章提出了一种基于线性变换的双分支（Dual-Branch, DB）时间建模架构。该架构将时间序列数据从一维重排为二维，以从长期和短期两个不同时间尺度上捕获周期性和趋势性模式（如图5-2所示）。DB框架中的每个分支通过两层线性变换实现  $\mathcal{O}(1)$  的信息传递路径，在减少信息损失的同时提高了运行效率。具体而言，第一层线性变换用于学习局部表示，第二层线性变换则聚合局部特征从而形成全局表示。此外，该框架在时间信息建模上实现了  $\mathcal{O}(\sqrt{T})$  的理论复杂度。

通过将SCI范式与DB框架相结合，本章提出了一种专门用于解决多变量异质性的长程多变量时间序列预测模型SCILINEar。总结来说，本章的主要贡献如下：

(1) 提出了变量完全独立建模新范式 SCI: SCI 通过为每个变量分配独立的参数, 消除了变量异质性带来的影响, 确保了建模的有效性和高效性。这种设计专门用于解决多变量的异质性。

(2) 提出了基于线性变换的双分支时间建模架构 DB: DB 能够从长期和短期的不同时间尺度上对周期性和趋势性模式进行建模，同时实现  $\mathcal{O}(1)$  的信息传递路径，从而减少信息损失以提升表示学习能力。

(3) 提出了新颖的长程多变量时间序列预测模型 SCILINE: 通过将 SCI 范式与基于线性的 DB 架构组合形成了 SCILINE。效率方面, 在时间建模中实现了  $\mathcal{O}(T)$  的复杂度, 在变量建模中实现了  $\mathcal{O}(N)$  的复杂度; 性能方面, 通过在真实场景下（能源、气象和交通）的五个基准数据集上展开验证性实验, 证明了 SCILINE 在多变量长程时间序列预测任务中处理变量间异质性的出色性能。

# 5.2 基于变量完全独立建模的线性预测方法

多变量时间序列预测任务是基于过去  $T$  步的输入  $\mathbf{X} \in \mathbb{R}^{T \times N}$ ，预测未来  $F$  步的输出  $\hat{\mathbf{Y}} \in \mathbb{R}^{F \times N}$ ，其中  $N$  表示时间序列中的变量数量。本节提出了一种新颖的变量完全独立（SCI）的建模方式，确保模型在前向计算和反向传播训练过程中每个变量的参数完全独立，解决了变量间存在的异质性造成的噪声干扰。与此同时，本节提出了一种基于线性变换的双分支（DB）时间建模框架，能够同时捕获时间建模的三个关键要素，以准确、全面地提取每个变量上的时间信息。通过SCI建模方式和DB时间建模框架的结合，形成了变量完全独立的线性预测模型（SCILinear），其模型架构图如图5-3所示。

![](images/6f9f90ad6e39199cdc98fadcf9638f46a6e4136b7ea6fd728f8f072e0a753ce5.jpg)



图5-3 SCILINE模型架构图



Fig 5-3 Overall architecture of SCILINE.


# 5.2.1 输入模块

为了便于模型学习有效特征，首先需要对原始输入时间序列  $\mathbf{X}$  进行归一化操作。参考Transformer等方法[61,108,109]的归一化方式，该过程可以形式化如公式

(5-1) 所示:

$$
\boldsymbol {\mu} = \frac {1}{T} \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t}, \tag {5-1a}
$$

$$
\boldsymbol {\sigma} ^ {2} = \frac {1}{T} \sum_ {t = 1} ^ {T} \left(\boldsymbol {x} _ {t} - \boldsymbol {\mu}\right) ^ {2}, \tag {5-1b}
$$

$$
\mathbf {X} _ {\mathrm {1 D}} = \left\{ \begin{array}{l l} \mathbf {X} & \text {n o r m} = 0 \\ (\mathbf {X} - \boldsymbol {\mu}) / \sigma , & \text {n o r m} = 1 \end{array} , \right. \tag {5-1c}
$$

其中， $\pmb{\mu} \in \mathbb{R}^{N}$  表示序列各变量的均值向量， $\pmb{\sigma}$  则表示序列各变量的标准差向量。 $\mathbf{X}_{\mathrm{ID}} \in \mathbb{R}^{T \times N}$  表示归一化后的序列，超参数 norm 需要根据不同数据集的特性进行确定。

随后，为直接捕获序列的周期特性，需要将归一化后的输入  $\mathbf{X}_{\mathrm{ID}}$  根据周期数  $P$  从一维转置到二维排布。同时，为给每个变量的每个时间步引入时间戳信息，需要将原始时间戳  $\mathbf{TF}_{\mathrm{hist}}$  在  $N$  个通道上进行复制，并进行相应的二维转置。最终，将转置后的时间戳信息与二维输入拼接，形成模型的最终输入。该过程可形式化表达如公式（5-2）所示：

$$
\mathcal {X} _ {\mathrm {2 D}} = \operatorname {R e s h a p e} \left(\mathbf {X} _ {\mathrm {1 D}}\right), \tag {5-2a}
$$

$$
\mathcal {T} F _ {\text {h i s t}} = \operatorname {R e p e a t} \left(\mathbf {T F} _ {\text {h i s t}}\right), \tag {5-2b}
$$

$$
\mathfrak {T} F _ {\text {h i s t}} ^ {2 \mathrm {D}} = \operatorname {R e s h a p e} \left(\mathfrak {T} F _ {\text {h i s t}}\right), \tag {5-2c}
$$

$$
\mathfrak {I} n _ {\mathrm {2 D}} = \left[ \mathcal {X} _ {\mathrm {2 D}}, \mathcal {T} F _ {\text {h i s t}} \right], \tag {5-2d}
$$

其中  $\mathcal{X}_{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N \times 1}$  表示序列从一维转置到二维后的张量，Reshape() 表示转置操作。 $R$  为时间序列转置后在时间维度上的行数， $P$  为周期数，即时间序列转置后在时间维度上的列数。 $\mathcal{TF}_{\mathrm{hist}} \in \mathbb{R}^{T \times N \times D}$  表示在  $N$  个通道上复制后的时间戳信息，Repeat() 表示复制操作。 $\mathcal{TF}_{\mathrm{hist}}^{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N \times D}$  表示时间戳二维化后的结果， $D$  为时间戳特征的维度。 $[\cdot]$  表示拼接（Concat）操作， $\mathcal{J}n_{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N \times (D + 1)}$  表示模型的最终输入。

# 5.2.2 变量完全独立的建模方式

基于变量独立（CI）建模的方法[27,39,41]虽然在模型前向计算中实现了各变量的独立处理，但由于参数在变量间共享，在反向传播训练时，模型仍倾向于学习变量间的统一模式。这种设计存在两个主要问题：（1）削弱了变量独立的核心理

念，无法充分保留各变量的独特特性；（2）一定程度上，在变量间引入了噪声干扰，影响预测精度。

为解决这些问题，本小节提出了一种新颖的变量完全独立（Separate Channel Independent, SCI）的建模方法。与CI建模方式不同，SCI在变量间使用完全独立的参数，确保模型在前向计算和反向传播训练过程中各变量的特性被独立捕获，并有效解决了变量间异质性造成的噪声干扰问题。

# 5.2.3 变量完全独立的双分支时间建模框架

为分别捕获时间序列中的周期性和趋势性特征，本节提出双分支（DB）时间建模框架。两个分支分别用于提取特定的时间特征：一个分支专注于周期性特征，另一个分支专注于趋势性特征。考虑到线性层在信息传递路径（ $\mathcal{O}(1)$ ）和处理时间序列复杂度（ $\mathcal{O}(T)$ ）方面的优势，每个分支均采用两层线性变换实现。

为消除变量间存在的异质性，DB时间建模框架采用SCI建模方式，即对每个变量使用独立参数的DB框架进行建模。第  $n$  个变量上的第一层线性变换计算过程如公式（5-3）所示：

$$
\mathbf {H} _ {1} ^ {n} = \operatorname {L i n e a r} _ {\text {t r e n d , l o c a l}} ^ {n} \left(\mathcal {J} n _ {2 \mathrm {D}} ^ {n}\right), \tag {5-3a}
$$

$$
\mathbf {H} _ {2} ^ {n} = \operatorname {L i n e a r} _ {\text {p e r i o d}, \text {l o c a l}} ^ {n} \left(\mathcal {I} n _ {2 \mathrm {D}} ^ {n}\right), \tag {5-3b}
$$

其中， $\mathfrak{I}n_{2\mathrm{D}}^{n}\in \mathbb{R}^{R\times P\times (D + 1)}$  表示第  $n$  个变量的输入。Linear $_{\mathrm{trend,local}}^{n}(\cdot)$  沿着  $\mathfrak{I}n_{2\mathrm{D}}^{n}$  中  $R$  的维度进行展平，将输入维度  $P\times (D + 1)$  映射为  $\mathbf{H}_1^n\in \mathbb{R}^{R\times dk}$ ，通过压缩周期内的信息来提取长期的趋势性特征。而 Linear $_{\mathrm{period,local}}^{n}(\cdot)$  则沿着  $\mathfrak{I}n_{2\mathrm{D}}^{n}$  中  $P$  的维度进行展平，将输入维度  $R\times (D + 1)$  映射为  $\mathbf{H}_2^n\in \mathbb{R}^{P\times dk}$ ，通过压缩长期的趋势性信息来提取周期性特征。 $dk$  表示第一层线性变换的局部特征维度。

为了将第一层提取到的局部特征进一步聚合成全局表示，需要通过第二层线性变换，处理方式与第一层类似，形式化表达如公式（5-4）所示：

$$
\boldsymbol {H} _ {1} ^ {n} = \operatorname {L i n e a r} _ {\text {t r e n d , g l o b a l}} ^ {n} \left(\mathbf {H} _ {1} ^ {n}\right), \tag {5-4a}
$$

$$
\boldsymbol {H} _ {2} ^ {n} = \operatorname {L i n e a r} _ {\text {p e r i o d , g l o b a l}} ^ {n} \left(\mathbf {H} _ {2} ^ {n}\right), \tag {5-4b}
$$

其中， $\operatorname{Linear}_{\text {trend,global }}^{n}(\cdot)$  沿着  $\mathbf{H}_1^n$  中  $P$  的维度，将局部特征维度  $dk$  进一步映射为  $\pmb{H}_1^n \in \mathbb{R}^{dm}$ ，从而得到趋势性特征的全局表示。而  $\operatorname{Linear}_{\text {period,global }}^{n}(\cdot)$  则沿着  $\mathbf{H}_2^n$  中  $R$  的维度，将局部特征维度  $dk$  进一步映射为  $\pmb{H}_2^n \in \mathbb{R}^{dm}$ ，以获得周期性特征的全局表示。 $dm$  表示第二层线性变换的全局特征维度。

最后，通过将趋势性特征的全局表示  $H_1^n$  与周期性特征的全局表示  $H_2^n$  在全局特征维度上进行拼合操作，得到最终的全局表示  $H^n$  。处理过程的形式化表达如公式（5-5）所示：

$$
\boldsymbol {H} ^ {n} = \left[ \boldsymbol {H} _ {1} ^ {n}, \boldsymbol {H} _ {2} ^ {n} \right], \tag {5-5}
$$

其中，[·]表示拼合操作， $H^n \in \mathbb{R}^{2dm}$  表示全局表示。

# 5.2.4 预测模块

预测模块将双分支时间建模框架的输出结果映射为预测值，其计算过程如公式（5-6）所示：

$$
\hat {Y} ^ {n} = \operatorname {L i n e a r} ^ {n} \left(\boldsymbol {H} ^ {n}\right), \tag {5-6}
$$

其中， $\hat{Y}^n \in \mathbb{R}^F$  代表第  $n$  个变量的预测向量， $F$  为预测步长。

# 5.2.5 变量完全独立建模方式的等价优化

虽然SCI建模方式有效解决了变量间异质性造成的噪声干扰问题，同时保持了变量独立的核心理念，但在模型信息的捕获过程中，若对每一层都采用SCI建模方式，会导致复杂度比CI方法高  $N$  倍。为平衡模型性能与计算效率，本小节提出了一种SCI的等价优化方案，能够在保持SCI特性的同时显著降低参数量。

该方案的核心思想是：仅在关键层使用SCI建模方式，而在其他层采用CI建模方式。这种设计具有以下优势：（1）在关键层保持变量间的完全独立性，确保模型能够有效捕获各变量的独特特性；（2）通过减少SCI层的数量，整体参数量与原始SCI建模方式相比大大降低，显著提高了模型的计算效率；（3）在保证模型性能的同时，便于模型扩展和实际部署。

# 5.2.6 理论复杂度分析

本节将从时间和变量两个维度对SCILINE的理论复杂度进行详细分析。

(1) 时间维度建模：在时间维度建模方面，理论复杂度分析主要针对DB时间建模框架和预测模块。

DB 时间建模框架的每个分支采用两层线性变换：第一层沿二维输入的一个维度进行信息压缩，第二层沿另一个维度进行压缩。由于线性变换的复杂度与其处理的序列长度呈线性关系，每个分支的复杂度为  $\mathcal{O}(R) + \mathcal{O}(P)$  。考虑到  $R \times P = T$  ，其中  $T$  为历史序列长度，DB 时间建模框架的整体（时间和空间）复杂度为  $\mathcal{O}(\sqrt{T})$  。

预测模块仅使用一层线性变换直接进行预测，其复杂度与未来序列长度  $F$  呈线性关系，因此预测模块的（时间和空间）复杂度为  $\mathcal{O}(F)$ 。

# (2) 变量维度建模:

在变量维度建模上，基于CI的建模方式，由于不考虑变量之间的相互作用，因此参数的复杂度与变量个数  $N$  无关，呈  $\mathcal{O}(1)$  关系，但由于也需要在  $N$  个通道上进行计算，因此复杂度为  $\mathcal{O}(N)$  。SCI的等价优化建模方式在关键层为  $N$  个通道分配独特的参数，仅在这一层的参数的复杂度上与变量个数  $N$  呈  $\mathcal{O}(N)$  线性关系。而整体的理论（时间和空间）复杂度上，与基于CI的建模方法一致，均为  $\mathcal{O}(N)$  。

# 5.3 实验评估

为全面评估本章所提出的SCILinear方法的性能，本节将在四个公开数据集上进行广泛实验，并对实验结果进行详细分析。

# 5.3.1 基线方法

本节的实验选取了十个具有代表性的方法进行比较，涵盖了不同的架构：（1）基于线性变换的方法：TimeMixer[40]、FITS[41]、SparseTSF[63]；（2）基于CNN方法：TimesNet[51]和ModernTCN[53]；（3）基于注意力机制的方法：PatchTST[27]，Basisformer[107]，iTransformer[61]；（4）基于GNN方法：FourierGNN[59]；（5）其他方法：Koopa[110]。

需要注意的是，早期一些知名的方法，包括Transformer[22]、Informer[2]、Autoformer[55]、Pyraformer[56]、FEDformer[54]、DLinear[39]和Crossformer[60]，在性能上均被本节所选择的基线方法显著超越。因此，这些方法未被纳入本节的基线比较方法中。

# 5.3.2 实验设置

本节聚焦于能源和天气领域的四个异质性较强的公开数据集展开实验，同时在一个相关性较强的公开数据集上进行反向验证。为验证SCILINE的性能，参考Pyraformer[56]、WITRAN[104]和TPGN[108]的实验设置，将输入序列长度固定为168步，设置168、336、720和1440四种预测步长。所有模型均基于PyTorch[102]实现，并在NVIDIA RTX A4000 16GB GPU上进行了实验。

SCILinear及所有基线模型均使用L2损失函数（MSE）和Adam优化器[103]进行训练，初始学习率设为  $10^{-3}$ ，批量大小（Batch size）为32。最大训练轮数设定

为25，若验证集的L2损失在连续5轮内未下降，则提前停止训练。

为确保公平比较，本节为所有模型的公共参数设定了相同的搜索空间：具体而言：(1) 设定模型的隐藏维度  $dk$ 、 $dm$  的范围为  $\{2,4,8,16,32,64,128,256,512,1024\}$ ; (2) 设定模型编码器和解码器的层数的范围为  $\{1,2,3\}$ ; (3) 设定注意力机制头数的范围固定为 8。对于各模型特有的超参数，参考其原始论文进行确定。所有模型的最佳参数均基于验证集上的最小损失函数值选择，以确保各模型在相同条件下达到最优性能。

# 5.3.3 预测性能分析

为了全面评估不同基线模型在多变量长程时间序列预测任务中的表现，本章在  $ECL$  、  $ETTh_{1}$  、  $ETTh_{2}$  以及Weather四个数据集上开展了正向验证实验，在Traffic数据集上进行了反向验证实验，实验结果汇总于表5-1。实验选用均方误差（MSE）和平均绝对误差（MAE）作为评价指标，数值越低表示预测精度越高。

通过对比各模型的预测结果可以发现，所提出的模型SCILINE具有较强的适应能力，能够应对不同的预测场景，并在应对于异质性的整体性能上超过了所有基线方法，实现最佳的表现。而对于相关性强的数据集上较差的实验效果，反向验证了本方法主要适用于异质性的处理，对于相关性的处理仍存在局限性。

具体而言，与基线方法相比，SCILinear在ECL数据集上的MSE提升幅度介于  $3.02\%$  至  $18.80\%$  之间，平均提升  $9.40\%$  ，而在MAE指标上则实现了  $0.75\%$  至 $12.85\%$  不等的性能提升，平均提高了  $6.07\%$  。在  $ETTh_{1}$  数据集上，SCILinear在MSE上的提升范围为  $5.60\%$  到  $21.69\%$  ，平均提升达到  $10.77\%$  ，同时在MAE上实现了  $0.56\%$  至  $13.06\%$  的提升，平均提高了  $5.42\%$  。而在  $ETTh_{2}$  数据集中，SCILinear的MSE提升幅度介于  $0.19\%$  和  $19.30\%$  之间，平均提升  $7.17\%$  ，而MAE的提升范围则为  $-3.35\%$  至  $13.09\%$  ，平均提高  $2.17\%$  。对于Weather数据集，MSE的提升幅度在  $-0.36\%$  至  $13.87\%$  之间，平均提升  $7.03\%$  ，而MAE方面则介于  $-3.79\%$  至  $5.90\%$  之间，平均提高  $1.61\%$  。

进一步从模型整体性能角度分析，SCILINE在各项任务中相较于对比的基线方法，在MSE上的提升幅度为  $4.42\%$  至  $11.21\%$  之间，平均提升  $8.59\%$  ，而在MAE指标上，提升范围为  $1.18\%$  至  $6.58\%$  ，平均提高  $3.82\%$  。上述结果充分验证了SCILINE在异质性的多变量长程时间序列预测任务中的卓越性能和广泛适用性。


表 5-1 多变量长程时间序列预测结果



Table 5-1 Multivariate Long-range forecasting results.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">SCILinear</td><td colspan="2">SparseTSF</td><td colspan="2">TimeMixer</td><td colspan="2">ModernTCN</td><td colspan="2">FITS</td><td colspan="2">iTransformer</td><td colspan="2">Basisformer</td><td colspan="2">FourierGNN</td><td colspan="2">Koopa</td><td colspan="2">TimesNet</td><td colspan="2">PatchTST</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.1532</td><td>0.2459</td><td>0.1620</td><td>0.2493</td><td>0.1551</td><td>0.2445</td><td>0.1672</td><td>0.2652</td><td>0.1726</td><td>0.2630</td><td>0.1545</td><td>0.2453</td><td>0.1764</td><td>0.2731</td><td>0.1841</td><td>0.2841</td><td>0.1665</td><td>0.2620</td><td>0.2059</td><td>0.3036</td><td>0.1543</td><td>0.2433</td></tr><tr><td>168-336</td><td>0.1742</td><td>0.2670</td><td>0.1817</td><td>0.2699</td><td>0.1792</td><td>0.2674</td><td>0.1875</td><td>0.2855</td><td>0.1935</td><td>0.2825</td><td>0.1774</td><td>0.2698</td><td>0.2072</td><td>0.3013</td><td>0.2046</td><td>0.3052</td><td>0.1866</td><td>0.2820</td><td>0.2144</td><td>0.3095</td><td>0.1766</td><td>0.2663</td></tr><tr><td>168-720</td><td>0.2114</td><td>0.2985</td><td>0.2229</td><td>0.3039</td><td>0.2208</td><td>0.3028</td><td>0.2178</td><td>0.3097</td><td>0.2346</td><td>0.3134</td><td>0.2173</td><td>0.3050</td><td>0.2535</td><td>0.3345</td><td>0.2432</td><td>0.3385</td><td>0.2318</td><td>0.3194</td><td>0.2614</td><td>0.3391</td><td>0.2203</td><td>0.3026</td></tr><tr><td>168-1440</td><td>0.2773</td><td>0.3504</td><td>0.3031</td><td>0.3634</td><td>0.2958</td><td>0.3603</td><td>0.2926</td><td>0.3603</td><td>0.3174</td><td>0.3714</td><td>0.3784</td><td>0.4257</td><td>0.3279</td><td>0.3839</td><td>0.3008</td><td>0.3845</td><td>0.3252</td><td>0.3835</td><td>0.3194</td><td>0.3740</td><td>0.2949</td><td>0.3612</td></tr><tr><td rowspan="4">ETTh1</td><td>168-168</td><td>0.4537</td><td>0.4674</td><td>0.4828</td><td>0.4740</td><td>0.4766</td><td>0.4782</td><td>0.5015</td><td>0.5009</td><td>0.4732</td><td>0.4699</td><td>0.4756</td><td>0.4824</td><td>0.4912</td><td>0.4919</td><td>0.5273</td><td>0.5207</td><td>0.4890</td><td>0.4886</td><td>0.5578</td><td>0.5367</td><td>0.4743</td><td>0.4772</td></tr><tr><td>168-336</td><td>0.5128</td><td>0.5157</td><td>0.5386</td><td>0.5151</td><td>0.5374</td><td>0.5153</td><td>0.5704</td><td>0.5447</td><td>0.5310</td><td>0.5080</td><td>0.5397</td><td>0.5258</td><td>0.5557</td><td>0.5333</td><td>0.5890</td><td>0.5604</td><td>0.5577</td><td>0.5319</td><td>0.7439</td><td>0.6254</td><td>0.5368</td><td>0.5179</td></tr><tr><td>168-720</td><td>0.6335</td><td>0.5935</td><td>0.6833</td><td>0.6045</td><td>0.6882</td><td>0.6111</td><td>0.7104</td><td>0.6331</td><td>0.6719</td><td>0.5952</td><td>0.7068</td><td>0.6280</td><td>0.6968</td><td>0.6207</td><td>0.6916</td><td>0.6239</td><td>0.7308</td><td>0.6348</td><td>0.7631</td><td>0.6591</td><td>0.6783</td><td>0.6071</td></tr><tr><td>168-1440</td><td>0.7082</td><td>0.6394</td><td>0.7949</td><td>0.6710</td><td>0.9182</td><td>0.7288</td><td>0.8672</td><td>0.7266</td><td>0.7793</td><td>0.6588</td><td>0.8607</td><td>0.7067</td><td>0.8268</td><td>0.6892</td><td>0.8350</td><td>0.6936</td><td>0.9173</td><td>0.7316</td><td>0.8857</td><td>0.7252</td><td>0.7863</td><td>0.6704</td></tr><tr><td rowspan="4">ETTh2</td><td>168-168</td><td>0.2664</td><td>0.3511</td><td>0.2712</td><td>0.3492</td><td>0.2668</td><td>0.3495</td><td>0.2935</td><td>0.3657</td><td>0.2640</td><td>0.3414</td><td>0.2751</td><td>0.3540</td><td>0.2819</td><td>0.3594</td><td>0.3284</td><td>0.4030</td><td>0.2725</td><td>0.3569</td><td>0.3083</td><td>0.3773</td><td>0.2688</td><td>0.3490</td></tr><tr><td>168-336</td><td>0.3141</td><td>0.3902</td><td>0.3196</td><td>0.3803</td><td>0.3202</td><td>0.3842</td><td>0.3464</td><td>0.3977</td><td>0.3117</td><td>0.3743</td><td>0.3287</td><td>0.3895</td><td>0.3372</td><td>0.3970</td><td>0.3733</td><td>0.4378</td><td>0.3248</td><td>0.3924</td><td>0.3514</td><td>0.4100</td><td>0.3230</td><td>0.3848</td></tr><tr><td>168-720</td><td>0.3969</td><td>0.4404</td><td>0.4048</td><td>0.4327</td><td>0.4081</td><td>0.4392</td><td>0.4099</td><td>0.4385</td><td>0.3896</td><td>0.4216</td><td>0.4154</td><td>0.4408</td><td>0.4241</td><td>0.4484</td><td>0.5200</td><td>0.5292</td><td>0.4205</td><td>0.4516</td><td>0.4309</td><td>0.4541</td><td>0.4078</td><td>0.4367</td></tr><tr><td>168-1440</td><td>0.5457</td><td>0.5366</td><td>0.6043</td><td>0.5469</td><td>0.5947</td><td>0.5447</td><td>0.6047</td><td>0.5440</td><td>0.5704</td><td>0.5269</td><td>0.6200</td><td>0.5524</td><td>0.6881</td><td>0.5844</td><td>0.6718</td><td>0.6087</td><td>0.5838</td><td>0.5430</td><td>0.6957</td><td>0.5915</td><td>0.5918</td><td>0.5396</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.5033</td><td>0.5145</td><td>0.5603</td><td>0.5370</td><td>0.5399</td><td>0.5239</td><td>0.5099</td><td>0.5098</td><td>0.5470</td><td>0.5254</td><td>0.5235</td><td>0.5170</td><td>0.5507</td><td>0.5274</td><td>0.5189</td><td>0.5230</td><td>0.5297</td><td>0.5130</td><td>0.5204</td><td>0.5142</td><td>0.5305</td><td>0.5193</td></tr><tr><td>168-336</td><td>0.5420</td><td>0.5430</td><td>0.5959</td><td>0.5612</td><td>0.5796</td><td>0.5490</td><td>0.5484</td><td>0.5363</td><td>0.5882</td><td>0.5528</td><td>0.5702</td><td>0.5467</td><td>0.5859</td><td>0.5511</td><td>0.5410</td><td>0.5408</td><td>0.5731</td><td>0.5422</td><td>0.5563</td><td>0.5350</td><td>0.5695</td><td>0.5451</td></tr><tr><td>168-720</td><td>0.5846</td><td>0.5704</td><td>0.6665</td><td>0.5996</td><td>0.6354</td><td>0.5840</td><td>0.5983</td><td>0.5700</td><td>0.6632</td><td>0.5949</td><td>0.6116</td><td>0.5699</td><td>0.6298</td><td>0.5759</td><td>0.5847</td><td>0.5713</td><td>0.6384</td><td>0.5830</td><td>0.5923</td><td>0.5539</td><td>0.6369</td><td>0.5839</td></tr><tr><td>168-1440</td><td>0.6305</td><td>0.6121</td><td>0.8292</td><td>0.6899</td><td>0.7453</td><td>0.6534</td><td>0.6954</td><td>0.6304</td><td>0.8284</td><td>0.6878</td><td>0.6430</td><td>0.5953</td><td>0.6872</td><td>0.6104</td><td>0.6470</td><td>0.6143</td><td>0.7667</td><td>0.6604</td><td>0.5807</td><td>0.5531</td><td>0.7676</td><td>0.6609</td></tr><tr><td colspan="4">SCILinear 的平均提升百分比</td><td>7.68%</td><td>2.26%</td><td>6.53%</td><td>1.99%</td><td>7.37%</td><td>3.62%</td><td>7.41%</td><td>1.89%</td><td>6.81%</td><td>2.65%</td><td>10.68%</td><td>4.96%</td><td>11.60%</td><td>8.23%</td><td>8.95%</td><td>4.22%</td><td>13.39%</td><td>7.03%</td><td>5.48%</td><td>1.32%</td></tr><tr><td rowspan="4">Traffic</td><td>168-168</td><td>0.4514</td><td>0.2995</td><td>0.4447</td><td>0.2788</td><td>0.4497</td><td>0.2934</td><td>0.4545</td><td>0.3008</td><td>0.4803</td><td>0.3059</td><td>0.4009</td><td>0.2658</td><td>0.4399</td><td>0.3136</td><td>0.5540</td><td>0.3748</td><td>0.4642</td><td>0.3164</td><td>0.6491</td><td>0.3401</td><td>0.4200</td><td>0.2700</td></tr><tr><td>168-336</td><td>0.4694</td><td>0.3095</td><td>0.4684</td><td>0.2889</td><td>0.4727</td><td>0.3007</td><td>0.4786</td><td>0.3220</td><td>0.4992</td><td>0.3149</td><td>0.4106</td><td>0.2731</td><td>0.4466</td><td>0.3070</td><td>0.5926</td><td>0.3940</td><td>0.4952</td><td>0.3371</td><td>0.6671</td><td>0.3466</td><td>0.4394</td><td>0.2789</td></tr><tr><td>168-720</td><td>0.4963</td><td>0.3224</td><td>0.5007</td><td>0.3072</td><td>0.5079</td><td>0.3181</td><td>0.5131</td><td>0.3452</td><td>0.5264</td><td>0.3295</td><td>0.4458</td><td>0.2926</td><td>0.4703</td><td>0.3125</td><td>0.6631</td><td>0.4297</td><td>0.5241</td><td>0.3533</td><td>0.6960</td><td>0.3593</td><td>0.4703</td><td>0.2967</td></tr><tr><td>168-1440</td><td>0.5545</td><td>0.3486</td><td>0.5546</td><td>0.3352</td><td>0.5513</td><td>0.3428</td><td>0.5590</td><td>0.3692</td><td>0.5697</td><td>0.3535</td><td>0.4867</td><td>0.3132</td><td>0.4730</td><td>0.3177</td><td>0.7569</td><td>0.4670</td><td>0.5687</td><td>0.3755</td><td>0.7383</td><td>0.3799</td><td>0.5183</td><td>0.3240</td></tr></table>


最佳结果以加粗标示，次优结果以下划线标示。MSE或MAE的值越低，表示预测效果越好。


# 5.3.4 运行效率分析

为全面验证本章所提出的SCILinear的实际运行效率，本小节设计两组对比实验：在第一组实验中，输入序列长度被固定为168，输出长度则分别设置为168、336、720和1440，以研究预测长度对模型运行效率的影响。第二组实验则将输出长度固定为1440，分别调整输入长度为168、336、720和1440，以分析历史输入序列长度对模型运行效率的影响。

在效率分析部分，本章从时间开销和显存占用两个方面进行了综合考虑。对比方法的选择是基于表5-1中的实验结果，从不同的模型范式中挑选出具有代表性的模型进行比较。为确保实验结果的公平性，所有实验均采用批量大小为32、模型维度为128的设置，并在单层模型的条件下进行测试，从而消除了不同公共参数对实验结果可能产生的影响。

![](images/dc88b83726e570073005a3b9c3e2e4c3c92c234c727c41d8231d7eca8cbbdf7c.jpg)



(a) 时间开销情况（输入长度固定为168）


![](images/ab963f872d712299c4bd9cbc607bd3c8d8ab9238ecc262c68cf167f8b81feecc.jpg)



(b) 显存占用情况（输入长度固定为168）


![](images/910b57bb2c0db8d4a2a8d47196165a895ac11e7c174c6c917764f95e54693090.jpg)



(c) 时间开销情况（输出长度固定为1440）


![](images/01c1605df11f2a094243004372d03955c960c49684e89e3785823a55dd319c34.jpg)



(d) 显存占用情况（输出长度固定为 1440）



图5-4 不同模型的时间和内存开销



Fig 5-4 Time and memory overhead of different models.


本小节对模型的预测效率进行了详细评估，关注了性能、推理时间和内存消

耗，结果如图5-4所示。与其他轻量级模型相比，SCILINE在时间开销方面表现相似，但在显存占用上具有显著优势，能够在保证最佳预测性能的同时，减少时间开销和内存消耗。这使得SCILINE在处理较大数据集时更加高效，适用于对计算资源和内存有较高要求的实际应用场景。

# 5.3.5 模型分析及讨论

本节通过消融实验、鲁棒性分析、模型学习的表示分析、参数敏感性分析和预测案例分析，全面评估了SCILINE模型的性能，并且验证了SCILINE在多变量长程时间序列预测中的优势。

# (1) 消融实验

为验证SCILINE中不同组件的有效性，本小节进行了消融实验研究，结果如表5-2所示。消融实验主要比较SCILINE与三个消融变体模型的表现：（1）CILINE表示去除SCI建模方式后的模型；（2）SCILINE-Trend表示仅使用DB时间建模框架中的趋势性提取分支（即仅使用公式（5-5）中的  $H_1^n$  进行预测）；（3）SCILINE-Period表示仅使用DB时间建模框架中的周期性提取分支（即仅使用公式（5-5）中的  $H_2^n$  进行预测）。


表 5-2 消融实验结果。



Table 5-2 Results of ablation study.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">SCILinear</td><td colspan="2">CILinear</td><td colspan="2">SCILinear-Trend</td><td colspan="2">SCILinear-Period</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.1532</td><td>0.2459</td><td>0.1705</td><td>0.2594</td><td>0.1593</td><td>0.2567</td><td>0.1526</td><td>0.2450</td></tr><tr><td>168-336</td><td>0.1742</td><td>0.2670</td><td>0.1902</td><td>0.2788</td><td>0.1805</td><td>0.2770</td><td>0.1737</td><td>0.2663</td></tr><tr><td>168-720</td><td>0.2114</td><td>0.2985</td><td>0.2291</td><td>0.3084</td><td>0.2179</td><td>0.3077</td><td>0.2108</td><td>0.2978</td></tr><tr><td>168-1440</td><td>0.2773</td><td>0.3504</td><td>0.3021</td><td>0.3608</td><td>0.2832</td><td>0.3578</td><td>0.2762</td><td>0.3492</td></tr><tr><td rowspan="4">\( ETTh_2 \)</td><td>168-168</td><td>0.2664</td><td>0.3511</td><td>0.2729</td><td>0.3525</td><td>0.2904</td><td>0.3726</td><td>0.2712</td><td>0.3559</td></tr><tr><td>168-336</td><td>0.3141</td><td>0.3902</td><td>0.3308</td><td>0.3959</td><td>0.3409</td><td>0.4098</td><td>0.3237</td><td>0.3943</td></tr><tr><td>168-720</td><td>0.3969</td><td>0.4404</td><td>0.4168</td><td>0.4447</td><td>0.4242</td><td>0.4603</td><td>0.4057</td><td>0.4497</td></tr><tr><td>168-1440</td><td>0.5457</td><td>0.5366</td><td>0.5941</td><td>0.5485</td><td>0.5558</td><td>0.5452</td><td>0.5383</td><td>0.5337</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.5033</td><td>0.5145</td><td>0.5322</td><td>0.5264</td><td>0.5351</td><td>0.5381</td><td>0.5084</td><td>0.5190</td></tr><tr><td>168-336</td><td>0.5420</td><td>0.5430</td><td>0.5676</td><td>0.5524</td><td>0.5785</td><td>0.5677</td><td>0.5466</td><td>0.5460</td></tr><tr><td>168-720</td><td>0.5846</td><td>0.5704</td><td>0.6187</td><td>0.5865</td><td>0.6203</td><td>0.5944</td><td>0.5866</td><td>0.5728</td></tr><tr><td>168-1440</td><td>0.6305</td><td>0.6121</td><td>0.6789</td><td>0.6367</td><td>0.6414</td><td>0.6823</td><td>0.6294</td><td>0.6115</td></tr></table>


最佳结果以加粗标示。MSE或MAE的值越低，表示预测效果越好。


表5-2的实验结果表明, SCILINE 的性能显著优于 CILINE, 这充分验证了 SCI 建模方法的有效性。进一步对比 SCILINE 与 SCILINE-Trend、SCILINE-Period 的实验结果可以发现: 首先, 双分支 DB 时间建模框架在大多数情况下表现出优越性; 其次, 周期分支的作用尤为突出, 在某些任务中甚至超越了完整 DB 框架的性能。这一现象可能源于两方面原因: 其一, 数据集的固有特性, 例如 ECL 数据集具有显著的周期性特征; 其二, 在长时预测任务中 (如预测步长为 1440), 此时趋

势信息的作用可能衰弱，因此趋势分支的引入相当于增加了噪声干扰。因此，在实际应用中，需要根据具体任务特性审慎决定是否保留趋势分支。

# (2）鲁棒性分析

为了评估SCILINE的鲁棒性，本小节遵循MICN[26]和WITRAN[104]的设置，通过引入简单的白噪声进行鲁棒性实验。具体而言，本小节从原始输入序列中随机选择了一个比例为  $\varepsilon$  的数据，并对所选数据加入范围为  $[-2X_i, 2X_i]$  的随机扰动，其中  $X_i$  表示原始数据。随后，将白噪声注入训练数据，具体实验结果如5-3所示。


表 5-3 SCILINE 预测结果的鲁棒性实验



Table 5-3 Robustness experiments of SCILinear's forecasting results.


<table><tr><td rowspan="2" colspan="2">预测任务 评价指标</td><td colspan="2">168-168</td><td colspan="2">168-336</td><td colspan="2">168-720</td><td colspan="2">168-1440</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>ε = 0%</td><td>0.1532</td><td>0.2459</td><td>0.1742</td><td>0.2670</td><td>0.2114</td><td>0.2985</td><td>0.2773</td><td>0.3504</td></tr><tr><td>ε = 1%</td><td>0.1534</td><td>0.2464</td><td>0.1744</td><td>0.2675</td><td>0.2115</td><td>0.2988</td><td>0.2773</td><td>0.3507</td></tr><tr><td>ε = 5%</td><td>0.1546</td><td>0.2485</td><td>0.1757</td><td>0.2695</td><td>0.2121</td><td>0.3001</td><td>0.2775</td><td>0.3515</td></tr><tr><td>ε = 10%</td><td>0.1557</td><td>0.2505</td><td>0.1762</td><td>0.2708</td><td>0.2130</td><td>0.3014</td><td>0.2766</td><td>0.3509</td></tr><tr><td rowspan="4">ETH1</td><td>ε = 0%</td><td>0.4537</td><td>0.4674</td><td>0.5128</td><td>0.5157</td><td>0.6335</td><td>0.5935</td><td>0.7082</td><td>0.6394</td></tr><tr><td>ε = 1%</td><td>0.4536</td><td>0.4675</td><td>0.5131</td><td>0.5158</td><td>0.6336</td><td>0.5935</td><td>0.7080</td><td>0.6394</td></tr><tr><td>ε = 5%</td><td>0.4539</td><td>0.4680</td><td>0.5130</td><td>0.5157</td><td>0.6336</td><td>0.5933</td><td>0.7076</td><td>0.6390</td></tr><tr><td>ε = 10%</td><td>0.4546</td><td>0.4690</td><td>0.5133</td><td>0.5159</td><td>0.6336</td><td>0.5934</td><td>0.7074</td><td>0.6389</td></tr><tr><td rowspan="4">ETH2</td><td>ε = 0%</td><td>0.2664</td><td>0.3511</td><td>0.3141</td><td>0.3902</td><td>0.3969</td><td>0.4404</td><td>0.5457</td><td>0.5366</td></tr><tr><td>ε = 1%</td><td>0.2664</td><td>0.3509</td><td>0.3146</td><td>0.3904</td><td>0.3971</td><td>0.4403</td><td>0.5446</td><td>0.5355</td></tr><tr><td>ε = 5%</td><td>0.2664</td><td>0.3508</td><td>0.3140</td><td>0.3903</td><td>0.3963</td><td>0.4393</td><td>0.5380</td><td>0.5307</td></tr><tr><td>ε = 10%</td><td>0.2663</td><td>0.3507</td><td>0.3140</td><td>0.3901</td><td>0.3955</td><td>0.4385</td><td>0.5362</td><td>0.5292</td></tr><tr><td rowspan="4">Weather</td><td>ε = 0%</td><td>0.5033</td><td>0.5145</td><td>0.5420</td><td>0.5430</td><td>0.5846</td><td>0.5704</td><td>0.6305</td><td>0.6121</td></tr><tr><td>ε = 1%</td><td>0.5033</td><td>0.5145</td><td>0.5419</td><td>0.5430</td><td>0.5846</td><td>0.5704</td><td>0.6305</td><td>0.6121</td></tr><tr><td>ε = 5%</td><td>0.5040</td><td>0.5151</td><td>0.5422</td><td>0.5432</td><td>0.5848</td><td>0.5704</td><td>0.6308</td><td>0.6121</td></tr><tr><td>ε = 10%</td><td>0.5050</td><td>0.5158</td><td>0.5426</td><td>0.5433</td><td>0.5848</td><td>0.5703</td><td>0.6310</td><td>0.6120</td></tr></table>


* 不同的  $\varepsilon$  表示不同的噪声注入比例。


可以观察到，随着扰动比例的增加，预测结果中的MSE和MAE指标略有上升或有轻微的扰动。这表明，SCILINE在处理低噪声水平（最高达到  $10\%$  ）的数据时表现出良好的鲁棒性，并且在有效应对各种异常数据波动方面具有显著优势。

# (3) 模型学习的表示分析

为进一步验证SCILINE中双分支（DB）时间建模框架和变量完全独立（SCI）建模方法的有效性，本小节将模型学习的表示进行可视化分析。

如图5-5所示，双分支（DB）时间建模框架能够有效地从原始时间序列中学习到周期性和趋势性特性。从图5-5中可以明显看出整个时间序列整体呈上升趋势，但是周期内不同位置的信息存在较大差异，而不同周期间的趋势性也存在不同。通过对DB时间建模框架学习到的表示进行可视化展现，发现DB能够很好地捕获到周期内和周期间的不同特性，证明其能够有效处理时间序列数据中蕴含的复杂周期性和趋势变化。

此外，图5-6分别展示了SCILINE的周期性分支和趋势性分支，模型表示通过

![](images/c6218c4e4a3f7613509f2634c01cc78f37d09d6393778e28db63714414c86bef.jpg)



图5-5  $\mathrm{ETTh}_1$  数据集上周期性模式和趋势模式学习表示的可视化结果



Fig 5-5 Visualization results of the learned representations of periodic and trend patterns in dataset  $\mathrm{ETTh}_1$ .


SCI范式前后的变量间关系的对比情况。其中红色系代表周期分支模型表示，绿色系代表趋势分支模型表示。通过图5-6的横向比对，可以看出变量在通过SCI范式前，各变量之间的表示存在显著差异（即图片不同纵向之间的颜色差异较大），而通过SCI范式后，这种差异性被大大削弱了（即图片不同纵向之间的颜色差异相对平缓很多）。这进一步证明了SCI范式能够有效处理变量间的异质性，以便后续的模块设计可以采用传统的参数共享进行建模，在提高建模性能的同时保证了模型的低开销。

# (4) 参数敏感性分析

在本章提出的模型中，超参数norm的设定呈现出显著差异，并对模型性能产生了直接影响。因此，本节重点围绕超参数norm进行分析和探讨。

在第四章中提到，超参数norm的取值应依据具体数据集的特性进行调整。为此，本部分对不同任务的数据集进行了统计分析，包括ECL、 $ETTh_{1}$ 、 $ETTh_{2}$ 和Weather四个数据集，统计结果如表5-4所示。

通过数据分析可以观察到，不同数据集的训练集在数据分布上存在一定差异。当数据集的标准差过小或过大时，分别意味着数据的整体变化幅度较小或波动性较强。在这类情况下，将超参数norm设定为1，有助于通过归一化平衡数据分布，从而提升模型的训练效果和稳定性。

为了进一步定量比较不同数据集的整体相关性，还计算了平均绝对相关性

![](images/8c16b7cd52ffa19c743c531f0cdbe4477e1c7bb881d914d53e056cb6cd97c252.jpg)


![](images/09c411164991309d3511d536b6c3887276faab1fadfc9e3fe076d9810d6f1170.jpg)


![](images/cd5e8b82f64c49a7b9b5b421883f76c57edf9246c16c8b66ca2bd5e5adb61e7c.jpg)


![](images/063bfed9236e4740101433c4f49e089a9297555978ecf85f23b880bf8028e017.jpg)



图5-6  $\mathrm{ETTh}_{1}$  数据集上各变量学习表示的可视化结果



Fig 5-6 Visualization results of the learned representations of each variable in dataset ETTh1.


(Average Absolute Correlation, AAC) 指标

$$
\mathbf {A A C} = \frac {1}{N (N - 1)} \sum_ {i j} \left| r _ {i j} \right|, \tag {5-7}
$$

其中  $r_{i,j}$  表示变量  $i$  和  $j$  的皮尔逊相关系数， $N$  为变量总数。该指标取值范围为0到1，值越高则说明整体变量间相关性越强。从表5-5可以看出，Traffic数据集的AAC值最高，其次是ECL，而ETTh、ETTh和Weather数据集的整体相关性则较弱，因此SCILINE不适用相关性较高的Traffic数据集。


表 5-4 训练集中数据集的分布 (标准差)



Table 5-4 The distribution (STD) of dataset in the training sets.


<table><tr><td rowspan="2">数据集 预测任务</td><td colspan="2">ECL</td><td colspan="2">ETTh1</td><td colspan="2">ETTh2</td><td colspan="2">Weather</td></tr><tr><td>STD</td><td>norm</td><td>STD</td><td>norm</td><td>STD</td><td>norm</td><td>STD</td><td>norm</td></tr><tr><td>168-168</td><td>0.9085</td><td></td><td>0.6142</td><td></td><td>0.5550</td><td></td><td>0.6989</td><td></td></tr><tr><td>168-336</td><td>0.9112</td><td rowspan="2">1</td><td>0.6655</td><td rowspan="2">0</td><td>0.5395</td><td rowspan="2">1</td><td>0.6964</td><td rowspan="2">0</td></tr><tr><td>168-720</td><td>0.9119</td><td>0.6564</td><td>0.5405</td><td>0.6974</td></tr><tr><td>168-1440</td><td>0.9118</td><td></td><td>0.6456</td><td></td><td>0.5440</td><td></td><td>0.6991</td><td></td></tr></table>


表 5-5 各个数据集 ACC 值比较



Table 5-5 ACC of different datasets.


<table><tr><td>数据集</td><td>Traffic</td><td>ECL</td><td>ETTh1</td><td>ETTh2</td><td>Weather</td></tr><tr><td>ACC</td><td>0.5638</td><td>0.4893</td><td>0.2221</td><td>0.3246</td><td>0.4049</td></tr></table>

# (5）案例分析

为进一步分析SCILinear的优势所在，本小节选取了  $ETTh_{1}$  数据集和Weather数据集上的预测案例进行分析，如图5-7至5-10所示。

![](images/f06e653110ab6ec2dde1935851ad278a032e019808d2a3247ea634287189c949.jpg)


![](images/2f404d7dec60bd0d59c3ff4f1ba19806477001bc5f694e22b09c5be9e07f78b6.jpg)


![](images/c88272374aea34891442a2a096882583b82807af104b6a684a5828732020dcfa.jpg)



图5-7 SCILINE在数据集ETTh1中的168-168预测案例



Fig 5-7 Forecasting cases of SCILINEar for 168-168 in dataset ETTh1.


![](images/2b5416428e38e065f6b164fbc0227f2fc2c6d8aac6ecc26459eaf51d0d4177cb.jpg)


![](images/b77b82311dff58be644a31b8bea8397e7809ba52958657a76b020c9ef8640974.jpg)


![](images/ff45b28dd12fde21d114928a4c785df436ff73b905dca2d3c0239dfe02ae87d4.jpg)



图5-8 SCILINE在数据集ETTh1中的168-336预测案例



Fig 5-8 Forecasting cases of SCILINEar for 168-336 in dataset ETTh1.


首先，在  $ETTh_{1}$  数据集中，SCILINE模型表现出色。与FITS和SparseTSF方法相比，SCILINE在趋势性和波动特征的捕获上更为精确。在168-168（图5-7）和168-336（图5-8）预测任务中，能够更好地拟合时间序列的波动性，预测值与真实值的拟合程度明显优于其他方法。在168-720的预测任务中（图5-9），SCILINE对趋势性和周期性特征的捕获更加全面，预测值与真实值的重叠程度更高，特别是

![](images/151e8711992ff363a44342570a2ccd09382f79f8acc2cd5d39eece61ad00ff01.jpg)


![](images/99d2b0fadcdf95d2a5c8db720c244be94b15504530c3d99a3c0893fc9b2103cf.jpg)


![](images/35f00e8a1d075c6b13ccca64365e4a045709e13db61cb60cb60bf473b2ebbc09.jpg)



图5-9 SCILINE在数据集ETTh1中的168-720预测案例



Fig 5-9 Forecasting cases of SCILINEar for 168-720 in dataset ETTh1.


![](images/639e46cae2af69d3a876fcffd81d9f63df8069280e8592c8c657450d556dfb45.jpg)


![](images/ca5e72f890612151547b65c566bb0b65f15a2c68cee63f321498447dca39b31f.jpg)


![](images/25a0a3b23efc9835ee89eb5a2f3fb6c54510b775db81e6babfbd568e45ca1f97.jpg)



图5-10SCILINE在数据集Weather中的168-1440预测案例



Fig 5-10 Forecasting cases of SCILINEar for 168-1440 in dataset Weather.


在峰值预测和长期稳定性方面表现卓越。

在Weather数据集上，SCILINE在不同时间尺度的预测任务中均表现出优异的趋势把握能力。在168-1440任务中（图5-10），SCILINE能够有效捕捉数据的整体变化趋势，并在整个预测区间内保持较高的预测精度，有效控制了误差累积问题。例如，在640-960时间点区间内的上升趋势和960-1280区间内的波动趋势，SCILINE均得到了较好的反映。相比之下，TimesNet和ModernTCN在长期预测中往往出现趋势偏离或幅度衰减的问题，即使TimesNet在总体评估指标上误差更小，但从图5-10中，能明显看出，其对于趋势的预测能力较差。

此外，SCILinear在处理“短序列输入-超长序列输出”预测任务时，展现了卓越的长期依赖性建模能力。其基于有限历史信息推断长期未来变化的能力尤其突出，能够在整个预测区间内保持性能的相对稳定。在预测的平滑性和连续性方面，SCILinear生成的预测曲线自然流畅，没有出现不合理的跳变或断点，显示了良好的数学稳定性和泛化能力。

综合来看，SCILinear凭借其在不同数据集和预测任务中的优异表现，证明了其作为通用时间序列预测方法的有效性和可靠性。这一方法不仅为电力负载预测领域提供了新的解决方案，也为气象预测、环境监测等需要长期预测的应用场景提供了可靠的技术工具，具有重要的理论价值和广阔的应用前景。

# 5.4 本章小结

本章首先提出了一种新颖的变量完全独立（Separate Channel Independent, SCI）建模范式，该范式通过为每个变量分配完全独立的模型参数进行建模，有效消除了变量异质性带来的影响，同时保持  $\mathcal{O}(N)$  的理论复杂度，与变量独立（CI）建模方式效率相当。

接着，本章还提出了一种基于线性变换的双分支（Dual-Branch, DB）时间建模架构，通过双层线性结构有效提取时间序列中的时间模式，并实现了  $\mathcal{O}(\sqrt{T})$  的理论复杂度和  $\mathcal{O}(1)$  的信息传递路径。

在此基础上，本章将SCI变量建模范式与基于线性变换的DB时间建模架构相结合，提出了一种专门处理异质性的多变量长程时间序列的预测模型——SCI-Linear。实验结果表明，SCILinear在保持高预测性能的同时，实现了卓越的运行效率。

SCilinear作为一种轻量级且具有良好可解释性的模型，为时间序列预测中的线性方法设定了新的基准，并为未来高效且可扩展的预测模型研究提供了方向。然而，SCilinear依然存在一些局限性。例如，当变量间的异质性并不显著时，其对变量的独立建模能力可能无法充分发挥，导致预测性能一定程度上的局限。

# 6 万年历式信息提取的多变量长程时间序列预测方法

第五章主要探讨了通道完全独立（SCI）建模范式在应对变量间异质性方面的有效性。然而，在实际应用中，变量之间的关系还可能以相似性为主导，此时则可采用变量独立建模（CI）的方式进行处理。总体而言，相似性和异质性分别体现了变量维度上的一致性和差异性，这两种特性由数据本身的固有属性所决定。针对它们，可以通过上述两种简单高效的方式进行有效建模与处理。

而在时间信息的建模过程中，如何有效捕获一致性与差异性却成为了一项重大挑战。二者在一定程度上存在相互矛盾：一致性强调统一化，而差异性则关注个性化。因此，兼顾两者，并在其之间找到合理的平衡点，是提升预测精度的关键所在。

此外，要确保一致性与差异性的有效建模，前提是能够充分捕获复杂的时间模式信息（包括趋势性模式、周期性模式、长期模式、短期模式、局部模式和全局模式），并尽可能减少信息损失。第三章和第四章分别围绕这两个关键问题提出了有效的解决方案，为本章进一步解决时间维度建模中的一致性与差异性挑战奠定了坚实基础。

基于此，本章提出了一种万年历式信息提取方法，并结合SCI和CI在变量维度信息提取上的一致性与差异性优势，构建了万年历式信息提取网络（CalendarNet）。CalendarNet通过将时间序列重构为类似万年历的二维排布结构，首先利用线性层在长期尺度上捕获局部周期性信息。随后，通过窗口滑动机制，使预测序列中的每个时间步都能获得全局感受野，并在短期尺度上有效建模趋势性变化。这一系列机制相互协同，在兼顾时间维度信息提取的一致性与差异性的同时，实现了对复杂时间模式的深度挖掘。此外，CalendarNet根据数据集的特性，适配性地通过SCI或CI建模方式，以兼顾变量维度信息提取的一致性与差异性。通过在五个真实场景下的基准数据集上的实验表明，CalendarNet在预测性能和运行效率上均展现出卓越的性能。

# 6.1 引言

在多变量长程时间序列预测任务中，多变量数据的固有特性使得捕获变量间的关联性至关重要，其中包括相似性和异质性。相似性体现为变量之间的一致性，即它们所具有的共同特性；而异质性则体现为不同变量在时间模式上的显著差异。而在时间维度上，信息提取方式的一致性和差异性则直接影响信息的有效利用。因


表 6-1 变量处理方法对比



Table 6-1 Comparison of Variable Processing Methods.


<table><tr><td>优势</td><td>(a) CD</td><td>(b) CI</td><td>(c) SCI</td><td>(d) Attention</td><td>(e) GNN</td></tr><tr><td>相似性</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>异质性</td><td>✗</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>复杂度</td><td>O(N)</td><td>O(N)</td><td>O(N)</td><td>O(N2)</td><td>O(N2)</td></tr></table>

此，本章旨在在充分捕获复杂的时间模式信息和减少长程信息传递损失的基础上，进一步兼顾信息提取的一致性和差异性，实现时间和变量两个维度的有效建模。

对于变量的相似性和异质性，现有的多种多变量处理方法能够实现不同程度的建模，如表6-1所示。基于变量融合（CD）的方法通过融合多变量信息来捕获变量相似性，但忽略了异质性的建模。基于注意力机制（Attention）的方法和图神经网络（GNN）的方法能够自适应地学习不同变量间的相似性与异质性，但由于其较高的复杂度  $O(N^2)$ ，将消耗更多的计算资源。基于变量独立（CI）的方法通过设置相同参数处理各个变量，再对各变量独立计算，在处理相似性上更具优势，但在处理异质性时有一定局限。基于变量完全独立（SCI）的方法则在 CI 方式中引入不同参数用来分别处理不同变量，使其能够较好地捕获变量的异质性，并保留一定相似性的建模能力。故变量的相似性与异质性问题分别可以通过 CI 和 SCI 范式得到简单高效地解决。但是，在时间维度上，如何在捕获时间模式信息并减少信息传递损失的同时，保证信息提取的一致性和差异性仍然是一项亟待解决的重要挑战。

在时间维度上，一致性要求每个预测点所使用的特征来自相同的数据来源，具体表现为：每个预测点需要基于相同长度的历史信息进行预测，并且采用相同的生成方式，这种一致性能够避免因信息量差异导致的预测偏差，从而提高预测结果的准确性和可靠性；而差异性则指不同时间步的预测应该保持其独特的变化态势，形成个性化的表示，这种差异性能够使得模型全面地捕获时间序列的复杂模式，从而进一步提升预测精度。

然而，一致性和差异性又存在相互矛盾的关系。一致性强调统一的信息提取方式，而差异性则强调个性化的信息提取方式。例如，如果在每个时间步都使用完全相同的数据进行预测，虽然保证了一致性，却完全丧失了差异性；反之，若只考虑差异性则容易导致预测点所利用的特征信息量级不一致，造成预测偏差。因此，如何在两者之间寻求合理的平衡，既确保信息的标准化提取，又保留足够的个性化特征，是一个具有挑战性的问题。

现有方法在捕获时间维度的复杂模式信息仍存在显著不足，因此更难以兼顾时间维度信息提取的一致性和差异性。基于原始一维时间序列直接建模的方法，如

PatchTST[27]、MICN[26]、ModernTCN[53]和iTransformer[61]等，难以直接建模周期性特征。基于时间序列分解的方法，如Autoformer[55]和DLinear[39]，通过不同分支分离周期和趋势成分，但可能导致信息丢失。频域方法如FITS[41]通过快速傅里叶变换（FFT)[111]能隐式地建模周期性特征，但主要关注全局周期特性，而忽略了对趋势性变化的捕获。相比之下，TimesNet[51]和WITRAN[104]通过将一维序列输入排布为二维序列，能够显式建模周期性特征。然而，TimesNet过度依赖Inception[52]结构的二维卷积处理全局信息，并将整个序列的全局信息直接用于预测，导致其对局部特征（特别是局部周期特性）的保留性较差。WITRAN则能够捕获时间复杂模式信息并保留局部周期特性，更具优势，并且在不同预测点上引入了不同的数据输入，建模了时间维度的信息提取差异性，但在各个预测点的信息利用一致性方面仍存在不足，如图6-1所示。例如，图中二维序列中第二列的预测点相较于第一列的预测点，其局部周期性信息的表示包含了更多的数据输入。这不仅对不同预测点造成了一定的预测偏差，还导致信息未能被充分利用，从而影响了整体预测准确性。

![](images/24952d9b43f41d5775324dcf1e4baa6ea4662891a452a4542015ad4e4ff78292.jpg)



图6-1 WITRAN提取信息过程示意图



Fig. 6-1 Diagram of the information extraction process of WITRAN.


总的来说，在实现捕获时间复杂模式信息的基础上，进一步地兼顾时间维度信息提取的一致性与差异性是一项重大挑战。本章旨在提出一种新方法，致力于全面建模上述时间特征，平衡一致性与差异性的相互作用关系，实现更准确和稳健的时间序列预测性能。

幸运的是，受万年历循环结构（如图6-2所示）的启发，本章创新性地将时间

![](images/9ea3d70282b4dde17ab15a01e4102602e7740a34099a902517d4b8046f80df92.jpg)



(a) 万年历情况示意图1（当月1日为周六）


![](images/dce4e5ff7bc9ae55602d2938ea2eace108118ba600e85d99bceb2d49b8a0ade3.jpg)



(b) 万年历情况示意图2（当月1日为周三）



图6-2 万年历示意图



Fig. 6-2 Diagram of the recurrent calendar.


建模过程与万年历结构相结合，提出了万年历式时间建模网络（CalendarNet）。从图6-2中可以看出，万年历是由日期表与日历窗口组成的二维结构，将每个月的天数在十三列宽（2周-1天）的表中进行排布，日历窗口框选了七天（一个周周期）宽度的日期表示星期日至星期六，并可以在日期表上滑动，使其可以适用于任何月份的日期排布。这种结构不仅直接体现了周期性优势，还具有两个关键特性：

(1) 一致性：无论日历窗口位于表上何处，总包含 1-31 日，这一结构在信息提取的一致性方面具有优势。

(2) 差异性: 滑动至各个位置上的日历窗口内日期排布不同, 得以适用于任何不同的月份日期, 这一结构在建模预测点个性化的信息提取差异性上具有优势。

基于以上分析，CalendarNet将万年历中的两个特性结合起来，使得无论日历窗口如何滑动，窗口的最后一列始终能够捕获周期性局部信息，同时始终保持整个窗口的全局感受野。这种独特的结构设计在信息提取的一致性与差异性方面具有显著优势。

具体而言，CalendarNet 首先将原始一维时间序列按照周期数转换为二维布局，并对此二维排布按照类似于万年历结构进行补充，将设置宽度等于周期的滑动窗口中的周期内信息补全，以确保滑动窗口能够一致地捕获全局信息，如图6-3所示。

为了提取周期性特性，CalendarNet采用线性层聚合每一列的信息。同时，为了捕获全局信息，CalendarNet将滑动窗口中的最后一列作为研究对象，并通过另一个线性层进一步重新聚集这些信息。每个滑动窗口都覆盖了相同的历史序列，确保在不同时间步中提取的信息具有相同量级，避免因数据分布的不均衡导致的学习偏差，保证了时间信息提取一致性。此外，通过引入一个简单的门控机制[108]，将提取的全局信息与当前研究对象的周期性信息进行融合，并将此表示直接用于未来序列的预测。通过线性层与门控机制对每列信息进行加权聚合，充分考虑不同时间步之间的个性化特征。由于时间序列的不同时间步可能具有不同的趋势，CalendarNet在聚合信息时自适应地分配权重，这种设计不仅确保了局部和全局信息在相同量级上被一致性提取，还保证了模型在捕获周期性和趋势性时的差异性。

此外，考虑到多变量时间序列中的异质性，CalendarNet采用了可调整的变量

![](images/7e3517c70d2e77360f34d1d8a0e030559e40cdb557abdc151ad456c1481a2673.jpg)



图6-3 CalendarNet提取信息过程示意图



Fig. 6-3 Diagram of the information extraction process of CalendarNet.


独立建模策略。基于不同数据集的特性，CalendarNet在第五章的基础上对变量独立机制进行了优化：对于变量间差距显著的数据集，采用SCI机制，而对于其他数据集，则采用CI机制。每个变量通过独立的CalendarNet模块进行处理，以保留其独特的时序特征，有效避免了通道间异质性带来的信息干扰。通过这种分层处理策略，CalendarNet既保证了单个变量的特征提取，又考虑了变量间的潜在协同效应，显著提升了多变量时间序列预测的整体性能。

总结来说，本章的主要贡献如下：

(1) 受到万年历循环结构的启发, 提出了一种新颖的时间建模框架 CalendarNet (如图6-3所示)。CalendarNet 能在有效捕捉时间复杂模式信息的基础上, 进一步地兼顾信息提取的一致性与差异性。

(2) 从模型架构的角度来看, CalendarNet 完全由线性层和简单的门控机制构建, 无需引入多个分支来提取相关信息, 设计上简洁、高效。

(3) 在性能方面, 通过在五个公开数据集上的实验表明, 与之前在长程预测任务中的最先进的 (SOTA) 方法相比, CalendarNet 在各个方面均展现出卓越的性能。

(4) 效率方面, CalendarNet 的理论复杂度为  $O(\sqrt{T})$  。并通过实验证明了 Cal-endarNet 的实际计算效率方面的优势。

# 6.2 万年历式信息提取网络

本节将详细介绍一种新颖的时间建模网络——万年历式时间建模网络（CalendarNet），其结构如图6-4所示。CalendarNet的设计灵感来源于万年历的循环结构（参见图6-2），能够高效捕捉时间序列中的周期性、趋势性、局部特征以及全局特征，同时兼顾信息提取的一致性与差异性。通过将时间序列数据从一维（1D）时间表示扩展为二维（2D）布局，使其能够直接建模跨周期的复杂关系。

![](images/230da7533bc2a40a6801747c27500c0a671c5204af899055481fe5c5f50d7b89.jpg)



图6-4 CalendarNet模型架构图



Fig.6-4 Overall architecture of CalendarNet.


为了进一步阐明 CalendarNet 的创新性与优势，本节首先介绍其整体架构及设计原理，探讨其与传统时间建模方法的主要区别与联系；随后，详细解析各模块的功能及核心公式的推导过程，阐述其在信息提取一致性与差异性上的平衡机制；最后，通过复杂度分析说明 CalendarNet 在时间建模任务中的效率与适用性，为后续的实验验证提供理论支撑。

# 6.2.1 输入模块

本模块首先对原始输入时间序列  $\mathbf{X} \in \mathbb{R}^{T \times N}$  进行归一化处理，以消除不同变量之间的量纲差异并提升模型的数值稳定性。随后，根据周期值  $P$  的大小，将  $\mathbf{X}$  沿时间维度重排布为二维结构  $\mathcal{X}_{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N}$ ，其中满足  $R \times P = T$ 。为了确保  $\mathcal{X}_{2\mathrm{D}}$  中每一列的元素能够一致性地捕获其对应前  $P - 1$  时间步的信息，从而有效提取时间序列的趋势性，需要对序列进行补全操作。该过程可形式化表示如下公式 (6-1)

所示：

$$
\boldsymbol {\mu} = \frac {1}{T} \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t}, \tag {6-1a}
$$

$$
\boldsymbol {\sigma} ^ {2} = \frac {1}{T} \sum_ {t = 1} ^ {T} \left(\boldsymbol {x} _ {t} - \boldsymbol {\mu}\right) ^ {2}, \tag {6-1b}
$$

$$
\mathbf {X} _ {\mathrm {1 D}} = \left\{ \begin{array}{l l} \mathbf {X} & \text {n o r m} = 0 \\ (\mathbf {X} - \boldsymbol {\mu}) / \boldsymbol {\sigma}, & \text {n o r m} = 1 \end{array} , \right. \tag {6-1c}
$$

$$
\mathcal {X} _ {\mathrm {2 D}} = \operatorname {R e s h a p e} \left(\mathbf {X} _ {\mathrm {1 D}}\right), \tag {6-1d}
$$

$$
\mathcal {X} _ {\mathrm {2 D}} ^ {\text {s u p p l y}} = \operatorname {S p l i t} \left(\mathcal {X} _ {\mathrm {2 D}}\right), \tag {6-1e}
$$

$$
\mathcal {X} _ {\mathrm {2 D}} ^ {\text {s u p p l y} \_ \text {p a d}} = \operatorname {P a d d i n g} _ {1} \left(\mathcal {X} _ {\mathrm {2 D}} ^ {\text {s u p p l y}}\right), \tag {6-1f}
$$

$$
\mathcal {X} _ {2 \mathrm {D}} ^ {\text {p a d}} = \operatorname {P a d d i n g} _ {2} \left(\mathcal {X} _ {2 \mathrm {D}}\right), \tag {6-1g}
$$

其中，归一化层的使用受到WITRAN方法的启发[104]，其参数norm的值需根据数据集的特性进行确定。函数Reshape(·)将一维时间序列  $\mathbf{X}_{\mathrm{1D}}$  沿时间维度重排布为二维结构  $\mathcal{X}_{2\mathrm{D}}$  。函数Split(·)用于从  $\mathcal{X}_{2\mathrm{D}}$  的第二维度中提取最后  $P - 1$  个时间步，从而生成补充序列  $\mathcal{X}_{2\mathrm{D}}^{\mathrm{supply}} \in \mathbb{R}^{R \times (P - 1) \times N}$  。

为了进一步对数据进行补全操作，函数Padding1(·)在  $\mathcal{X}_{2D}^{\mathrm{supply}}$  的第一维度前端进行零值填充，得到扩展后的补充序列  $\mathcal{X}_{2D}^{\mathrm{supply\_pad}} \in \mathbb{R}^{(R+1) \times (P-1) \times N}$  。同时，函数Padding2(·)在  $\mathcal{X}_{2D}$  的第一维度末端进行零值填充，生成  $\mathcal{X}_{2D}^{\mathrm{pad}} \in \mathbb{R}^{(R+1) \times P \times N}$  。

# 6.2.2 周期性提取模块

为了有效捕捉时间序列数据中的周期性特征，本节将详细介绍周期性提取模块的两种设计方案：基础的周期性特征提取层和改进的周期性特征提取层。二者分别针对不同的场景和需求提供解决方案，以增强周期性信息的提取效果。

# (1) 基础的周期性特征提取层

在  $\mathcal{X}_{2D}^{\mathrm{supply\_pad}}$  和  $\mathcal{X}_{2D}^{\mathrm{pad}}$  中，周期对齐机制使得跨周期关系能够被直接建模。为了显式提取每一列的周期性特征，基础的周期性特征提取层通过引入共享的线性层进行处理，具体计算过程如下：

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {s u p p l y} - \text {p a d}} = \operatorname {L i n e a r} _ {\text {p e r i o d}} \left(\mathcal {X} _ {2 \mathrm {D}} ^ {\text {s u p p l y} - \text {p a d}}\right), \tag {6-2a}
$$

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {p a d}} = \operatorname {L i n e a r} _ {\text {p e r i o d}} \left(\chi_ {2 \mathrm {D}} ^ {\text {p a d}}\right). \tag {6-2b}
$$

此方法通过共享线性层提取特征，能够高效地捕捉周期性信息。然而，由于零值

填充的位置不同，可能会引入噪声，从而影响特征提取的准确性。

# (2) 改进的周期性特征提取层

为减少基础周期性特征提取层中的噪声影响，改进的周期性特征提取层针对  $\mathcal{X}_{2\mathrm{D}}^{\mathrm{supply\_pad}}$  和  $\mathcal{X}_{2\mathrm{D}}^{\mathrm{pad}}$  的不同填充位置，分别引入独立的线性层进行处理，以提升特征提取效果。改进设计的具体公式如下：

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {s u p p l y}} = \operatorname {L i n e a r} _ {\text {p e r i o d}} ^ {1} \left(\mathcal {X} _ {2 \mathrm {D}} ^ {\text {s u p p l y}}\right), \tag {6-3a}
$$

$$
\mathcal {H} _ {\text {p e r i o d}} = \operatorname {L i n e a r} _ {\text {p e r i o d}} ^ {2} \left(\mathcal {X} _ {2 \mathrm {D}}\right). \tag {6-3b}
$$

其中， $\operatorname{Linear}_{\mathrm{period}}^{*}(\cdot)$  表示沿张量的第一个维度进行线性变换的操作，其输入大小为  $R$ ，输出大小为  $dk$ 。通过该改进，得到的张量及其维度分别为  $\mathcal{H}_{\mathrm{period}}^{\mathrm{supply}} \in \mathbb{R}^{dk \times (P-1) \times N}$  和  $\mathcal{H}_{\mathrm{period}} \in \mathbb{R}^{dk \times P \times N}$ 。

与基础设计相比，改进的周期性特征提取层在不同填充位置分别应用对应独立的变换，使得周期性特征的提取更加精确，从而有效提升了模型的鲁棒性。

# 6.2.3 趋势性提取模块

在时间序列预测中，周期性特征提取模块通过捕捉时间序列中的重复模式，揭示了数据在固定时间间隔内的规律性变化。然而，仅依赖周期性特征不足以全面刻画时间序列的全局行为。为了进一步提升模型的预测能力，趋势性特征提取模块通过聚合长期趋势信息，关注时间序列中的整体变化方向，从而补充和扩展了周期性特征的表达能力，为时间序列预测提供了更全面的支持。

趋势性提取模块旨在捕获时间序列中的趋势性特征。为实现这一目标，设计了两种趋势性特征提取层，分别为基本趋势性特征提取层和改进的趋势性特征提取层。这些层在特征提取方法和处理细节上有所不同，能够有效应对不同的噪声和局部信息需求。

# (1) 趋势性特征提取层

为了提取趋势性特征，首先将  $\mathcal{H}_{\mathrm{period}}^{\mathrm{supply}}$  与  $\mathcal{H}_{\mathrm{period}}$  进行拼接。然后，通过线性层对拼接结果进行处理，以聚合趋势性信息，如公式（6-4）所示：

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {a l l}} = \operatorname {C o n c a t} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {\text {s u p p l y}}, \mathcal {H} _ {\text {p e r i o d}}\right), \tag {6-4a}
$$

$$
\mathcal {H} _ {\text {t r e n d}} = \operatorname {S p l i t} \left(\operatorname {L i n e a r} _ {\text {t r e n d}} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {\text {c a l l}}\right)\right), \tag {6-4b}
$$

其中, 线性变换  $\operatorname{Linear}_{\mathrm{trend}}(\cdot)$  作用于  $\mathcal{H}_{\mathrm{period}}^{\mathrm{all}} \in \mathbb{R}^{dk \times (2P - 1) \times N}$  的第二维度, 其输入大小为  $(P - 1) \times dk$ , 输出大小为  $dm$  。Split( $\cdot$ ) 在第二维度上舍弃最后一个时间步的特

征表示，得到最终的输出  $\mathcal{H}_{\mathrm{trend}} \in \mathbb{R}^{dm \times P \times N}$ 。

# (2) 改进的趋势性特征提取层

在趋势性特征提取的过程中，滑动窗口的处理可能由于  $\mathcal{H}_{\mathrm{period}}^{\mathrm{supply}}$  和  $\mathcal{H}_{\mathrm{period}}$  来源的局部周期性特征数量不均而引入噪声。为解决这一问题，改进的趋势性特征提取层对滑动窗口中捕获的每段特征应用对应独立的线性变换，从而提升趋势性提取精度。如公式（6-5）所示：

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {a l l}} = \operatorname {C o n c a t} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {\text {s u p p l y}}, \mathcal {H} _ {\text {p e r i o d}}\right), \tag {6-5a}
$$

$$
\mathcal {H} _ {\text {t r e n d}} ^ {(j)} = \operatorname {L i n e a r} _ {\text {t r e n d}} ^ {(j)} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {(j)}\right), \tag {6-5b}
$$

$$
\mathcal {H} _ {\text {t r e n d}} = \operatorname {C o n c a t} \left(\mathcal {H} _ {\text {t r e n d}}, \mathcal {H} _ {\text {t r e n d}} ^ {(j)}\right), \tag {6-5c}
$$

其中， $\mathcal{H}_{\mathrm{period}}^{(j)} \in \mathbb{R}^{dm \times (P - 1) \times N}$  通过对  $\mathcal{H}_{\mathrm{period}}^{\mathrm{all}}$  在第二维度滑动窗口（窗口大小为  $P - 1$ ）提取得到。每个独立线性层  $\operatorname{Linear}_{\mathrm{trend}}^{(j)}(\cdot)$  生成的输出为  $\mathcal{H}_{\mathrm{trend}}^{(j)} \in \mathbb{R}^{dm \times 1 \times N}$  。最终输出  $\mathcal{H}_{\mathrm{trend}} \in \mathbb{R}^{dm \times P \times N}$  通过沿第二维度依次拼接  $\mathcal{H}_{\mathrm{trend}}^{(j)}$  得到。

改进的趋势性特征提取层在捕获局部信息的同时有效减少噪声干扰，进一步提升了趋势性特征的准确性。

# 6.2.4 等价优化的周期性和趋势性提取模块

改进后的周期性特征提取层与原设计功能相同，而改进后的趋势性特征提取层则是对原趋势性特征提取层的必要替代。通过结合这两种改进的特征提取方法，模型能够针对输入模块中  $\mathcal{X}_{2\mathrm{D}}$  和  $\mathcal{X}_{2\mathrm{D}}^{\mathrm{supply}}$  的每一列学习独立的参数，从而提高特征提取的灵活性。然而，这些独立的处理步骤不可避免地增加了计算复杂度。

为了在保持性能的同时降低计算开销，我们在改进的周期性和趋势性特征提取模块上做了进一步改进，具体过程如公式（6-6）所示：

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {n e w}} = \left\{ \begin{array}{l l} \operatorname {L i n e a r} _ {\text {p e r i o d}} ^ {\text {n e w}} \left(\mathcal {X} _ {2 \mathrm {D}}\right), & \text {t r a n s} = 0, \\ \operatorname {T r a n s} \left(\operatorname {L i n e a r} _ {\text {p e r i o d}} ^ {\text {n e w}} \left(\mathcal {X} _ {2 \mathrm {D}}\right)\right), & \text {t r a n s} = 1, \end{array} \right. \tag {6-6a}
$$

$$
\mathcal {H} _ {\text {p e r i o d}} ^ {\text {a l l - n e w}} = \operatorname {C o n c a t} \left(\operatorname {S p l i t} _ {1} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {\text {n e w}}\right), \mathcal {H} _ {\text {p e r i o d}} ^ {\text {n e w}}\right), \tag {6-6b}
$$

$$
\hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {a l l} \text {n e w}} = \operatorname {T r a n s} _ {\text {p e r i o d}} \left(\mathcal {H} _ {\text {p e r i o d}} ^ {\text {a l l} \text {n e w}}\right), \tag {6-6c}
$$

$$
\mathcal {H} _ {\text {t r e n d}} ^ {\text {n e w}} = \operatorname {L i n e a r} _ {\text {t r e n d}} ^ {\text {n e w}} \left(\operatorname {S p l i t} _ {2} \left(\hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {a l l ＿ n e w}}\right)\right), \tag {6-6d}
$$

$$
\hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {n e w}} = \operatorname {S p l i t} _ {3} \left(\hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {c a l l} \_ \text {n e w}}\right). \tag {6-6e}
$$

首先，输入模块中的  $\mathcal{X}_{2\mathrm{D}} \in \mathbb{R}^{R \times P \times N}$  通过线性变换  $\operatorname{Linear}_{\mathrm{period}}^{\mathrm{new}}(\cdot)$  提取周期性特

征，得到  $\mathcal{H}_{\mathrm{period}}^{\mathrm{new}} \in \mathbb{R}^{dk \times P \times N}$  。在处理多变量时间序列时，可以根据数据集的特性选择是否对变量维度进行特征变换  $\mathrm{Trans}(\cdot)$  。

随后，利用  $\mathrm{Split}_1(\cdot)$  从  $\mathcal{H}_{\mathrm{period}}^{\mathrm{new}}$  的第二维度提取最后  $P - 1$  步的周期性信息，并将其与原始特征拼接，形成新的张量  $\mathcal{H}_{\mathrm{period}}^{\mathrm{all\_new}} \in \mathbb{R}^{dk \times (2P - 1) \times N}$ 。

接着，通过变换层Trans_period（）对  $\mathcal{H}_{\mathrm{period}}^{\mathrm{all\_new}}$  的每一列独立进行参数化变换，得到增强表示的张量  $\hat{\mathcal{H}}_{\mathrm{period}}^{\mathrm{all\_new}} \in \mathbb{R}^{dk \times (2P - 1) \times N}$ ，以提升特征的表达能力。

进一步地，从  $\hat{\mathcal{H}}_{\mathrm{period}}^{\mathrm{all\_new}}$  中利用  $\mathrm{Split}_2(\cdot)$  移除最后一个时间步的信息，并通过线性变换  $\mathrm{Linear}_{\mathrm{trend}}^{\mathrm{new}}(\cdot)$  聚合剩余数据，从而提取趋势性特征，生成  $\mathcal{H}_{\mathrm{trend}}^{\mathrm{new}} \in \mathbb{R}^{dm \times P \times N}$ 。

同时，使用  $\mathrm{Split}_3(\cdot)$  从  $\hat{\mathcal{H}}_{\mathrm{period}}^{\mathrm{all\_new}}$  中提取每个研究对象的最后  $P - 1$  步周期性特征，最终得到  $\hat{\mathcal{H}}_{\mathrm{period}}^{\mathrm{new}} \in \mathbb{R}^{dk \times P \times N}$ 。

综上，该模块通过整合周期性和趋势性特征提取的改进设计，不仅显著提升了模型的表征能力，还有效地降低了计算复杂度。

# 6.2.5 信息融合模块

为了在保留每个研究对象周期性信息和趋势性信息差异性的同时实现信息的有效融合，本小节受  $\mathrm{PGN}^{[108]}$  的启发，引入了基于门控机制的融合方法。这种方法不仅简单高效，还能充分结合周期性和趋势性表示的差异性特征，同时一致性地捕获全局信息。其融合过程如公式（6-7）所示：

$$
\mathcal {H} _ {1} = \operatorname {s i g m o i d} \left(\operatorname {L i n e a r} _ {1} \left(\left[ \mathcal {H} _ {\text {t r e n d}} ^ {\text {n e w}}, \hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {n e w}} \right]\right)\right), \tag {6-7a}
$$

$$
\mathcal {H} _ {2} = \tanh  \left(\operatorname {L i n e a r} _ {2} \left(\left[ \mathcal {H} _ {\text {t r e n d}} ^ {\text {n e w}}, \hat {\mathcal {H}} _ {\text {p e r i o d}} ^ {\text {n e w}} \right]\right)\right), \tag {6-7b}
$$

$$
\mathcal {H} _ {\text {g l o b a l}} = \mathcal {H} _ {1} \odot \mathcal {H} _ {\text {t r e n d}} ^ {\text {n e w}} + (1 - \mathcal {H} _ {1}) \odot \mathcal {H} _ {2}. \tag {6-7c}
$$

在该融合机制中， $\mathrm{Linear}_1(\cdot)$  和  $\mathrm{Linear}_2(\cdot)$  分别表示两个独立的线性变换，作用于拼接后的表示  $[\mathcal{H}_{\mathrm{trend}}^{\mathrm{new}}, \hat{\mathcal{H}}_{\mathrm{period}}^{\mathrm{new}}]$ ，将输入维度从  $dm + dk$  映射到  $dm$ 。门控函数 sigmoid( $\cdot$ ) 生成权重张量  $\mathcal{H}_1 \in \mathbb{R}^{dm \times P \times N}$ ，动态调控趋势性表示  $\mathcal{H}_{\mathrm{trend}}^{\mathrm{new}}$  与变换后的表示  $\mathcal{H}_2$  的相对权重。其中， $\mathcal{H}_2 \in \mathbb{R}^{dm \times P \times N}$  是通过对  $\mathrm{Linear}_2(\cdot)$  的输出应用  $\tanh(\cdot)$  激活函数得到。最终的融合表示  $\mathcal{H}_{\mathrm{global}} \in \mathbb{R}^{dm \times P \times N}$  通过  $\mathcal{H}_{\mathrm{trend}}^{\mathrm{new}}$  和  $\mathcal{H}_2$  的加权求和生成。

这种融合设计使模型能够自适应地平衡周期性信息与趋势性信息的保留程度，从而兼顾了信息提取的差异性和一致性，为下游任务提供稳健且一致的学习表示。

# 6.2.6 预测模块

通过前述建模过程， $\mathcal{H}_{\mathrm{global}}$  已经有效捕获并整合了输入数据  $\mathcal{X}_{2\mathrm{D}}$  中各列的周期性局部信息和趋势性局部信息。这一设计既保留了局部信息提取的差异性，又确保了全局信息提取的一致性。因此，在预测模块中，仅需将信息融合模块的输出  $\mathcal{H}_{\mathrm{global}}$  与待预测的点进行对齐，从而直接生成预测结果。其形式化表达如公式(6-8）所示：

$$
\hat {y} _ {\mathrm {2 D}} = \operatorname {L i n e a r} _ {-} \operatorname {p r e d} \left(\mathcal {H} _ {\text {g l o b a l}}\right), \tag {6-8a}
$$

$$
\hat {\mathbf {Y}} = \operatorname {R e s h a p e} \left(\hat {\mathcal {Y}} _ {2 \mathrm {D}}\right). \tag {6-8b}
$$

在上述公式中，Linear_pred(·) 表示线性变换，将维度为  $dm$  的输入映射到  $F_{\mathrm{period}}$  ，其中  $F_{\mathrm{period}}$  与周期大小  $P$  的乘积等于预测长度  $F$  。随后，通过  $\mathrm{Reshape}(\cdot)$  将二维时间序列输出  $\hat{\mathbf{y}}_{2\mathrm{D}}$  重新排列为一维形式，得到最终的预测结果  $\hat{\mathbf{Y}}$  。此外，归一化系数norm设置为1，在预测结束后进行逆归一化操作，确保预测结果具有物理意义。

# 6.2.7 理论复杂度分析

本节将对精细提取周期性与趋势性特征的方法进行理论复杂度分析。

在提取周期性模式的过程中，时间序列的二维输入首先按照行数  $R$  进行聚合，因此该步骤的复杂度与  $R$  成线性关系。当针对每一列应用不同的参数时，复杂度与列数  $P$  亦成线性关系。随后，在计算近期趋势时，相关操作仍然在列的维度上进行，因此该步骤的复杂度同样与  $P$  成线性关系。在最终的预测阶段，表示被转换为预测行数  $F_{\mathrm{period}}$  ，该步骤的复杂度与  $F_{\mathrm{period}}$  成线性关系。

综上所述，CalendarNet 的时间建模过程在每个步骤中均作用于二维序列的行或列，这表明每一步的理论复杂度均与行数或列数成线性关系。由于二维序列的行数与列数之积等于总序列长度（包括历史长度  $H$  和预测长度  $F$ ），即为  $T$ ，因此整体的理论（时间和空间）复杂度为  $\mathcal{O}(\sqrt{T})$ 。

# 6.3 实验评估

为了验证 CalendarNet 模型在长程时间序列预测中的性能，本节将在第 2.7 节介绍的五个公开数据集上进行广泛实验，对比了十二种具有代表性的基线方法，涵盖了线性模型、CNN、注意力机制、GNN、RNN 等多种架构。并对实验结果从预

测性能、运行效率、模型结构影响以及不同预测长度下的表现等多个角度进行了分析。

# 6.3.1 基线方法

为了全面对比 CalendarNet 与各种代表性方法的性能，本节选取了两个基于注意力的方法：iTransformer[61] 和 Leddam[112]；六个基于线性模型的方法：DLinear[39]、TimeMixer[40]、FITS[41]、SparseTSF[63]、FilterNet[113] 和 TimeKAN[114]；两个基于 CNN 的方法：TimesNet[51] 和 ModernTCN[53]；一个基于 RNN 的方法：SegRNN[106]；以及一个基于 GNN 的方法：CrossGNN[58]，共计十二个基线方法。

# 6.3.2 实验设置

本节聚焦于能源、交通、天气领域的五个公开数据集展开实验。为验证 Cal- darNet 的性能，参考 Pyraformer[56]、WITRAN[104] 和 TPGN[108] 的实验设置，将输入序列长度固定为 168 步，设置 168、336、720 和 1440 四种预测步长。所有模型均基于 PyTorch[102] 实现，并在 NVIDIA RTX 4060Ti 16GB GPU 上进行了实验。

CalendarNet 及所有基线模型均使用 L2 损失函数（MSE）和 Adam 优化器[103]进行训练，初始学习率设为  $10^{-3}$ ，批量大小（Batch size）为 32。最大训练轮数设定为 25，若验证集的 L2 损失在连续 5 轮内未下降，则提前停止训练。随机种子设置为 2023 至 2027，以确保结果的可重复性。

为确保公平比较，本节所有模型的公共参数均与前几章相同：（1）设定模型的隐藏维度  $dk$ 、 $dm$  的范围为  $\{2,4,8,16,32,64,128,256,512,1024\}$ ；（2）设定模型编码器和解码器的层数的范围为  $\{1,2,3\}$ ；（3）设定注意力机制头数的范围固定为 8。对于各模型特有的超参数，参考其原始论文进行确定。所有模型的最佳参数均基于验证集上的最小损失函数值选择，以确保各模型在相同条件下达到最优性能。

# 6.3.3 预测性能分析

每种方法在各预测任务中的表现如表6-2所示。实验结果表明，CalendarNet在绝大多数任务中取得了最佳性能。相较于当前最先进（SOTA）方法，CalendarNet在MSE指标上性能平均提升了  $3.10\%$  至  $17.26\%$  ，在MAE指标上性能平均提升了 $1.07\%$  至  $9.18\%$  ，充分证明了CalendarNet的优越性。

具体而言，CalendarNet 在不同数据集上的表现如下：在  $ECL$  数据集上，CalendarNet 的 MSE 较基准方法性能平均提升了  $6.17\%$  ，MAE 指标上性能平均提升


表 6-2 多变量长程时间序列预测结果



Table 6-2 Multivariate Long-range forecasting results.


<table><tr><td rowspan="2">方法 评价指标</td><td colspan="2">CalendarNet</td><td colspan="2">SCILinear</td><td colspan="2">TimeKAN</td><td colspan="2">FilterNet</td><td colspan="2">SparseTSF</td><td colspan="2">Leddam</td><td colspan="2">FITS</td><td colspan="2">iTransformer</td><td colspan="2">ModernTCN</td><td colspan="2">TimeMixer</td><td colspan="2">CrossGNN</td><td colspan="2">TimesNet</td><td colspan="2">SegRNN</td><td colspan="2">DLinear</td><td></td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td></td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.1533</td><td>0.2421</td><td>0.1534</td><td>0.2462</td><td>0.1607</td><td>0.2512</td><td>0.1554</td><td>0.2488</td><td>0.1618</td><td>0.2493</td><td>0.1548</td><td>0.2432</td><td>0.1725</td><td>0.2629</td><td>0.1574</td><td>0.2487</td><td>0.1671</td><td>0.2648</td><td>0.1551</td><td>0.2445</td><td>0.1674</td><td>0.2627</td><td>0.1951</td><td>0.2938</td><td>0.1559</td><td>0.2494</td><td>0.1683</td><td>0.2603</td></tr><tr><td>168-336</td><td>0.1755</td><td>0.2638</td><td>0.1743</td><td>0.2671</td><td>0.1818</td><td>0.2712</td><td>0.1831</td><td>0.2758</td><td>0.1818</td><td>0.2697</td><td>0.1777</td><td>0.2669</td><td>0.1935</td><td>0.2825</td><td>0.2154</td><td>0.3013</td><td>0.1896</td><td>0.2875</td><td>0.1790</td><td>0.2674</td><td>0.1874</td><td>0.2823</td><td>0.2379</td><td>0.3222</td><td>0.1800</td><td>0.2747</td><td>0.1882</td><td>0.2819</td></tr><tr><td>168-720</td><td>0.2169</td><td>0.2978</td><td>0.2118</td><td>0.2985</td><td>0.2241</td><td>0.3046</td><td>0.2758</td><td>0.3438</td><td>0.2230</td><td>0.3039</td><td>0.2191</td><td>0.3023</td><td>0.2346</td><td>0.3134</td><td>0.2253</td><td>0.3116</td><td>0.2181</td><td>0.3100</td><td>0.2209</td><td>0.3030</td><td>0.2284</td><td>0.3173</td><td>0.2394</td><td>0.3262</td><td>0.2245</td><td>0.3160</td><td>0.2255</td><td>0.3151</td></tr><tr><td>168-1440</td><td>0.2943</td><td>0.3567</td><td>0.2963</td><td>0.3594</td><td>0.3117</td><td>0.3684</td><td>0.3189</td><td>0.3831</td><td>0.3029</td><td>0.3635</td><td>0.2962</td><td>0.3610</td><td>0.3174</td><td>0.3714</td><td>0.3243</td><td>0.3876</td><td>0.2935</td><td>0.3609</td><td>0.2978</td><td>0.3612</td><td>0.3062</td><td>0.3767</td><td>0.3410</td><td>0.3823</td><td>0.3068</td><td>0.3830</td><td>0.2906</td><td>0.3675</td></tr><tr><td rowspan="4">Traffic</td><td>168-168</td><td>0.4127</td><td>0.2653</td><td>0.4516</td><td>0.3007</td><td>0.4709</td><td>0.3038</td><td>0.4176</td><td>0.2746</td><td>0.4443</td><td>0.2792</td><td>0.4181</td><td>0.2703</td><td>0.4803</td><td>0.3059</td><td>0.4001</td><td>0.2655</td><td>0.4548</td><td>0.3020</td><td>0.4480</td><td>0.2947</td><td>0.4875</td><td>0.3180</td><td>0.6539</td><td>0.3427</td><td>0.6235</td><td>0.2899</td><td>0.4793</td><td>0.3052</td></tr><tr><td>168-336</td><td>0.4327</td><td>0.2739</td><td>0.4688</td><td>0.3086</td><td>0.4892</td><td>0.3121</td><td>0.4393</td><td>0.2833</td><td>0.4671</td><td>0.2875</td><td>0.4401</td><td>0.2800</td><td>0.4989</td><td>0.3143</td><td>0.4077</td><td>0.2722</td><td>0.4783</td><td>0.3224</td><td>0.4668</td><td>0.3021</td><td>0.5066</td><td>0.3264</td><td>0.6733</td><td>0.3497</td><td>0.6665</td><td>0.3135</td><td>0.4982</td><td>0.3144</td></tr><tr><td>168-720</td><td>0.4616</td><td>0.2914</td><td>0.4961</td><td>0.3220</td><td>0.5177</td><td>0.3282</td><td>0.4773</td><td>0.3009</td><td>0.4999</td><td>0.3076</td><td>0.4714</td><td>0.2960</td><td>0.5267</td><td>0.3300</td><td>0.4467</td><td>0.2931</td><td>0.5139</td><td>0.3463</td><td>0.5041</td><td>0.3153</td><td>0.5377</td><td>0.3422</td><td>0.6938</td><td>0.3575</td><td>0.7350</td><td>0.3516</td><td>0.5260</td><td>0.3307</td></tr><tr><td>168-1440</td><td>0.5128</td><td>0.3200</td><td>0.5530</td><td>0.3479</td><td>0.5614</td><td>0.3545</td><td>0.5298</td><td>0.3241</td><td>0.5520</td><td>0.3346</td><td>0.5228</td><td>0.3264</td><td>0.5699</td><td>0.3536</td><td>0.4901</td><td>0.3146</td><td>0.5610</td><td>0.3706</td><td>0.5499</td><td>0.3433</td><td>0.5771</td><td>0.3669</td><td>0.7392</td><td>0.3799</td><td>0.8657</td><td>0.4198</td><td>0.5708</td><td>0.3567</td></tr><tr><td rowspan="4">ETh1</td><td>168-168</td><td>0.4379</td><td>0.4644</td><td>0.4556</td><td>0.4686</td><td>0.4717</td><td>0.4774</td><td>0.4804</td><td>0.4870</td><td>0.4870</td><td>0.4785</td><td>0.4722</td><td>0.4734</td><td>0.4732</td><td>0.4698</td><td>0.4787</td><td>0.4849</td><td>0.4936</td><td>0.4953</td><td>0.4773</td><td>0.4794</td><td>0.4933</td><td>0.4931</td><td>0.5586</td><td>0.5378</td><td>0.4639</td><td>0.4836</td><td>0.4653</td><td>0.4671</td></tr><tr><td>168-336</td><td>0.5088</td><td>0.5194</td><td>0.5137</td><td>0.5161</td><td>0.5417</td><td>0.5211</td><td>0.5500</td><td>0.5318</td><td>0.5374</td><td>0.5142</td><td>0.5354</td><td>0.5165</td><td>0.5321</td><td>0.5091</td><td>0.5399</td><td>0.5257</td><td>0.5809</td><td>0.5503</td><td>0.5419</td><td>0.5199</td><td>0.5787</td><td>0.6118</td><td>0.7084</td><td>0.6118</td><td>0.5343</td><td>0.5314</td><td>0.5171</td><td>0.5067</td></tr><tr><td>168-720</td><td>0.6290</td><td>0.6021</td><td>0.6291</td><td>0.5908</td><td>0.6999</td><td>0.6212</td><td>0.6929</td><td>0.6212</td><td>0.6829</td><td>0.6039</td><td>0.6880</td><td>0.6103</td><td>0.6724</td><td>0.5958</td><td>0.7192</td><td>0.6357</td><td>0.7073</td><td>0.6335</td><td>0.6855</td><td>0.6097</td><td>0.7439</td><td>0.6475</td><td>0.7376</td><td>0.6522</td><td>0.6873</td><td>0.6232</td><td>0.6307</td><td>0.5854</td></tr><tr><td>168-1440</td><td>0.7550</td><td>0.6612</td><td>0.7715</td><td>0.6688</td><td>0.8575</td><td>0.7101</td><td>0.8328</td><td>0.7000</td><td>0.7952</td><td>0.6710</td><td>0.8290</td><td>0.6942</td><td>0.7792</td><td>0.6587</td><td>0.8414</td><td>0.6976</td><td>0.8669</td><td>0.7270</td><td>0.9143</td><td>0.7273</td><td>0.12968</td><td>0.8587</td><td>0.8554</td><td>0.7099</td><td>0.8178</td><td>0.6983</td><td>0.7455</td><td>0.6537</td></tr><tr><td rowspan="4">ETh2</td><td>168-168</td><td>0.2631</td><td>0.3523</td><td>0.2671</td><td>0.3515</td><td>0.2692</td><td>0.3495</td><td>0.2675</td><td>0.3506</td><td>0.2719</td><td>0.3490</td><td>0.2682</td><td>0.3452</td><td>0.2639</td><td>0.3414</td><td>0.2752</td><td>0.3541</td><td>0.3007</td><td>0.3691</td><td>0.2721</td><td>0.3531</td><td>0.2708</td><td>0.3821</td><td>0.3213</td><td>0.3832</td><td>0.2700</td><td>0.3538</td><td>0.2659</td><td>0.3432</td></tr><tr><td>168-336</td><td>0.2922</td><td>0.3813</td><td>0.3192</td><td>0.3942</td><td>0.3217</td><td>0.3864</td><td>0.3140</td><td>0.3826</td><td>0.3182</td><td>0.3799</td><td>0.3233</td><td>0.3832</td><td>0.3117</td><td>0.3743</td><td>0.3291</td><td>0.3907</td><td>0.3411</td><td>0.3970</td><td>0.3216</td><td>0.3864</td><td>0.3262</td><td>0.3901</td><td>0.3393</td><td>0.3999</td><td>0.3232</td><td>0.3928</td><td>0.3143</td><td>0.3775</td></tr><tr><td>168-720</td><td>0.3765</td><td>0.4399</td><td>0.4121</td><td>0.4500</td><td>0.4038</td><td>0.4358</td><td>0.4021</td><td>0.4378</td><td>0.4070</td><td>0.4332</td><td>0.4083</td><td>0.4336</td><td>0.3895</td><td>0.4216</td><td>0.4147</td><td>0.4403</td><td>0.4177</td><td>0.4437</td><td>0.3994</td><td>0.4349</td><td>0.4056</td><td>0.4360</td><td>0.4496</td><td>0.4622</td><td>0.4009</td><td>0.4412</td><td>0.4028</td><td>0.4319</td></tr><tr><td>168-1440</td><td>0.4845</td><td>0.5061</td><td>0.5497</td><td>0.5388</td><td>0.6090</td><td>0.5517</td><td>0.5813</td><td>0.5407</td><td>0.6082</td><td>0.5490</td><td>0.5949</td><td>0.5401</td><td>0.5703</td><td>0.5269</td><td>0.6221</td><td>0.5539</td><td>0.6064</td><td>0.5475</td><td>0.5956</td><td>0.5449</td><td>0.6063</td><td>0.5526</td><td>0.6040</td><td>0.5571</td><td>0.5578</td><td>0.5276</td><td>0.6062</td><td>0.5473</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.5007</td><td>0.5120</td><td>0.5042</td><td>0.5156</td><td>0.5336</td><td>0.5223</td><td>0.5317</td><td>0.5160</td><td>0.5624</td><td>0.5381</td><td>0.5094</td><td>0.5033</td><td>0.5469</td><td>0.5253</td><td>0.5243</td><td>0.5177</td><td>0.5122</td><td>0.5101</td><td>0.5395</td><td>0.5206</td><td>0.5094</td><td>0.5199</td><td>0.5186</td><td>0.5124</td><td>0.5189</td><td>0.5208</td><td>0.5340</td><td>0.5261</td></tr><tr><td>168-336</td><td>0.5408</td><td>0.5416</td><td>0.5441</td><td>0.5452</td><td>0.5670</td><td>0.5483</td><td>0.5748</td><td>0.5444</td><td>0.5974</td><td>0.5609</td><td>0.5558</td><td>0.5353</td><td>0.5885</td><td>0.5532</td><td>0.5688</td><td>0.5462</td><td>0.5502</td><td>0.5368</td><td>0.5791</td><td>0.5493</td><td>0.5412</td><td>0.5405</td><td>0.5551</td><td>0.5338</td><td>0.5602</td><td>0.5500</td><td>0.5704</td><td>0.5523</td></tr><tr><td>168-720</td><td>0.5958</td><td>0.5718</td><td>0.5859</td><td>0.5704</td><td>0.6300</td><td>0.5871</td><td>0.6199</td><td>0.5758</td><td>0.6674</td><td>0.5997</td><td>0.6145</td><td>0.5693</td><td>0.6632</td><td>0.5949</td><td>0.6089</td><td>0.5685</td><td>0.6028</td><td>0.5709</td><td>0.6350</td><td>0.5844</td><td>0.5880</td><td>0.5755</td><td>0.5934</td><td>0.5536</td><td>0.6168</td><td>0.5816</td><td>0.5927</td><td></td></tr><tr><td>168-1440</td><td>0.6531</td><td>0.6164</td><td>0.6323</td><td>0.6136</td><td>0.7706</td><td>0.6772</td><td>0.7453</td><td>0.6516</td><td>0.8276</td><td>0.6900</td><td>0.7100</td><td>0.6299</td><td>0.8285</td><td>0.6878</td><td>0.6362</td><td>0.5912</td><td>0.6929</td><td>0.6270</td><td>0.7473</td><td>0.6527</td><td>0.6700</td><td>0.6315</td><td>0.5827</td><td>0.5535</td><td>0.7471</td><td>0.6606</td><td>0.7178</td><td>0.6556</td></tr><tr><td colspan="3">CalendarNet 的平均提升百分比</td><td>3.10%</td><td>2.79%</td><td>8.28%</td><td>4.66%</td><td>6.91%</td><td>3.36%</td><td>8.17%</td><td>3.03%</td><td>4.69%</td><td>1.07%</td><td>8.96%</td><td>4.10%</td><td>5.49%</td><td>2.52%</td><td>8.44%</td><td>6.08%</td><td>7.29%</td><td>3.54%</td><td>10.15%</td><td>7.10%</td><td>17.26%</td><td>9.18%</td><td>11.96%</td><td>5.79%</td><td>6.74%</td><td>4.01%</td><td></td></tr></table>


* 最好的结果用加粗标出，第二好的结果用下划线标出


了  $5.16\%$  ；在 Traffic 数据集上，MSE 指标上性能平均提升了  $9.53\%$  ，MAE 指标上性能平均提升了  $9.14\%$  ；在  $ETTh_{1}$  数据集上，MSE 指标上性能平均提升了  $9.96\%$  ，MAE 指标上性能平均提升了  $4.09\%$  ；在  $ETTh_{2}$  数据集上，MSE 指标上性能平均提升了  $10.38\%$  ，MAE 指标上性能平均提升了  $2.32\%$  ；在 Weather 数据集上，MSE 指标上性能平均提升了  $4.69\%$  ，MAE 指标上性能平均提升了  $1.25\%$  。

这些结果表明，CalendarNet在不同领域的长程时间序列预测任务中均能达到甚至超越SOTA性能。这表明本章设计的万年历式信息提取模块能够很好地捕获时间序列中耦合的多种复杂时间模式。

# 6.3.4 运行效率分析

![](images/a94c15e476ebebe5de9512a54c59d0d6a9a379ee9416b7122844831050d3f880.jpg)



(a) 时间开销情况（输入长度固定为168）


![](images/719eabd26df065b8c0ff24ad50d49e0512a303d3ba69288bb18eac4da09f8a74.jpg)



(b) 显存占用情况（输入长度固定为168）


![](images/048153894092f76848e523f7a965c1f3a7df236bf7aaec7eb12e9e423a6d9001.jpg)



(c) 时间开销情况（输出长度固定为1440）


![](images/dd39cdf3ad86f3781635a9deebe54a177c11b3067dc296b9641e1b369a16a264.jpg)



(d) 显存占用情况（输出长度固定为1440）



图6-5 不同模型的时间和内存开销



Fig 6-5 Time and memory overhead of different models.


为了全面评估本章提出的 CalendarNet 模型在实际应用中的运行效率，本小节设计了两组对比实验：在第一组实验中，固定输入长度为 168，输出长度分别设置

为 168、336、720 和 1440，以考察预测长度对模型效率的影响。第二组实验固定输出长度为 1440，调整输入长度为 168、336、720 和 1440，以分析历史输入序列长度的影响。

效率分析考虑了时间开销和显存占用两个方面。对比方法选取了表6-2中具有代表性的模型，并在批量大小为32、模型维度为128、单层模型的条件下进行测试，以排除公共参数对结果的影响。

本小节对模型的预测效率进行了全面评估，涵盖性能、推理时间以及内存消耗等方面。实验结果如图6-5所示，CalendarNet在效率评估中展现出显著优势，不仅实现了最佳的预测性能，同时还保持了最低的推理延迟和内存开销，充分体现了其在实际应用中的优越性。

# 6.3.5 模型分析及讨论

本小节主要通过消融实验、鲁棒性分析、参数敏感性分析和案例分析四种多维度方法，系统性地对CalendarNet进行全面深入的剖析，旨在多角度证实该模型在长周期时序预测任务中的卓越性能。

# (1) 消融实验

在本节中，进行了消融实验，以验证周期提取模块、趋势提取模块和信息聚合模块的有效性。具体来说，逐一去除这些模块，并将其与原始的 CalendarNet 进行性能对比。同时，本节还验证了改进版周期提取和趋势提取方法。实验结果如表 6-3 所示，展示了不同配置对长程时间序列预测任务中模型性能的影响。

在表6-3中，“w/o fusion”表示去除了信息融合模块，“w/o trend”表示去除了趋势提取模块，“w/o period”表示去除了周期提取模块。“w/o improve of trend”表示未使用改进版趋势提取模块，尽管模型仍然进行趋势信息提取。同样，“w/o improve of period”表示未使用改进版周期提取模块，但模型仍然会进行周期模式的提取。通过比较每种配置下的平均绝对误差（MAE）和均方误差（MSE），观察到在去除每个模块后，模型的预测性能普遍下降。这表明周期提取模块、趋势提取模块和信息聚合模块在提升模型预测能力方面起到了至关重要的作用。此外，通过改进前后的周期提取模块和趋势提取模块的实验结果对比，进一步验证了这些改进的有效性。

总体而言，消融实验的结果清楚地展示了每个模块和改进方法对 CalendarNet 性能提升的贡献，为设计选择提供了有力支持。

# (2) 鲁棒性分析

为评估 CalendarNet 在噪声干扰下的稳定性, 本小节参考 MICN[26] 和 WITRAN[104]


表 6-3 长程时间序列预测任务的消融研究结果



Table 6-3 Results of the ablation study on long-range forecasting tasks.


<table><tr><td rowspan="2" colspan="2">方法 评价指标</td><td colspan="2">CalendarNet</td><td colspan="2">w/o fusion</td><td colspan="2">w/o trend</td><td colspan="2">w/o period</td><td colspan="2">w/o improve of trend</td><td colspan="2">w/o improve of period</td></tr><tr><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td></tr><tr><td rowspan="4">ECL</td><td>168-168</td><td>0.2421</td><td>0.1533</td><td>0.2521</td><td>0.1587</td><td>0.2531</td><td>0.1634</td><td>0.2856</td><td>0.1838</td><td>0.2599</td><td>0.1751</td><td>0.2615</td><td>0.1743</td></tr><tr><td>168-336</td><td>0.2638</td><td>0.1755</td><td>0.2768</td><td>0.1836</td><td>0.2771</td><td>0.1870</td><td>0.3100</td><td>0.2104</td><td>0.2856</td><td>0.2013</td><td>0.2857</td><td>0.2121</td></tr><tr><td>168-720</td><td>0.2978</td><td>0.2169</td><td>0.3142</td><td>0.2236</td><td>0.3139</td><td>0.2291</td><td>0.3369</td><td>0.2427</td><td>0.3262</td><td>0.2955</td><td>0.3286</td><td>0.2697</td></tr><tr><td>168-1440</td><td>0.3567</td><td>0.2943</td><td>0.3892</td><td>0.3222</td><td>0.3919</td><td>0.3322</td><td>0.4093</td><td>0.3417</td><td>0.3858</td><td>0.3296</td><td>0.3858</td><td>0.3277</td></tr><tr><td rowspan="4">Traffic</td><td>168-168</td><td>0.2653</td><td>0.4127</td><td>0.3170</td><td>0.4830</td><td>0.3113</td><td>0.4956</td><td>0.3399</td><td>0.5183</td><td>0.2913</td><td>0.5124</td><td>0.2910</td><td>0.5162</td></tr><tr><td>168-336</td><td>0.2739</td><td>0.4327</td><td>0.3250</td><td>0.5014</td><td>0.3190</td><td>0.5116</td><td>0.3474</td><td>0.5345</td><td>0.2954</td><td>0.5359</td><td>0.2946</td><td>0.5243</td></tr><tr><td>168-720</td><td>0.2914</td><td>0.4616</td><td>0.3437</td><td>0.5313</td><td>0.3309</td><td>0.5408</td><td>0.3620</td><td>0.5619</td><td>0.3080</td><td>0.5451</td><td>0.3080</td><td>0.5477</td></tr><tr><td>168-1440</td><td>0.3200</td><td>0.5128</td><td>0.3753</td><td>0.5839</td><td>0.3627</td><td>0.5909</td><td>0.3895</td><td>0.6085</td><td>0.3409</td><td>0.6442</td><td>0.3419</td><td>0.6533</td></tr><tr><td rowspan="4">ETTh1</td><td>168-168</td><td>0.4644</td><td>0.4379</td><td>0.4726</td><td>0.4740</td><td>0.4691</td><td>0.4839</td><td>0.4760</td><td>0.4766</td><td>0.4751</td><td>0.4818</td><td>0.4802</td><td>0.4862</td></tr><tr><td>168-336</td><td>0.5194</td><td>0.5088</td><td>0.5168</td><td>0.5438</td><td>0.5117</td><td>0.5470</td><td>0.5212</td><td>0.5495</td><td>0.5431</td><td>0.5804</td><td>0.5421</td><td>0.5766</td></tr><tr><td>168-720</td><td>0.6021</td><td>0.6290</td><td>0.6006</td><td>0.6805</td><td>0.6021</td><td>0.6825</td><td>0.6106</td><td>0.6888</td><td>0.6336</td><td>0.7256</td><td>0.6386</td><td>0.7296</td></tr><tr><td>168-1440</td><td>0.6612</td><td>0.7550</td><td>0.6670</td><td>0.8007</td><td>0.6696</td><td>0.8054</td><td>0.7234</td><td>0.9260</td><td>0.6707</td><td>0.8007</td><td>0.7243</td><td>0.9172</td></tr><tr><td rowspan="4">ETTh2</td><td>168-168</td><td>0.3523</td><td>0.2631</td><td>0.3543</td><td>0.2684</td><td>0.3559</td><td>0.2795</td><td>0.3554</td><td>0.2704</td><td>0.3607</td><td>0.2814</td><td>0.3596</td><td>0.2799</td></tr><tr><td>168-336</td><td>0.3813</td><td>0.2922</td><td>0.3872</td><td>0.3291</td><td>0.3978</td><td>0.3454</td><td>0.3916</td><td>0.3334</td><td>0.3962</td><td>0.3382</td><td>0.3941</td><td>0.3374</td></tr><tr><td>168-720</td><td>0.4399</td><td>0.3765</td><td>0.4425</td><td>0.4207</td><td>0.4479</td><td>0.4381</td><td>0.4442</td><td>0.4295</td><td>0.4651</td><td>0.4598</td><td>0.4584</td><td>0.4481</td></tr><tr><td>168-1440</td><td>0.5061</td><td>0.4845</td><td>0.5504</td><td>0.6225</td><td>0.5630</td><td>0.6489</td><td>0.5608</td><td>0.6468</td><td>0.5342</td><td>0.5894</td><td>0.5430</td><td>0.6061</td></tr><tr><td rowspan="4">Weather</td><td>168-168</td><td>0.5120</td><td>0.5007</td><td>0.5183</td><td>0.5100</td><td>0.5422</td><td>0.5377</td><td>0.5230</td><td>0.5131</td><td>0.5175</td><td>0.5077</td><td>0.5187</td><td>0.5122</td></tr><tr><td>168-336</td><td>0.5416</td><td>0.5408</td><td>0.5493</td><td>0.5504</td><td>0.5633</td><td>0.5685</td><td>0.5516</td><td>0.5528</td><td>0.5421</td><td>0.5402</td><td>0.5462</td><td>0.5434</td></tr><tr><td>168-720</td><td>0.5718</td><td>0.5958</td><td>0.5896</td><td>0.6133</td><td>0.5995</td><td>0.6271</td><td>0.5894</td><td>0.6133</td><td>0.5725</td><td>0.5975</td><td>0.5747</td><td>0.5993</td></tr><tr><td>168-1440</td><td>0.6164</td><td>0.6531</td><td>0.6582</td><td>0.7109</td><td>0.6680</td><td>0.7226</td><td>0.6565</td><td>0.7059</td><td>0.6185</td><td>0.6556</td><td>0.7179</td><td>0.9012</td></tr></table>


* 最好的结果用加粗标出，第二好的结果用下划线标出


的实验设置，采用白噪声扰动对模型的鲁棒性进行测试。具体而言，在原始输入序列中随机选取一定比例  $(\varepsilon)$  的数据，并对其施加幅度范围为  $[-2X_{i}, 2X_{i}]$  的随机扰动，其中  $X_{i}$  为原始数据值。随后，使用加入噪声后的数据进行训练，并分析模型的预测表现（见表6-4）。

实验结果表明，随着噪声比例的增加，MSE和MAE指标虽有所波动，但整体变化较小。在噪声比例最高达到  $10\%$  的情况下，CalendarNet依然能够保持稳定的预测效果，表明其在应对数据异常波动时具有较强的鲁棒性。

# (3) 参数敏感性分析

与第四章和第五章类似，本章同样对超参数 norm 进行了重点分析。本部分对不同任务的数据集进行了统计分析，结果如表6-5所示。其中，ECL、ETTh<sub>1</sub>、ETTh<sub>2</sub> 和 Weather 四个数据集的统计结果来源于第五章，本章在此基础上新增了 Traffic 数据集的统计结果，以进一步完善分析的全面性。

结合数据统计结果与第五章对超参数norm的分析，可以发现，当数据集的标准差（STD）过小（小于0.5）或过大（大于0.9）时，分别表明数据整体变化幅度较小或波动性较强。在这类情况下，将超参数norm设定为1，有助于通过归一化平衡数据分布，从而提升模型的训练效果和稳定性。而当STD处于0.5至0.9之间时，超参数norm设为1或0均能获得较好的训练效果，表明模型在该范围内对norm具有一定的鲁棒性。


表 6-4 CalendarNet 预测结果的鲁棒性实验



Table 6-4 Robustness experiments of CalendarNet's forecasting results.


<table><tr><td colspan="2">预测任务</td><td colspan="2">168-168</td><td colspan="2">168-336</td><td colspan="2">168-720</td><td colspan="2">168-1440</td></tr><tr><td colspan="2">评价指标</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan="4">ECL</td><td>ε = 0%</td><td>0.1533</td><td>0.2421</td><td>0.1755</td><td>0.2638</td><td>0.2169</td><td>0.2978</td><td>0.2943</td><td>0.3567</td></tr><tr><td>ε = 1%</td><td>0.1531</td><td>0.2416</td><td>0.1757</td><td>0.2646</td><td>0.2172</td><td>0.2979</td><td>0.2945</td><td>0.3567</td></tr><tr><td>ε = 5%</td><td>0.1531</td><td>0.2411</td><td>0.1760</td><td>0.2644</td><td>0.2178</td><td>0.2977</td><td>0.2957</td><td>0.3563</td></tr><tr><td>ε = 10%</td><td>0.1534</td><td>0.2413</td><td>0.1755</td><td>0.2649</td><td>0.2183</td><td>0.2981</td><td>0.2985</td><td>0.3580</td></tr><tr><td rowspan="4">Traffic</td><td>ε = 0%</td><td>0.4127</td><td>0.2653</td><td>0.4327</td><td>0.2739</td><td>0.4616</td><td>0.2914</td><td>0.5128</td><td>0.3200</td></tr><tr><td>ε = 1%</td><td>0.4122</td><td>0.2647</td><td>0.4324</td><td>0.2735</td><td>0.4729</td><td>0.2968</td><td>0.5125</td><td>0.3198</td></tr><tr><td>ε = 5%</td><td>0.4119</td><td>0.2637</td><td>0.4326</td><td>0.2725</td><td>0.4607</td><td>0.2897</td><td>0.5123</td><td>0.3193</td></tr><tr><td>ε = 10%</td><td>0.4116</td><td>0.2631</td><td>0.4322</td><td>0.2726</td><td>0.4726</td><td>0.2961</td><td>0.5124</td><td>0.3188</td></tr><tr><td rowspan="4">ETTh1</td><td>ε = 0%</td><td>0.4379</td><td>0.4644</td><td>0.5088</td><td>0.5194</td><td>0.6290</td><td>0.6021</td><td>0.7550</td><td>0.6612</td></tr><tr><td>ε = 1%</td><td>0.4381</td><td>0.4648</td><td>0.5088</td><td>0.5146</td><td>0.6292</td><td>0.6024</td><td>0.7549</td><td>0.6610</td></tr><tr><td>ε = 5%</td><td>0.4385</td><td>0.4655</td><td>0.5018</td><td>0.5126</td><td>0.6298</td><td>0.6028</td><td>0.7562</td><td>0.6611</td></tr><tr><td>ε = 10%</td><td>0.4387</td><td>0.4661</td><td>0.5031</td><td>0.5137</td><td>0.6311</td><td>0.6038</td><td>0.7520</td><td>0.6645</td></tr><tr><td rowspan="4">ETTh2</td><td>ε = 0%</td><td>0.2631</td><td>0.3523</td><td>0.2922</td><td>0.3813</td><td>0.3765</td><td>0.4399</td><td>0.4845</td><td>0.5061</td></tr><tr><td>ε = 1%</td><td>0.2616</td><td>0.3526</td><td>0.2618</td><td>0.3579</td><td>0.3680</td><td>0.4398</td><td>0.4851</td><td>0.5064</td></tr><tr><td>ε = 5%</td><td>0.2609</td><td>0.3525</td><td>0.2628</td><td>0.3595</td><td>0.3651</td><td>0.4384</td><td>0.4928</td><td>0.5103</td></tr><tr><td>ε = 10%</td><td>0.2613</td><td>0.3544</td><td>0.2626</td><td>0.3608</td><td>0.3607</td><td>0.4358</td><td>0.5029</td><td>0.5153</td></tr><tr><td rowspan="4">Weather</td><td>ε = 0%</td><td>0.5007</td><td>0.5120</td><td>0.5408</td><td>0.5416</td><td>0.5958</td><td>0.5718</td><td>0.6531</td><td>0.6164</td></tr><tr><td>ε = 1%</td><td>0.5010</td><td>0.5122</td><td>0.5410</td><td>0.5420</td><td>0.5943</td><td>0.5707</td><td>0.6489</td><td>0.6137</td></tr><tr><td>ε = 5%</td><td>0.5016</td><td>0.5125</td><td>0.5425</td><td>0.5447</td><td>0.5958</td><td>0.5727</td><td>0.6473</td><td>0.6130</td></tr><tr><td>ε = 10%</td><td>0.5019</td><td>0.5128</td><td>0.5434</td><td>0.5493</td><td>0.5951</td><td>0.5715</td><td>0.6568</td><td>0.6185</td></tr></table>


* 不同的  $\varepsilon$  表示不同的噪声注入比例。



表 6-5 训练集中数据集的分布 (标准差)



Table 6-5 The distribution (STD) of dataset in the training sets.


<table><tr><td rowspan="2">数据集 预测任务</td><td colspan="2">ECL</td><td colspan="2">Traffic</td><td colspan="2">ETTh1</td><td colspan="2">ETTh2</td><td colspan="2">Weather</td></tr><tr><td>STD</td><td>norm</td><td>STD</td><td>norm</td><td>STD</td><td>norm</td><td>STD</td><td>norm</td><td>STD</td><td>norm</td></tr><tr><td>168-168</td><td>0.9085</td><td></td><td>0.9805</td><td></td><td>0.6142</td><td></td><td>0.5550</td><td></td><td>0.6989</td><td></td></tr><tr><td>168-336</td><td>0.9112</td><td rowspan="2">1</td><td>0.9842</td><td rowspan="2">1</td><td>0.6655</td><td rowspan="2">0</td><td>0.5395</td><td rowspan="2">0</td><td>0.6964</td><td rowspan="2">0</td></tr><tr><td>168-720</td><td>0.9119</td><td>0.9833</td><td>0.6564</td><td>0.5405</td><td>0.6974</td></tr><tr><td>168-1440</td><td>0.9118</td><td></td><td>0.9820</td><td></td><td>0.6456</td><td></td><td>0.5440</td><td></td><td>0.6991</td><td></td></tr></table>

# (4) 数据集分析

为了衡量各个数据集变量之间的相关性，这里采用皮尔逊相关系数（Pearson Correlation Coefficient）来表示各个变量之间的相关性，并利用热力图直观展示变量间的相关性。如图6-6所示，颜色越偏向红色表示正相关性越强，而颜色越偏向蓝色则表示负相关性越强。由图中可以看出，ECL和Traffic数据集的热力图整体呈现明显的红色区域，说明其中各变量之间正相关性较强，因而难以实现独立建模；而  $ETTh_{1}$  、  $ETTh_{2}$  和Weather数据集的热力图中，红色区域相对较少，表明这些数据集的变量相关性不够显著。综上，ECL数据集同时展现出一致性和差异性，Traffic数据集展现出高度的一致性。然而，  $ETTh_{1}$  、  $ETTh_{2}$  和Weather数据集的一致性较弱，主要以差异性占主导。

# (5) 案例分析

为展示 CalendarNet 在长程时间序列预测任务中的优势，本节随机选择了两个

![](images/a77826f1e479559ef6ac3ad6661b4a1e15a27a46358b691a9e5dd87d678f761c.jpg)



(a) ECL 数据集


![](images/40de806c923541d5ffbea5854731ba9aba08dc47e8d75e6e5722cc465d1ae7e3.jpg)



(b) Traffic 数据集


![](images/709cdd161210c449aa5d74ceaf5075ca1ea72d1dc99fff68d2e10f9f7755b920.jpg)



(c)  $\mathrm{ETTh}_1$  数据集


![](images/88621dea1a0d90333884557c1a8d49b35a4e7ef6a34fb812da12285fa571b45f.jpg)



(d)  $\mathrm{ETTh}_2$  数据集


![](images/0142a97e2860a7e406619082ad185552c45de889c250d96464a5bba9eaf9cff2.jpg)



(e) Weather 数据集



图6-6 各个数据集热力图



Fig 6-6 Heatmaps of different datasets.


数据集—— $ETTh_{1}$  数据集和 Weather 数据集，并将 CalendarNet 的预测结果与基于均方误差（MSE）评估指标选出的第二优和第三优模型的预测结果进行对比，结果如图6-7至6-12所示。

从  $ETTh_{1}$  数据集的实验结果（如图6-7至图6-9）可以看出，CalendarNet在电力负载预测任务中表现出色。该模型能够精确捕捉时间序列中的趋势性与周期性模式，如在短期预测的200-220时间点区间内的波动变化上。在长期预测方面，CalendarNet在220-280时间点区间内成功保持了与真实数据相近的趋势，展示了其优越的稳定性。此外，CalendarNet还能够准确预测电力负载中的波峰和波谷，如中长期预测的195时间点附近的波谷，以及长期预测230和780时间点附近的波峰。最重要的是，在短序列输入的条件下，CalendarNet能够准确预测出未来长时间段内的变化，避免了明显的异常波动或跳变，保持了稳定的性能。相比之下，DLinear的结果与真实值在均值上存在较大偏差，不能较好地捕捉序列地变化趋势；FITS的结果中高频成分又偏离真实值较多，在捕捉时间序列周期性上表现欠佳。

在Weather数据集的实验中（如图6-10至图6-12），CalendarNet也展现出了卓越的性能。对于超长时间序列预测，CalendarNet能够精确捕捉幅度变化，尤其在600-960时间点区间内的表现明显优于iTransformer和TimesNet等对比模型，在

![](images/4e09cff4f681115e2a9161baba8b6236bc512999f100365b94e37e819848f06c.jpg)


![](images/aaf1c7895225f09e2089f97a716fe58c61b0c944e97c7fc6ea2cc001e5fb55f7.jpg)


![](images/96a537817bbd34c643dcb61681b5ed6c581b0fa846f29acbec94fb86e7c9fb41.jpg)


![](images/f000cf7769097d5339e846b5a1b07d4b86f1752ee6c057119909dbff56c362be.jpg)



图6-7 CalendarNet在数据集  $\mathrm{ETTh}_1$  中的所有任务预测案例



Fig 6-7 Forecasting cases of CalendarNet for all tasks in dataset  $\mathrm{ETTh}_1$ .


![](images/9ef41d8ae1ef2074b5406b7775b08ac18d86eaa3b53eb1793e099a8730f52c7c.jpg)


![](images/badf55ddf7e041895a124c381a50769af031dd9c49e82515786aad74f9cda104.jpg)


![](images/ad41422cb761e2ae4d952f3acffb66dc4bc6029893e9e15f23d9c3141f262b63.jpg)


![](images/46bfde7a1422fd6cb1fcf7415017e9216676a0630e02a1a11899dc814cebd2a9.jpg)



图6-8 DLinear在数据集  $\mathrm{ETTh}_1$  中的所有任务预测案例



Fig 6-8 Forecasting cases of DLinear for all tasks in dataset  $\mathrm{ETTh}_1$


![](images/28629e4a59baa9e3075952ff2e25ff886dc52894065917d77ee07184fcc76974.jpg)


![](images/6e0ee391adb90e410622012e3d50cc843e55cd2cdc5bc2f9c2d4402cf82622dd.jpg)


![](images/8bd334a1bb6e49bf28ad23cb8cd49563845eecf4ce5cf811d3ae46fb7286600b.jpg)


![](images/4936d7c004cab604a58c4a0110f19e76aa96ac572f4cb1b6b1752f8bffabc781.jpg)



图6-9 FITS在数据集  $\mathrm{ETTh}_1$  中的所有任务预测案例



Fig 6-9 Forecasting cases of FITS for all tasks in dataset ETTh<sub>1</sub>.


![](images/b81e54da92d9f139b0219307c1070f30bccb8ca92f02e2fd393879d701bbad28.jpg)


![](images/99963a367e6375bf5dd563e5d24e7f48a0698849bc810af63bbd6d885c589116.jpg)


![](images/385c3cff9200a259ff9a9838c1239e5c0ec9b3c8057acdcc8294cab1c4ae29d7.jpg)


![](images/f5ae37041b0e9c07a863ddd1b31a62d3b8b31067b0390c714ca1786be359f052.jpg)



图6-10 CalendarNet在数据集Weather中的所有任务预测案例



Fig 6-10 Forecasting cases of CalendarNet for all tasks in dataset Weather.


![](images/f786e367f600a23b44a054ecfcda0431d3075c8279d4227f6a18ea95c5508d3d.jpg)


![](images/fee01b6b8dada9ba42b2e25b4bc134838888f402bd6f85e0d0d439a0605fb6a7.jpg)


![](images/afd74d0fc0e1059855c009e6dd222d03752f7fac4ae9c5640ac5b0ce2d21d661.jpg)


![](images/36778d53a592c7adbb30905ddd76dfb08dde97ad10ba14c8771ea3e81a70508b.jpg)



图6-11 iTransformer在数据集Weather中的所有任务预测案例



Fig 6-11 Forecasting cases of iTransformer for all tasks in dataset Weather.


![](images/877d6de734d272b36a7b4364a0d49af0e02593153172163551f0d49fa5fffb22.jpg)


![](images/752e799341b246838a420b02943586f21e7478ec0565287ac67059025a7387ce.jpg)


![](images/39dd7613997ded5fb04a94d269c4028815c612dcf3362e0069623d5e73d5a244.jpg)


![](images/7e44f1cc15d72cd704faa366794359d6e48ae044664ae785150e6b00baa2cb1c.jpg)



图6-12 TimesNet在数据集Weather中的所有任务预测案例



Fig 6-12 Forecasting cases of TimesNet for all tasks in dataset Weather.


960-1440时间点的预测中，CalendarNet依然能够维持与真实数据接近的波动幅度和频率。此外，CalendarNet在识别复杂波动模式方面具有明显优势，能够较好捕捉超长期下的趋势性和周期性波动模式。对比模型中的iTransformer虽能较好地捕捉周期变化，但预测值与真实值差距较大；TimesNet在短期任务中能够捕捉周期性模式和波动特征，但在超长期任务中预测值随时间步增加明显偏离了真实值，难以捕获序列的趋势性变化。

综上所述，CalendarNet凭借其独特的模型架构和优化策略，成功解决了时间序列预测中的多项挑战，并在多种应用场景中展现出优异的表现。进一步验证了该方法可为电力负载、能源监测、气象分析、交通管理等领域的长程预测任务提供了高效、精确的解决方案，具有广泛应用潜力和深远的实际价值。

# 6.4 本章小结

本章提出了一种新的万年历式信息提取的多变量长程时间序列预测方法，该方法借鉴万年历的循环结构，将一维时间序列转换为二维布局，并结合滑动窗口与门控机制，在捕获复杂时间模式、减少信息传递损失的同时，兼顾时间与变量两个维度的信息提取一致性与差异性，既确保特征信息的充分利用，又保留时间模式的个性化特征，使得预测更加的准确和稳定。

CalendarNet采用了线性层和简单的门控机制，避免了使用多个分支进行信息提取，从而实现了简洁而高效的设计。通过在五个基准多变量数据集上的实验，结果显示，CalendarNet在长程时间序列预测任务中，均方误差较最先进（SOTA）方法（MSE）平均提升了  $3.10\%$  到  $17.26\%$  ，表现出了优越的性能。

此外，CalendarNet 的理论复杂度为  $\mathcal{O}(\sqrt{T})$  ，实际评估显示其计算开销较小。这些结果表明，CalendarNet 不仅在建模精度上具有显著优势，而且在效率上也表现出色，为时间序列预测领域提供了一种有效的新思路和支撑方法。

# 7 总结与展望

# 7.1 论文工作总结

本文围绕长程时间序列预测任务展开研究，旨在解决确保高预测精度和高运行效率的双重挑战。针对时间序列数据中复杂时间模式信息提取、信息传递路径过长引发的信息损失、多变量间异质性导致的模式识别性能下降及关键信息丢失，以及信息提取的一致性与差异性之间的矛盾等问题，本文提出了一系列创新性解决方案，并在多个公开数据集上验证了其有效性。具体工作总结如下：

(1) 针对时间序列数据中复杂时间模式难以有效提取的挑战，本文提出了水波型信息传递的长程时间序列预测方法（WITRAN）。通过双方向信息传递机制和双粒度门控选择单元（HVGSU），WITRAN能够同时从长期和短期的尺度上，捕获趋势性和周期性模式，并逐渐从局部模式捕获到全局模式，显著提升了预测精度。此外，RAN加速框架的引入进一步优化了模型的运算效率。实验结果表明，WITRAN在多个领域的长程时间序列预测任务上表现出色。

(2) 针对信息传递路径过长导致的信息损失问题, 本文提出了并行门控网络 (PGN)。PGN 通过缩短信息传递路径至  $\mathcal{O}(1)$ , 显著提升了序列间依赖关系的捕获能力, 同时保持了  $\mathcal{O}(T)$  的理论复杂度。基于 PGN, 本文进一步提出了时间并行门控网络 (TPGN), 通过双分支结构分别从长期和短期尺度上, 捕获局部周期性和全局趋势性模式, 实现了复杂时间模式的充分捕获。实验结果表明, TPGN 在长程时间序列预测任务中的性能和效率均优于现有方法。

(3) 针对多变量间异质性导致的模式识别准确性下降及关键信息丢失问题, 本文提出了变量完全独立建模 (SCI) 的多变量长程时间序列预测方法。通过为每个变量分配独立参数, 并在关键层进行使用, SCI 有效消除了变量异质性带来的噪声干扰, 同时保持了  $\mathcal{O}(N)$  的计算复杂度。结合基于线性变换的双分支 (DB) 时间建模框架, 该方法进一步实现了对周期性和趋势性模式的高效捕获, 并在多个基准数据集上验证了其预测精度的显著提升。

(4) 针对信息提取的一致性与差异性之间的平衡问题, 本文提出了一种万年历式信息提取方式, 并适配性地引入 SCI 或变量独立建模 (CI) 方式, 构建成为 CalendarNet, 以从时间维度和变量双维度兼顾信息的一致性与差异性提取, 而适用于多变量长程时间序列预测任务。通过在多个基准数据集上的实验验证, 结果表明 CalendarNet 在预测性能、计算效率和适用性方面均展现出卓越的表现, 具备强有效性、高效性和通用性。

总结而言，四种方法各具优势与局限性：前两种方法主要聚焦于时间维度的信息建模，而后两种模型则实现了时间维度与变量维度的协同建模。（1）WITRAN方法在复杂时间模式的提取方面具有开创性，为后续研究提供了重要的理论基础和方法启示；（2）PGN创新范式通过优化信息传递路径，在降低信息损耗的同时提升了并行计算效率，其衍生方法TPGN在长程时间序列预测中展现出卓越的精度与效率优势，这些特性在第三、四章的实验中得到了充分验证；（3）SCI范式特别适用于异质性显著的多变量时间序列数据，特别是其仅在关键层的操作设计有效控制了计算开销。然而，该方法主要适用于变量间异质性较强的数据集，在面对变量间高度相关的数据时，其处理效果仍存在一定的局限性；（4）CalendarNet创新性地采用万年历式时间建模与自适应SCI变量建模相结合的策略，通过协调时间与变量维度的一致性和差异性，展现出更强的泛化能力。第五章和第六章的实验结果充分验证了它们在不同场景下的适用性。

综上所述，本文通过一系列创新性方法，有效解决了长程时间序列预测中的关键挑战，显著提升了预测精度和运行效率，为相关领域的研究和应用提供了新的思路和技术支持。

# 7.2 未来工作展望

尽管本文在长程时间序列预测任务中取得了一系列创新性成果，但仍存在一些值得进一步探索的方向，尤其是在模型的泛化性、实用性以及变量间相关性的研究方面。

# (1) 泛化性与场景适应性

本文提出的方法在多个领域的公共数据集上表现优异，但其在不同应用场景中的泛化能力仍需进一步验证。未来的研究可以探索模型在更广泛场景下的适应性，例如金融市场的波动预测、医疗健康领域的生理信号分析等。同时，需要明确模型的局限性及其适用边界，例如在某些高噪声或数据稀疏的场景下，模型的性能可能会受到限制。通过系统性的实验和分析，可以更好地理解模型在不同场景下的表现，从而为其实际应用提供指导。

# (2) 变量间相关性的建模

本文在多变量时间序列预测中提出了通道完全独立（SCI）的建模方式，有效解决了变量异质性带来的噪声干扰问题。然而，变量间的相关性在实际应用中往往具有重要意义。例如，在交通流量预测中，不同路段的流量可能存在协同效应。未来的研究可以探索如何在保持变量独立建模优势的同时，引入变量间相关性的建模机制。例如，借鉴图神经网络（GNN）或注意力机制显式建模变量间相关性

的优势，同时优化计算方式，实现更高精度、高效率的预测。

# (3) 通道建模的明确指导

本文提出的SCI方法为每个变量分配独立参数，有效避免了变量异质性带来的干扰，但在实际应用中，如何选择通道独立（CI）或通道完全独立（SCI）建模方式仍缺乏明确的指导原则。未来的研究可以探索基于数据特性的自适应建模策略，例如通过数据驱动的自动化方法，动态选择适合的建模方式，从而提升模型的实用性和灵活性。

# (4) 单变量与多变量预测的统一框架

本文主要关注独立的单变量时间序列预测和多变量时间序列预测，但在实际应用中，统一的单/多变量时间序列预测具有重要意义。未来的研究可以探索构建一个统一的框架，既能处理单变量时间序列，又能扩展到多变量场景。通过共享部分模型参数或设计通用的特征提取模块，实现单变量与多变量预测的无缝衔接，从而提升模型的普适性。

# (5) 模型效率与实用性的进一步提升

尽管本文提出的方法在计算效率方面已经取得了显著进展，但在大规模数据集或实时预测任务中，模型的效率仍需进一步优化。未来的研究可以探索更高效的算法设计，例如基于分布式计算等技术，以进一步提升模型的实用性。

综上所述，未来的研究将在本研究的基础上，进一步聚焦于泛化性、变量间相关性建模、通道建模指导、单变量与多变量预测的统一框架以及模型效率优化等方面展开深入探索，以推动长程时间序列预测技术向更深层次发展，为更多实际应用场景提供更强的支持。

# 参考文献



[1] 王燕. 应用时间序列分析-第2版 [M]. 应用时间序列分析-第2版, 2008.





[2] Zhou H, Zhang S, Peng J, et al. Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting [C]. In Proceedings of the 35th AAAI Conference on Artificial Intelligence, 2021: 11106-11115.





[3] Yin Y, Shang P. Forecasting Traffic Time Series with Multivariate Predicting Method [J]. Applied Mathematics and Computation, 2016, 291: 266-278.





[4] Angryk R A, Martens P C, Aydin B, et al. Multivariate Time Series Dataset for Space Weather Data Analytics [J]. Scientific data, 2020, 7 (1): 227.





[5] 易丹辉. 时间序列分析: 方法与应用 [M]. 时间序列分析：方法与应用, 2011.





[6] 艾琳·尼尔森. 时间序列分析实战：基于机器学习和统计学 [M]. 北京: 人民邮电出版社, 2023.





[7] Jiang W, Luo J. Graph Neural Network for Traffic Forecasting: A Survey [J]. Expert Systems with Applications, 2022, 207: 117921.





[8] Bui K-H N, Cho J, Yi H. Spatial-Temporal Graph Neural Network for Traffic Forecasting: An Overview and Open Research Issues [J]. Applied Intelligence, 2022, 52 (3): 2763-2774.





[9] Jiang W, Luo J, He M, et al. Graph Neural Network for Traffic Forecasting: The Research Progress [J]. ISPRS International Journal of Geo-Information, 2023, 12 (3): 100.





[10] Box G E, Jenkins G M. Some Recent Advances in Forecasting and Control [J]. Journal of the Royal Statistical Society. Series C (Applied Statistics), 1968, 17 (2): 91-109.





[11] George B E P, Jenkins G M. Time Series Analysis Forecasting and Control [J]. Journal of Time Series Analysis, 1970, 3 (3228).





[12] Corberán-Vallet A, Bermúdez J D, Vercher E. Forecasting Correlated Time Series with Exponential Smoothing Models [J]. International Journal of Forecasting, 2011, 27 (2): 252–265.





[13] Taylor S J, Letham B. Forecasting at Scale [J]. The American Statistician, 2018, 72 (1): 37-45.





[14] Hyndman R J, Athanasopoulos G. Forecasting: Principles and Practice [M]. OTexts, 2018.





[15] Chen Z, Ma M, Li T, et al. Long Sequence Time-Series Forecasting with Deep Learning: A Survey [J]. Information Fusion, 2023, 97: 101819.





[16] Shen Z, Zhang Y, Lu J, et al. A Novel Time Series Forecasting Model with Deep Learning [J]. Neurocomputing, 2020, 396: 302-313.





[17] Torres J F, Hadjout D, Sebaa A, et al. Deep Learning for Time Series Forecasting: A Survey [J]. Big data, 2021, 9 (1): 3-21.





[18] Hewamalage H, Bergmeir C, Bandara K. Recurrent Neural Networks for Time Series Forecasting: Current Status and Future Directions [J]. International Journal of Forecasting, 2021, 37 (1): 388-427.





[19] Khaldi R, Afia A E, Chiheb R, et al. What is the Best RNN-Cell Structure to Forecast Each Time Series Behavior? [J]. Expert Systems with Applications, 2023, 215: 119140.





[20] Jianxin W. Introduction to Convolutional Neural Networks [J]. National Key Lab for Novel Software Technology. Nanjing University. China, 2017, 5 (23): 495.





[21] Li Z, Yang W, Peng S, et al. A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects [J]. IEEE Transactions on Neural Networks and Learning Systems, 2021, 33 (12): 6999-7019.





[22] Vaswani A, Shazeer N, Parmar N, et al. Attention is All You Need [J]. Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017.





[23] Wen Q, Zhou T, Zhang C, et al. Transformers in Time Series: A Survey [C]. In Proceedings of the 32nd International Joint Conference on Artificial Intelligence, 2023: 6778-6786.





[24] Ahmed S, Nielsen I E, Tripathi A, et al. Transformers in Time-Series Analysis: A Tutorial [J]. Circuits, Systems, and Signal Processing, 2023, 42 (12): 7433-7466.





[25] Pascanu R, Mikolov T, Bengio Y. On the Difficulty of Training Recurrent Neural Networks [C]. In International Conference on Machine Learning, 2013: 1310-1318.





[26] Wang H, Peng J, Huang F, et al. MICN: Multi-Scale Local and Global Context Modeling for Long-Term Series Forecasting [C]. In The 11th International Conference on Learning Representations, 2023.





[27] Nie Y, Nguyen N H, Sinthong P, et al. A Time Series is Worth 64 Words: Long-term Forecasting with Transformers [C]. In Proceedings of the 11th International Conference on Learning Representations, 2023.





[28] Tishby N, Zaslavsky N. Deep Learning and the Information Bottleneck Principle [C]. In 2015 IEEE Information Theory Workshop (ITW), 2015: 1-5.





[29] Hyndman R J, Athanasopoulos G. Forecasting: Principles and Practice [M]. 2018.





[30] Cortes C, Vapnik V. Support-Vector Networks [J]. Machine Learning, 1995, 20 (3): 273-297.





[31] Schölkopf B, Smola A. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond [M]. MIT Press, 2002.





[32] Friedman J H. Greedy Function Approximation: A Gradient Boosting Machine [C]. In Proceedings of the 13th International Conference on Neural Information Processing Systems, 1999: 1023-1030.





[33] Chen T, Guestrin C. XGBoost: A Scalable Tree Boosting System [C]. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016: 785-794.





[34] Ke G, Meng Q, Finley T, et al. LightGBM: A Highly Efficient Gradient Boosting Decision Tree [C]. In Proceedings of the 31th International Conference on Neural Information Processing Systems, 2017: 3149-3157.





[35] Qiu X, Zhang L, Suganthan P N, et al. Oblique Random Forest Ensemble via Least Square Estimation for Time Series Forecasting [J]. Information Sciences, 2017, 420: 249-262.





[36] Xueyan, Wu G, Wei J, et al. Deep learning on traffic prediction: Methods, analysis, and future directions [J]. IEEE Transactions on Intelligent Transportation Systems, 2021, 23 (6): 4927-4943.





[37] Naomi Zimmerman SP N K J G A H E S R A L R, Albert A Presto, Subramanian R. A Machine Learning Calibration Model Using Random Forests to Improve Sensor Performance for Lower-Cost Air Quality Monitoring [J]. Atmospheric Measurement Techniques, 2018, 11 (1): 291-313.





[38] Lecun Y, Bengio Y, Hinton G. Deep Learning [J]. Nature, 2015, 521 (7553): 436-444.





[39] Zeng A, Chen M, Zhang L, et al. Are Transformers Effective for Time Series Forecasting? [C]. In Proceedings of the 37th AAAI Conference on Artificial Intelligence, 2023: 11121-11128.





[40] Wang S, Wu H, Shi X, et al. TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting [C]. In The Twelfth International Conference on Learning Representations, 2024.





[41] Xu Z, Zeng A, Xu Q. FITS: Modeling Time Series with  $10\mathrm{k}$  Parameters [C]. In The Twelfth International Conference on Learning Representations, 2024.





[42] Elman J L. Finding Structure in Time [J]. Cognitive science, 1990, 14 (2): 179-211.





[43] Hochreiter S, Schmidhuber J. Long Short-Term Memory [J]. Neural Computation, 1997, 9 (8): 1735-1780.





[44] Chung J, Gulcehre C, Cho K, et al. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling [C]. In NIPS 2014 Workshop on Deep Learning, 2014.





[45] Sutskever I, Vinyals O, Le Q V. Sequence to Sequence Learning with Neural Networks [J], 2014: 3104-3112.





[46] Chang S, Zhang Y, Han W, et al. Dilated Recurrent Neural Networks [J], 2017: 76-86.





[47] Yu Z, Liu G. Sliced Recurrent Neural Networks [C]. In Proceedings of the 27th International Conference on Computational Linguistics, 2018: 2953-2964.





[48] Bai S, Kolter J Z, Koltun V. An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling [J]. Universal Language Model Fine-tuning for Text Classification, 2018.





[49] Franceschi J-Y, Dieuleveut A, Jaggi M. Unsupervised Scalable Representation Learning for Multivariate Time Series [J]. Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019: 4650-4661.





[50] Sen R, Yu H-F, Dhillon I. Think globally, act locally: a deep neural network approach to high-dimensional time series forecasting [J]. Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019: 4837-4846.





[51] Wu H, Hu T, Liu Y, et al. Timesnet: Temporal 2D-Variation Modeling for General Time Series Analysis [C]. In Proceedings of the 11th International Conference on Learning Representations, 2023.





[52] Szegedy C, Liu W, Jia Y, et al. Going Deeper with Convolutions [C]. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015: 1-9.





[53] Luo D, Wang X. Modern Convolution Structure for General Time Series Analysis [C]. In Proceedings of the 12th International Conference on Learning Representations, 2024: 1-43.





[54] Zhou T, Ma Z, Wen Q, et al. Fedformer: Frequency Enhanced Decomposed Transformer for Long-Term Series Forecasting [C]. In Proceedings of the 39th International Conference on Machine Learning, 2022: 27268-27286.





[55] Wu H, Xu J, Wang J, et al. Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting [J]. Proceedings of the 35th International Conference on Neural Information Processing Systems, 2021, 34: 22419-22430.





[56] Liu S, Yu H, Liao C, et al. Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting [C]. In Proceedings of the 9th International Conference on Learning Representations, 2021.





[57] Han L, Ye H-J, Zhan D-C. The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting [J]. IEEE Transactions on Knowledge and Data Engineering, 2024.





[58] Huang Q, Shen L, Zhang R, et al. CrossGNN: Confronting Noisy Multivariate Time Series via Cross Interaction Refinement [C]. In Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023.





[59] Yi K, Zhang Q, Fan W, et al. FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective [C]. In Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023: 69638-69660.





[60] Zhang Y, Yan J. Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting [C]. In The 11th International Conference on Learning Representations, 2023.





[61] Liu Y, Hu T, Zhang H, et al. Itransformer: Inverted Transformers are Effective for Time Series Forecasting [C]. In The 12th International Conference on Learning Representations, 2024.





[62] Rumelhart D E, Hinton G E, Williams R J. Learning Representations by Back-propagating Errors [J]. Nature, 1986, 323 (6088): 533-536.





[63] Lin S, Lin W, Wu W, et al. Sparsetsf: Modeling Long-term Time Series Forecasting with 1k Parameters [C]. In Proceedings of the 41st International Conference on Machine Learning, 2024.





[64] LeCun Y, Bottou L, Bengio Y, et al. Gradient-based Learning Applied to Document Recognition [J]. Proceedings of the IEEE, 1998, 86 (11): 2278-2324.





[65] Hinton G E, Osindero S, Teh Y-W. A Fast Learning Algorithm for Deep Belief Nets [J]. Neural Computation, 2006, 18 (7): 1527-1554.





[66] Oliveira A C B D, Siami M, Sontag E D. Remarks on the Gradient Training of Linear Neural Network Based Feedback for the LQR Problem [J]. 2024 IEEE 63rd Conference on Decision and Control (CDC), 2024: 7846-7852.





[67] Popescu M-C, Balas V E, Perescu-Popescu L, et al. Multilayer perceptron and neural net





works [J]. WSEAS Transactions on Circuits and Systems, 2009, 8 (7): 579-588.





[68] Liu Y, Gong C, Yang L, et al. DSTP-RNN: A Dual-Stage Two-Phase Attention-Based Recurrent Neural Network for Long-Term and Multivariate Time Series Prediction [J]. Expert Systems with Applications, 2020, 143: 113082.





[69] Cho K, van Merrienboer B, Bahdanau D, et al. On the Properties of Neural Machine Translation: Encoder-decoder Approaches [C]. In 8th Workshop on Syntax, Semantics and Structure in Statistical Translation, SSST 2014, 2014: 103-111.





[70] Bahdanau D, Cho K H, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate [C]. In Proceedings of the 3rd International Conference on Learning Representations (ICLR), 2015.





[71] Hochreiter S, Schmidhuber J. Long Short-term Memory [J]. Neural Computation, 1997, 9 (8): 1735-1780.





[72] Cho K, Merrienboer B V, Gulcehre C, et al. Learning Phrase Representations using RNN Encoder-decoder for Statistical Machine Translation [C]. In Conference on Empirical Methods in Natural Language Processing, 2014.





[73] LeCun Y, Boser B, Denker J S, et al. Backpropagation Applied to Handwritten Zip Code Recognition [J]. Neural Computation, 1989, 1 (4): 541-551.





[74] Krizhevsky A, Sutskever I, Hinton G E. Imagenet Classification with Deep Convolutional Neural Networks [C]. In Proceedings of the 26th International Conference on Neural Information Processing Systems, 2012.





[75] Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-scale Image Recognition [C]. In The 11th International Conference on Learning Representations, 2015.





[76] He K, Zhang X, Ren S, et al. Deep Residual Learning for Image Recognition [C]. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016: 770-778.





[77] Wan R, Mei S, Wang J, et al. Multivariate Temporal Convolutional Network: A Deep Neural Networks Approach for Multivariate Time Series Forecasting [J]. Electronics, 2019, 8 (8): 876.





[78] Zhang C-X, Li J, Huang X-F, et al. Forecasting Stock Volatility and Value-at-risk Based on Temporal Convolutional Networks [J]. Expert Systems with Applications, 2022, 207: 117951.





[79] Bahdanau D, Cho K, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate [C]. 2014.





[80] Luong M-T, Pham H, Manning C D. Effective Approaches to Attention-based Neural Machine Translation [C]. 2015.





[81] Ott M, Edunov S, Grangier D, et al. Scaling Neural Machine Translation [C]. In Proceedings of the Third Conference on Machine Translation: Research Papers (WMT), 2018: 1-9.





[82] Zhang J, Zhao Y, Saleh M, et al. Pegasus: Pre-Training with Extracted Gap-Sentences for Abstractive Summarization [C]. In Proceedings of the 37th International Conference on Machine Learning, 2020: 11328–11339.





[83] Devlin J, Chang M-W, Lee K, et al. Bert: Pre-Training of Deep Bidirectional Transformers for





Language Understanding [C]. In Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), 2019: 4171-4186.





[84] Ba J L, Kiros J R, Hinton G E. Layer Normalization [J]. stat, 2016, 1050: 21.





[85] Nie X, Zhou X, Li Z, et al. Logtrans: Providing efficient local-global fusion with transformer and cnn parallel network for biomedical image segmentation [C]. In 2022 IEEE 24th Int Conf on High Performance Computing & Communications, 2022: 769-776.





[86] Kitaev N, Kaiser L, Levskaya A. Reformer: The Efficient Transformer [C]. In International Conference on Learning Representations, 2020.





[87] Cooley J W, Tukey J W. An Algorithm for The Machine Calculation of Complex Fourier Series [J]. Mathematics of Computation, 1965, 19 (90): 297-301.





[88] Velicković P, Cucurull G, Casanova A, et al. Graph Attention Networks [C]. In International Conference on Learning Representations, 2018.





[89] Yu X, Shi S, Xu L. A Spatial-Temporal Graph Attention Network Approach for Air Temperature Forecasting [J]. Applied Soft Computing, 2021, 113: 107888.





[90] Liu H, Yang D, Liu X, et al. Todynet: Temporal Dynamic Graph Neural Network for Multivariate Time Series Classification [J]. Information Sciences, 2024, 677: 120914.





[91] Chen L, You Z, Zhang N, et al. UTRAD: Anomaly Detection and Localization with U-Transformer [J]. Neural Networks, 2022, 147: 53–62.





[92] Guo K, Hu Y, Sun Y, et al. Hierarchical Graph Convolution Network for Traffic Forecasting [C]. In Proceedings of the 35th AAAI Conference on Artificial Intelligence, 2021: 151-159.





[93] Wu Z, Pan S, Long G, et al. Graph Wavenet for Deep Spatial-Temporal Graph Modeling [C]. In The 28th International Joint Conference on Artificial Intelligence (IJCAI), 2019.





[94] Kipf T N, Welling M. Semi-Supervised Classification with Graph Convolutional Networks [C]. In International Conference on Learning Representations, 2017.





[95] Lai G, Chang W, Yang Y, et al. Modeling Long-and Short-Term Temporal Patterns with Deep Neural Networks [C]. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, 2018: 95-104.





[96] 谢贵才, 段磊, 蒋为鹏, et al. 多尺度时序依赖的校园公共区域人流量预测 [J]. 软件学报, 2021, 32 (3): 14.





[97] Livieris I E, Pintelas E, Pintelas P. A CNN-LSTM Model for Gold Price Time-Series Forecasting [J]. Neural Computing and Applications, 2020, 32: 17351-17360.





[98] Li S, Jin X, Xuan Y, et al. Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting [J]. Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019, 32.





[99] Zhou T, Ma Z, Wen Q, et al. Film: Frequency Improved Legendre Memory Model for Long-Term Time Series Forecasting [J]. Proceedings of the 36th International Conference on Neural Information Processing Systems, 2022, 35: 12677–12690.





[100] Rangapuram S S, Seeger M W, Gasthaus J, et al. Deep State Space Models for Time Series Forecasting [J]. Proceedings of the 32nd International Conference on Neural Information Processing Systems, 2018, 31.





[101] Salinas D, Flunkert V, Gasthaus J, et al. DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks [J]. International Journal of Forecasting, 2020, 36 (3): 1181-1191.





[102] Paszke A, Gross S, Sam F, et al. Pytorch: An imperative style, high-performance deep learning library [J]. Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019, 32.





[103] Kinga D, Adam J B. A Method for Stochastic Optimization [C]. In Proceedings of the 3rd International Conference on Learning Representations (ICLR), 2015.





[104] Jia Y, Lin Y, Hao X, et al. WITRAN: Water-wave Information Transmission and Recurrent Acceleration Network for Long-range Time Series Forecasting [C]. In Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023.





[105] Dai T, Wu B, Liu P, et al. Periodicity Decoupling Framework for Long-term Series Forecasting [C]. In The 12th International Conference on Learning Representations, 2024.





[106] Lin S, Lin W, Wu W, et al. Segrn: Segment recurrent neural network for long-term time series forecasting [J]. arXiv preprint arXiv:2308.11200, 2023.





[107] Ni Z, Yu H, Liu S, et al. BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis [C]. In Proceedings of 37th Conference on Neural Information Processing Systems, 2023.





[108] Jia Y, Lin Y, Yu J, et al. PGN: The RNN's New Successor is Effective for Long-Range Time Series Forecasting [C]. In Proceedings of the 38th International Conference on Neural Information Processing Systems, 2024.





[109] Liu Y, Wu H, Wang J, et al. Non-stationary transformers: exploring the stationarity in time series forecasting [C]. In Proceedings of the 36th International Conference on Neural Information Processing Systems, 2022: 9881-9893.





[110] Liu Y, Li C, Wang J, et al. Koopa: learning non-stationary time series dynamics with koopman predictors [C]. In Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023: 12271-12290.





[111] Duhamel P, Vetterli M. Fast Fourier transforms: a tutorial review and a state of the art [J]. Signal processing, 1990, 19 (4): 259-299.





[112] Yu G, Zou J, Hu X, et al. Revitalizing multivariate time series forecasting: learnable decomposition with inter-series dependencies and intra-series variations modeling [C]. In Proceedings of the 41st International Conference on Machine Learning, 2024: 57818-57841.





[113] Yi K, Fei J, Zhang Q, et al. FilterNet: Harnessing Frequency Filters for Time Series Forecasting [C]. In Proceedings of the 38th International Conference on Neural Information Processing Systems, 2024.





[114] Huang S, Zhao Z, Li C, et al. TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting [C]. In The Thirteenth International Con-



ference on Learning Representations, 2025.

# 学位论文数据集


表 1.1 数据集页


<table><tr><td>关键词*</td><td>密级*</td><td>中图分类号</td><td>UDC</td><td>论文资助</td></tr><tr><td>长程时间序列预测；水波式信息传递；并行门控网络；变量完全独立建模；万年历式信息提取</td><td>公开</td><td>中图分类号 查阅：http://www.ztflh.com/</td><td></td><td></td></tr><tr><td colspan="2">学位授予单位名称*</td><td>学位授予单位代码*</td><td>学位类别*</td><td>学位级别*</td></tr><tr><td colspan="2">北京交通大学</td><td>10004</td><td>工学</td><td>博士</td></tr><tr><td colspan="2">论文题名*</td><td colspan="2">并列题名</td><td>论文语种*</td></tr><tr><td colspan="2">长程时间序列预测方法研究</td><td colspan="2"></td><td>中文</td></tr><tr><td>作者姓名*</td><td colspan="2">贾宇欣</td><td>学号*</td><td>21112031</td></tr><tr><td colspan="2">培养单位名称*</td><td>培养单位代码*</td><td>培养单位地址</td><td>邮编</td></tr><tr><td colspan="2">北京交通大学</td><td>10004</td><td>北京市海淀区西直门外上园村3号</td><td>100044</td></tr><tr><td colspan="2">学科专业*</td><td>研究方向*</td><td>学制*</td><td>学位授予年*</td></tr><tr><td colspan="2">计算机科学与技术</td><td>机器学习</td><td>4年</td><td>2025年</td></tr><tr><td>论文提交日期*</td><td colspan="4">2025年6月</td></tr><tr><td>导师姓名*</td><td colspan="2">林友芳</td><td>职称*</td><td>教授</td></tr><tr><td>评阅人</td><td colspan="2">答辩委员会主席*</td><td colspan="2">答辩委员会成员</td></tr><tr><td>贾彩燕、王宁、万怀宇、高良才、张莹</td><td colspan="2">贾彩燕</td><td colspan="2">王宁、万怀宇、高良才、张莹</td></tr><tr><td colspan="5">电子版论文提交格式 文本（✓）图像()视频()音频()多媒体()其他()推荐格式：application/msword；application/pdf</td></tr><tr><td colspan="2">电子版论文出版（发布）者</td><td colspan="2">电子版论文出版（发布）地</td><td>权限声明</td></tr><tr><td colspan="2"></td><td colspan="2"></td><td></td></tr><tr><td>论文总页数*</td><td colspan="4">139页</td></tr><tr><td colspan="5">共33项，其中带*为必填数据，为22项。</td></tr></table>